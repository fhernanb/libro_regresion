# Diagn贸sticos parte II {#diag2}
En este cap铆tulo se presentan otras herramientas 煤tiles para realizar diagn贸sticos.

## Matriz sombrero o hat {-}
La matriz sombrero o matriz Hat se define as铆:

$$
\boldsymbol{H} = \boldsymbol{X}(\boldsymbol{X}^\top \boldsymbol{X})^{-1}\boldsymbol{X}^\top
$$

Esta matriz contiene en su diagonal las distancias relativas desde el centroide de los datos hasta cada uno de los puntos. En la siguiente figura se ilustra el concepto de distancia relativa entre el centroide (color rojo) de las variables explicativas y cada uno de los puntos para un caso con tres variables explicativas $x_1$, $x_2$ y $x_3$.

<p align="center">
  <img src="images/ilustracion_hat.png" width="300">
</p>

La cantidad $h_{ii}$ se llama leverage y corresponde al elemento $i$ de la diagonal de la matriz sombrero $\boldsymbol{H}$. Los valores de $h_{ii}$ cumplen lo siguiente:

- siempre est谩n entre $1/n$ y 1. 
- la suma $\sum h_{ii}$ es igual al n煤mero de $\beta$'s del modelo (incluyendo $\beta_0$).

Si la observaci贸n $i$-茅sima tiene un valor grande de $h_{ii}$ significa que ella tiene valores inusuales de $\boldsymbol{x}_i$, mientras que valores peque帽os de $h_{ii}$ significa que la observaci贸n se encuentra cerca del centroide de los datos.

```{block2, type='rmdwarning'}
La distancia $h_{ii}$ no incluye informaci贸n de la variable respuesta $y$, solo de las covariables, esto se nota claramente en la f贸rmula de $\boldsymbol{H}$ dada arriba.
```

驴Para qu茅 se usan los $h_{ii}$ en la pr谩ctica?

En el siguiente apartado se explicar谩 el uso de los $h_{ii}$.

## 驴Qu茅 es extrapolaci贸n oculta? {-}
Suponga tenemos un modelo de regresi贸n una variable respuesta y dos covariables $x_1$ y $x_2$. En la siguiente figura se ilustra los posibles datos desde una vista superior (sin ver los valores de $y$). Esa elipse o forma se llama Regressor Variable Hull (RVH) o cascar贸n de los datos.

<p align="center">
  <img src="images/extrapolacion_oculta.png" width="500">
</p>

Una vez se tenga el modelo ajustado podr铆amos usar valores de $x_1$ y $x_2$ para estimar la media de $y$. Lo ideal es usar el modelo para predecir la media de $y$ con valores de $x_1$ y $x_2$ que se encuentren dentro del cascar贸n. 

Si tratamos de estimar la media de $y$ para valores de las covariables fuera del cascar贸n, como en el caso del punto rojo, no podemos garantizar que el modelo tenga un buen desempe帽o debido a que el modelo no se entren贸 con ese tipo de ejemplos.

El problema de __extrapolaci贸n oculta__ se presenta cuando tratamos de predecir informaci贸n de $y$ con covariables fuera del cascar贸n. La extrapolaci贸n oculta es f谩cil de identificarla cuando s贸lo se tiene dos covariables, pero, 驴c贸mo saber si se est谩 haciendo extrapolaci贸n oculta cuando se tienen varias covariables. 
Supongamos que queremos saber si el vector de covariables $\boldsymbol{x}_0=(x_1, x_2, \ldots, x_p)^\top$ est谩 o no dentro del cascar贸n, dicho de otra manera, 驴se cometer铆a extrapolaci贸n oculta usando $\boldsymbol{x}_0$?. Los pasos para determinar si $\boldsymbol{x}_0$ est谩 o no dentro del cascar贸n son:

1. Calcular la matriz $\boldsymbol{H}$.
2. Obtener los valores $h_{ii}$ de la matriz $\boldsymbol{H}$.
3. Identificar $h_{max} = max\{h_{11}, h_{22}, \ldots, h_{nn}\}$.
4. Calcular $h_{00} = \boldsymbol{x}_0 (\boldsymbol{X}^\top \boldsymbol{X})^{-1} \boldsymbol{x}_0^\top$.
5. Si $h_{00} > h_{max}$ el punto $\boldsymbol{x}_0$ est谩 fuera del cascar贸n y se podr铆a est谩r cometiendo extrapolaci贸n oculta.

Los valores $h_{ii}$ se pueden obtener al calcular la matriz $\boldsymbol{H}$. Otra forma de obtener los $h_{ii}$ es ajustando el modelo de regresi贸n y luego usando la funci贸n `hatvalues(model)` o `lm.influence(model)`.

### Ejemplo {-}
Calcular los valores $h_{ii}$ para un modelo de regresi贸n `y ~ x + z` con los siguientes datos.

```{r}
y <- c(2, 3, 6, 5)
x <- c(3, 5, 6, 7)
z <- c(5, 4, 6, 3)
```

__Soluci贸n__

A seguir se muestran las tres formas para obtener los valores $h_{ii}$.

```{r}
# Forma 1
X <- cbind(1, x, z)
H <- X %*% solve(t(X) %*% X) %*% t(X)
H
diag(H)

# Forma 2
mod <- lm(y ~ x + z)
hatvalues(mod)

# Forma 3
lm.influence(mod)$hat
```

### Reto para el lector {-}
Use la informaci贸n del ejemplo anterior y determine si la observaci贸n con valores de $x=4$ y $z=1$ est谩 o no dentro del cascar贸n de los datos, en otras palabras, determine si se podr铆a cometer extrapolaci贸n oculta al usar el modelo ajustado con $x=4$ y $z=1$.

## Punto at铆pico (outlier) y punto influyente {-}
Los conceptos de at铆pico e influyente son diferentes y se definen as铆:

- Punto at铆pico (outlier): es una observaci贸n que es num茅ricamente distante del resto de los datos.
- Punto influyente: punto que tiene impacto en las estimativas del modelo.

En la siguiente figura se ilustra la diferencia entre los conceptos de at铆pico e influyente.

<p align="center">
  <img src="images/atipico_influyente.png" width="500">
</p>

驴C贸mo se puede saber si un punto es influyente?

Para saber si un punto es influyente debemos tener una m茅trica o medida para determinar si 茅l es influyente, una medida podr铆a ser la Distancia de Cook.

## Prueba de Bonferroni para detectar outliers
El paquete **car** [@R-car] tiene la funci贸n `outlierTest` para realizar una prueba de hip贸tesis con $H_0:$ la observaci贸n $i$-茅sima NO es un outlier frente a $H_1:$ la observaci贸n $i$-茅sima SI es un outlier. La estructura de la funci贸n `outlierTest` se muestra a continuaci贸n.

```{r eval=FALSE}
outlierTest(model, cutoff=0.05, n.max=10, order=TRUE, labels=names(rstudent), ...)
```

En la secci贸n 11.3.1 del libro @fox2015applied est谩n los detalles de la prueba, se invita al lector para que los consulte.

### Ejemplo {-}
En este ejemplo se usar谩 una base de datos que contiene medidas corporales para un grupo de estudiantes universitarios que vieron el curso de modelos de regresi贸n en el a帽o 2013. Abajo se muestra una figura ilustrativa de los datos.

<p align="center">
  <img src="images/medidas_cuerpo_upb.png" width="700">
</p>

El objetivo es determinar si hay alguna observaci贸n que se pueda considerar como outlier cuando se ajusta un modelo de regresi贸n para explicar el peso corporal en funci贸n de las otras covariables.

__Soluci贸n__

Primero vamos a ajustar el modelo y luego vamos a aplicar la prueba de Bonferroni para detectar outliers.

```{r}
url <- "https://raw.githubusercontent.com/fhernanb/datos/master/medidas_cuerpo2"
datos <- read.table(file=url, sep="\t", header=TRUE)

mod <- lm(Peso ~ Estatura + circun_cuello + circun_muneca, data=datos)

library(car)
outlierTest(mod, cutoff=Inf, n.max=4)
```

En la salida de arriba vemos las cuatro observaciones (`n.max=4`) que tienen los mayores valores de residual estudentizado $r_i$. La observaci贸n ubicada en la l铆nea 11 es la 煤nica con un valor-P muy peque帽o y por lo tanto hay evidencias para considerar esa observaci贸n como un posible outlier.

Es posible dibujar los resultados de la prueba para cada observaci贸n usando la funci贸n `influenceIndexPlot` del paquete **car**. En la siguiente figura se observa que s贸lo la observacion 11 es identificada como un posible outlier.

```{r bonf_test_01, fig.height=6, fig.width=6, fig.align='center'}
influenceIndexPlot(mod, vars="Bonf", las=1)
```

## Distancia de Cook {-}
Es una medida de c贸mo influye la observaci贸n $i$-茅sima sobre la estimaci贸n de $\boldsymbol{\beta}$ al ser retirada del conjunto de datos. Una distancia de Cook grande significa que una observaci贸n tiene un peso grande en la estimaci贸n de $\boldsymbol{\beta}$.

$$
D_i = \frac{\sum_{j=1}^{n} (\hat{y}_j - \hat{y}_{j(i)} )^2 }{p \hat{\sigma^2}},
$$

donde la notaci贸n $(i)$ significa "sin la observaci贸n $i$-茅sima", eso quiere decir que $\hat{y}_{j(i)}$ es la estimaci贸n de $j$-茅sima sin haber tenido en cuenta $i$-茅sima observaci贸n en el ajuste del modelo. La cantidad $p$ se refiere a todos los $\beta$'s en el modelo ($\beta_0, \beta_1, \beta_2, \ldots, \beta_k$).

<p align="center">
  <img src="images/get_out.gif" width="200">
</p>

```{block2, type='rmdnote'}
Son puntos influyentes las observaciones que presenten $D_i=\frac{4}{n-p-2}$.
```

### Ejemplo: 驴c贸mo se relaciona el peso corporal con la circunferencia de la mu帽eca, cuello y estatura? {-}
En este ejemplo se usar谩 una base de datos que contiene medidas corporales para un grupo de estudiantes universitarios que vieron el curso de modelos de regresi贸n en el a帽o 2013. Abajo se muestra una figura ilustrativa de los datos.

<p align="center">
  <img src="images/medidas_cuerpo_upb.png" width="700">
</p>

El objetivo es ajustar un modelo de regresi贸n para explicar el peso promedio en funci贸n de la circunferencia de la mu帽eca, cuello y estatura. Luego de ajustar el modelo se deben identificar los posible estudiantes influyentes y el efecto de ellos en el modelos.

__Soluci贸n__

Lo primero es cargar los datos en nuestra sesi贸n de R.

```{r}
url <- "https://raw.githubusercontent.com/fhernanb/datos/master/medidas_cuerpo2"
datos <- read.table(file=url, sep="\t", header=TRUE)
head(datos, n=5)
```

Antes de ajustar cualquier modelo es fundamental hacer un an谩lisis descriptivo de los datos. Comenzaremos construyendo un diagrama de dispersi贸n con `pairs`.

```{r upb_01, fig.height=6, fig.width=6, fig.align='center'}
panel.cor <- function(x, y, digits=2, prefix="", cex.cor, ...) {
  usr <- par("usr"); on.exit(par(usr))
  par(usr=c(0, 1, 0, 1))
  r <- cor(x, y)
  txt <- format(c(r, 0.123456789), digits=digits)[1]
  txt <- paste(prefix, txt, sep="")
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex=cex.cor * r, col=gray(1-r))
}

# Creamos el grafico SOLO para las variables cuantitativas
pairs(datos[, c("Peso", "Estatura", "circun_cuello", "circun_muneca")], 
      pch=19, las=1,
      upper.panel=panel.smooth, lower.panel=panel.cor)
```

De la figura anterior se observa que hay un punto que se aleja de la nube, es un estudiante que pesa un poco m谩s de 100 kilogramos.

En la siguiente figura se muestran los valores de $h_{ii}$ para cada estudiante, esta figura se obtiene con la funci贸n `influenceIndexPlot` del paquete **car**.

```{r hii_estudiantes_upb, fig.height=6, fig.width=6, fig.align='center'}
influenceIndexPlot(mod, vars="hat")
```

De la figura anterior se observa que los estudiantes 3 y 17 fueron se帽alados por est谩r muy lejos del centroide de los datos. 

Vamos ahora a ajustar nuestro primer modelo.

```{r}
mod1 <- lm(Peso ~ Estatura + circun_cuello + circun_muneca, data=datos)
summary(mod1)
```

Como en la tabla anterior aparecen variables que nos son significativas vamos a realizar una selecci贸n de variables usando el paquete **mixlm** creado por @R-mixlm. Vamos a realizar una selecci贸n de variables de manera que s贸lo queden variables significativas con un $\alpha=0.04$.

```{r}
mod2 <- mixlm::backward(mod1, alpha=0.04)
summary(mod2)
```

En la siguiente tabla se comparan los modelos 1 y 2 ajustados hasta ahora.

<p align="center">
  <img src="images/tabla_1_2_upb.png" width="400">
</p>

De la tabla anterior podemos destacar lo siguiente:

- El intercepto estimado cambia bastante.
- En el modelo 2 la variable cuello aumenta su efecto.
- El $R^2$ se mantiene constante.
- La varianza de los errores disminuye, eso significa que el modelo 2 deja menos sin explicar.

Vamos ahora a crear el diagrama de dispersi贸n con el modelo ajustado.

```{r upb_02, fig.height=4, fig.width=5, fig.align='center'}
# Para construir el grafico de dispersion
with(datos, 
     plot(x=circun_cuello, y=Peso, pch=19, las=1,
          xlab="Circunferencia cuello (cm)", ylab="Peso (Kg)"))
# Ahora agregamos la linea de tendencia
abline(mod2, lwd=3, col='blue2')
# por ultimo un texto con la ecuacion o modelo ajustado
text(x=34, y=95, expression(hat(Peso) == -44.61 + 3.10 * C.cuello), 
     col='blue3' )
```

De la figura anterior vemos que hay un estudiante (el de 100 kilos de peso) que est谩 muy alejado de la recta de regresi贸n. 

Vamos a calcular las distancia de Cook para las observaciones del modelo 2 as铆:

```{r}
cooks.distance(mod2)
```

Es mejor representar las distancias de Cook en forma gr谩fica para identificar los posible puntos influyentes as铆:

```{r upb_03, fig.height=4, fig.width=5, fig.align='center'}
cutoff <- 4 / (26-2-2)
plot(mod2, which=4, cook.levels=cutoff, las=1)
abline(h=cutoff, lty="dashed", col="springgreen3")
```

De esta figura es claro que las observaciones 11 y 8 tienen $D_i$ por encima de la cota y se consideran observaciones influyentes.

Ahora vamos a revisar los residuales del modelo 2.

```{r upb_04, fig.height=6, fig.width=6, fig.align='center'}
par(mfrow=c(2, 2))
plot(mod2, col='deepskyblue4')
```

De la anterior figura vemos que las observaciones 8, 11 y 13 fueron identificadas por tener valores de residuales grandes.

Vamos ahora a identificar las observaciones 8, 11, 12 y 13 en un diagrama de dispersi贸n.

```{r upb_05, fig.height=4, fig.width=5, fig.align='center', echo=FALSE}
with(datos, 
     plot(x=circun_cuello, y=Peso, pch=19, las=1, xlim=c(29, 43), ylim=c(45, 110),
          xlab="Circunferencia cuello (cm)", ylab="Peso (Kg)"))
abline(mod2, lwd=3, col='blue2')
text(x=34, y=95, expression(hat(Peso) == -44.61 + 3.10 * C.cuello), 
     col='blue3')
points(x=datos$circun_cuello[c(8, 11, 12, 13)],
       y=datos$Peso[c(8, 11, 12, 13)], pch=21, col='red', cex=2)
text(x=datos$circun_cuello[c(8, 11, 12, 13)] + 0.8,
       y=datos$Peso[c(8, 11, 12, 13)], c(8, 11, 12, 13), col='red')
```

La observaci贸n 11 es un hombre que pesa m谩s de 100 kilos y que solo mide 1.79 metros. Las observaciones 8, 12 y 13 son mujeres con las mayores diferencias entre $y_i$ y $\hat{y}_i$, para ellas el modelo sobreestima el peso corporal.

En la siguiente tabla se muestran los resultados de ajustar nuevamente el modelo 2 bajo tres situaciones: con todas las observaciones, sin la observaci贸n 11 y sin las observaciones 8, 11, 12 y 13. De la tabla vemos que la observaci贸n 11 es muy influyente, al sacar esa observaci贸n el modelo aumenta su $R^2$ y disminuye su $\sigma^2$. De la 煤ltima columna se observa el mismo comportamiento, $R^2$ aumenta y disminuye su $\sigma^2$ al sacar todas las observaciones sospechosas. 

<p align="center">
  <img src="images/tabla_2_sin_obs_inf_upb.png" width="400">
</p>

Pero, 驴cu谩l modelo debo usar como modelo final? 驴El modelo 2, el modelo 2 sin la obs 11 o el modelo 2 sin las obs 8, 11, 12 y 13?

Lo que se recomienda es que el analista se asesore de un experto en el 谩rea de aplicaci贸n para que juntos estudien esas observaciones sospechosas. Si hay una raz贸n de peso para considerarlas como observaciones at铆picas, ellas deben salir del modelo. Si por el contrario, no hay nada raro con las observaciones ellas deben seguir en el modelo. 

<p align="center">
  <img src="images/revisar.png" width="200">
</p>

```{block2, type='rmdwarning'}
Las observaciones sospechosas NO se deben sacar inmediatamente del modelo. Antes se deben estudiar para ver si hay algo raro con ellas, en caso afirmativo se sacan de la base y se ajusta nuevamente el modelo.
```

```{block2, type='rmdnote'}
Una observaci贸n influyente NO es una observaci贸n mala en el modelo. Al contrario, ella es una observaci贸n clave en el ajuste porque "lidera" la estimaci贸n.

Una observaci贸n que no es influyente es una observaci贸n que estando presente o no, el modelo ajustado no se ve afectado.
```

## DFFITS {-}
Se puede investigar la influencia de eliminar la $i$-茅sima observaci贸n sobre el valor predicho o ajustado.

$$
DFFITS_i = \frac{\hat{y}_i - \hat{y}_{i(i)}}{\sqrt{s_{(i)}^2 h_{ii}}}.
$$

Se sugiere que merece investigarse toda observaci贸n con $|DFFITS| > 2 \sqrt{p/n}$.

La funci贸n en R para obtener los $DFFITS_i$ es `dffits`.

## DFBETAS {-}
Indica cu谩nto cambia el coeficiente de regresi贸n, en unidades de desviaci贸n est谩ndar, si se omitiera la -茅sima observaci贸n.

$$
DFBETAS_{i,j} = \frac{\hat{\beta}_j - \hat{\beta}_{j(i)}}{\sqrt{s_{(i)}^2 C_{jj}}},
$$

donde $C_{jj}$ es $j$-茅simo elemento de la diagonal de $(\boldsymbol{X}^\top \boldsymbol{X})^{-1}$. Se sugiere que merece investigarse toda observaci贸n con $|DFBETAS| > 2 \sqrt{n}$.

La funci贸n en R para obtener los $DFBETAS_{i,j}$ es `dfbetas`.

### Ejemplo {-}
En R se pueden encontrar las funciones `dfbeta` y `dfbetas`, esto puede generar alguna confusi贸n y por esa raz贸n vamos a explicar con detalle el asunto.

__Soluci贸n__

Vamos a crear unos datos para el ejemplo.

```{r}
# Creando unos datos de ejemplo
datos <- data.frame(x=1:5, y=rnorm(5))
mod <- lm(y ~ x, data=datos)
```

```{r}
dfbeta(mod)
```

```{r}
dfbetas(mod)
```

```{r}
# DFBETAS para la pendiente manual para i=1
mod1 <- lm(y ~ x, data=datos[-1, ])

# Para obtener dfbeta de pendiente para i=1
coef(mod)[2] - coef(mod1)[2]
```

```{r}
# Para obtener dfbetas de pendiente para i=1
numerator <- mod$coef[2] - mod1$coef[2]
denominator <- sqrt(summary(mod1)$sigma^2 * 
	         diag(summary(mod)$cov.unscaled)[2])
DFBETAS <- numerator/denominator
DFBETAS
```

En conclusi贸n,

1. La funci贸n `dfbeta` entrega $\hat{\beta}_j - \hat{\beta}_{j(i)}$.
2. La funci贸n `dfbetas` entrega $\frac{\hat{\beta}_j - \hat{\beta}_{j(i)}}{\sqrt{s_{(i)}^2 C_{jj}}}$.

驴Cu谩l de las dos funciones se debe usar?

