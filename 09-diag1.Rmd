# Diagnósticos parte I {#diag1}
En este capítulo se presentan varias herramientas útiles para hacer diagnósticos de un modelo ajustado.

## Supuestos {-}
Los supuestos en un modelo de regresión se pueden escribir de dos formas:

__Forma I__

1. Los errores $\epsilon_i$ tienen distribución normal.
2. Los errores $\epsilon_i$ tienen media cero.
3. Los errores $\epsilon_i$ tiene varianza constante.
4. Los errores $\epsilon_i$ no están correlacionados.

__Forma II__

1. La respuesta $y$ tiene distribución normal.
2. La varianza de la respuesta $y$ es constante.
3. Las observaciones son independientes $y$.
4. Relación lineal entre la variable respuesta y las covariables.

Ambos conjuntos de supuestos son equivalentes, la forma I está dirigida hacia los errores mientras que en la forma II está dirigida hacia los $y_i$.

## Residuales {-}
Los residuales en los modelos de regresión nos ayuda a:

- determinar qué tan bien el modelo explica el patrón de los datos,
- verificar el cumplimiento de los supuestos del modelo.

<p align="center">
  <img src="images/ResidualsLinear.gif" width="200">
</p>

A continuación se muestran los diferentes tipos de residuales que se pueden definir para un modelo de regresión.

<p align="center">
  <img src="images/tipos_de_residuales.png" width="600">
</p>

La cantidad $w_i$ corresponde al peso o importancia de cada observación en el modelo, por defecto es $w_i=1$. 

La cantidad $h_{ii}$ se llama leverage y corresponde al elemento $i$ de la diagonal de la matriz sombrero o hat $\boldsymbol{H} = \boldsymbol{X}(\boldsymbol{X}^\top \boldsymbol{X})^{-1}\boldsymbol{X}^\top$. 

La varianza $\hat{\sigma}_{(i)}^{2}$ es la varianza estimada al __NO__ tener en cuenta la observación $i$-ésima. La cantidad $\hat{y}_{(i)}$ es la estimación de la $i$-ésima observación usando un modelo en el cual la observación $i$-ésima __NO__ fue usada en el ajuste del modelo.

Para obtener los residuales arriba definidos tenemos las siguientes funciones:

```{r eval=FALSE}
residuals(object, type=c("working", "response", "deviance", "pearson", "partial"))
rstandard(object)
rstudent(object)
```

Si un modelo lineal está correctamente especificado (ajustado), los residuos de Pearson serán independientes de los valores ajustados e independientes de los predictores, y estos gráficos deben ser "gráficos nulos", es decir, gráficos sin características sistemáticas, en el sentido de que la distribución condicional de los residuos (en el eje vertical del gráfico) no debe cambiar con los valores ajustados o con un predictor (en el eje horizontal) [@fox2019].

```{block2, type='rmdwarning'}
Los errores del modelo se denotan como $\epsilon_i$ mientras que los residuales usuales se denotan como $e_i$, no los confunda.
```

### Ejemplo {-}
Considere los datos mostrados abajo, ajuste un modelo de regresión lineal para explicar la media de $y$ en función de $x$ y usando como pesos los valores de $w$. Obtenga los residuales usando las definiciones y luego usando las funciones de R, compruebe que los resultados coinciden.

```{r}
x <- c(4, 6, 8, 7, 8, 5)
y <- c(1, 2, 3, 4, 5, 4)
w <- c(0.1, 0.1, 0.2, 0.1, 0.2, 0.9)
```

__Solución__

Primero se van a calcular los residuales manualmente aplicando las definiciones.

```{r}
mod <- lm(y ~ x, weights=w)

ei <- y - fitted(mod)
pi <- ei * sqrt(mod$weights)
hii <- lm.influence(mod)$hat
di <- ei * sqrt(mod$weights) / sqrt(summary(mod)$sigma^2 * (1-hii))
ri <- ei * sqrt(mod$weights) / sqrt(lm.influence(mod)$sigma^2 * (1-hii))

cbind(ei=ei, pi=pi, di=di, ri=ri)
```

Ahora se van a calcular los residuales usando las funciones de R.

```{r}
cbind(ei=residuals(mod, type='working'),
      pi=residuals(mod, type='pearson'),
      di=rstandard(mod),
      ri=rstudent(mod))
```

Estimado lector, __¿qué puede usted concluir de los resultados de este ejemplo?__

## Chequeando normalidad de los errores {-}
Para estudiar si lo errores tienen una distribución aproximadamente normal se construyen los residuales estandarizados $d_i$. Una vez calculados los $d_i$ se construye un gráfico de normalidad o qqplot usando la función `qqnorm`, el resultado es un gráfico similar al mostrado a continuación.

<p align="center">
  <img src="images/qq_residuales_estandarizados.png" width="450">
</p>

En la siguiente figura se muestran los diferentes patrones que se pueden encontrar en el gráfico de normalidad para $d_i$. Para que se cumpla el supuesto de normalidad de los errores $e_i$ se necesita que los $d_i$ estén lo más alineados con la recta de referencia, alejamientos severos de esta recta significa que se viola el supuesto de normalidad de los errores.

<p align="center">
  <img src="images/patrones_qqplot.png" width="450">
</p>

## Chequeando si errores con media cero {-}
Para determinar si los errores tienen una media cerca al valor de cero se puede usar la función `mean` sobre los residuales $e_i$.

## Chequeando si los errores tiene varianza constante {-}
En la siguiente figura se muestra el caso de varianza $\sigma^2$ constante (homocedasticidad) y el caso de varianza $\sigma^2$ no constante (heterocedasticidad). La homocedasticidad es el supuesto exigido en modelos de regresión.

<p align="center">
  <img src="images/homo_hetero.png" width="500">
</p>

Para chequear si los errores tiene varianza constante se construye un gráfico de $e_i$ versus $\hat{\mu}_i$, un gráfico similar al mostrado a continuación.

<p align="center">
  <img src="images/ei_versus_mui.png" width="450">
</p>

En la siguiente figura se muestran los diferentes patrones que se pueden encontrar en el gráfico de $e_i$ versus $\hat{\mu}_i$. Para que se cumpla el supuesto de homocedasticidad de los errores se necesita que los puntos se ubiquen como una nube de puntos sin ningún patrón claro. Cualquier patrón que se observe es evidencia de que no se cumple el supuesto de homocedasticidad de los errores.

<p align="center">
  <img src="images/patrones_ei_versus_mui.png" width="450">
</p>

Una analogía útil para recordar si se cumple la homocedasticidad es que el gráfico de $e_i$ versus $\hat{\mu}_i$ tenga una apariencia como la mostrada en la siguiente figura.

<p align="center">
  <img src="images/cielo_estrellado.png" width="450">
</p>

Otro gráfico útil para chequear el supuesto de homocedasticidad es dibujar un diagrama de dispersión de $\sqrt{|d_i|}$ versus $\hat{\mu}_i$, un gráfico similar al mostrado a continuación.

<p align="center">
  <img src="images/di_versus_mui.png" width="450">
</p>

Al igual que en el gráfico de $e_i$ versus $\hat{\mu}_i$, se espera que no existan patrones claros en la nube de puntos.

## Chequeando si errores no están correlacionados {-}
Para estudiar esta situación se debe tener la historia de los errores, es decir, el orden en que las observaciones fueron tomadas. Usando es información se puede dibujar un diagrama de dispersión del residual versus tiempo,  un gráfico similar al mostrado a continuación.

<p align="center">
  <img src="images/res_tiempo.png" width="450">
</p>

En la siguiente figura se muestran los diferentes patrones que se pueden encontrar en el gráfico de $e_i$ versus el tiempo. Para que se cumpla el supuesto de independencia se espera que los puntos se ubiquen como una nube de puntos sin ningún patrón claro.

<p align="center">
  <img src="images/patrones_ei_tiempo.png" width="450">
</p>

### Ejemplo cumpliendo los supuestos {-}
En este ejemplo vamos a simular 500 observaciones del modelo mostrado abajo, luego vamos a ajustar un modelo correcto a los datos y por último vamos a realizar el análisis de residuales para saber si el modelo fue bien ajustado.

\begin{align*} 
y_i &\sim  N(\mu_i, \sigma^2) \\ 
\mu_i &= 4 - 6 x_i \\
x_i &\sim U(-5, 6) \\
\sigma^2 &= 16
\end{align*}

__Solución__

Lo primero que se debe hacer es simular los datos y ajustar el modelo.

```{r}
gen_dat <- function(n) {
  varianza <- 16
  x <- runif(n=n, min=-5, max=6)
  media <- 4 - 6 * x
  y <- rnorm(n=n, mean=media, sd=sqrt(varianza))
  marco_datos <- data.frame(y=y, x=x)
  return(marco_datos)
}

datos <- gen_dat(n=500)
mod <- lm(y ~ x, data=datos)
```

Los gráficos de residuales explicados anteriormente se pueden obtener usando la función `plot` sobre el modelo ajustado `mod`.

```{r resid01, fig.height=6, fig.width=6, fig.align='center'}
par(mfrow=c(2, 2))
plot(mod, las=1, col='darkseagreen3', which=1:3)
```

En la figura anterior se observa que los puntos del gráfico de normalidad de los residuales estandarizados $d_i$ están muy cerca de la línea de referencia. Los diagramas de dispersión entre los residuales versus $\hat{\mu}_i$ no muestran ninguna anomalía. Por estas razones podemos asumir que los supuestos del modelo se cumplen.

Para estar más seguros de la normalidad de los errores vamos a aplicar la prueba [Shapiro-Wilks](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test). En esta prueba se tienen las siguiente hipótesis.

\begin{align}
H_0 &: \text{los residuales tienen distribución normal.} \\ 
H_1 &= \text{los residuales NO tienen distribución normal.}
\end{align}

Para aplicar la prueba podemos usar el siguiente código:

```{r}
ei <- residuals(mod)
shapiro.test(ei)
```

De la salida anterior vemos que el valor-p es mayor que un nivel de significancia del 7 por ciento, eso significa que no hay evidencias para rechazar $H_0$.


```{block2, type='rmdnote'}
En este ejemplo se usó `plot(mod, which=1:3)` para obtener los tres primeros gráficos que entrega la función `plot`, el cuarto gráfico no es un gráfico de residuales y por eso se evitó en el ejemplo.
```

### Ejemplo violando los supuestos {-}
En este ejemplo vamos a simular 500 observaciones del modelo mostrado abajo en el cual modelo la media es función de $x$ y de $x^2$. Luego vamos a ajustar un modelo __incorrecto__ en el cual la media solo dependa de $x$ y por último vamos a construir los gráficos de residuales para ver si se logra identificar el problema.

\begin{align*} 
y_i &\sim  N(\mu_i, \sigma^2) \\ 
\mu_i &= 4 - 6 x_i + 2 x_i^2 \\
x_i &\sim U(-5, 6) \\
\sigma^2 &= 16
\end{align*}

__Solución__

Lo primero que se debe hacer es simular los datos y ajustar el modelo.

```{r}
gen_dat <- function(n) {
  varianza <- 16
  x <- runif(n=n, min=-5, max=6)
  media <- 4 - 6 * x + 2 * x^2
  y <- rnorm(n=n, mean=media, sd=sqrt(varianza))
  marco_datos <- data.frame(y=y, x=x)
  return(marco_datos)
}

datos <- gen_dat(n=500)
mod <- lm(y ~ x, data=datos)
```

Los gráficos de residuales explicados anteriormente se pueden obtener usando la función `plot` sobre el modelo ajustado `mod`.

```{r resid02, fig.height=6, fig.width=6, fig.align='center'}
par(mfrow=c(2, 2))
plot(mod, las=1, col='tomato', which=1:3)
```

De los gráficos anteriores se observa claramente que lo residuales no dicen que algo está mal con el modelo ajustado.

Para estar más seguros de la normalidad de los errores vamos a aplicar la prueba [Shapiro-Wilks](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test). En esta prueba se tienen las siguiente hipótesis.

\begin{align}
H_0 &: \text{los residuales tienen distribución normal.} \\ 
H_1 &= \text{los residuales NO tienen distribución normal.}
\end{align}

Para aplicar la prueba podemos usar el siguiente código:

```{r}
ei <- residuals(mod)
shapiro.test(ei)
```

De la salida anterior vemos que el valor-p es menor que un nivel de significancia del 7 por ciento, eso significa que no hay evidencias para rechazar $H_0$.

### Ejemplo violando los supuestos {-}
En este ejemplo vamos a simular 500 observaciones del modelo mostrado abajo en el cual la varianza de $Y$ es función de $x$. Luego vamos a ajustar un modelo __incorrecto__ en el cual asumimos que la varianza es constante y por último vamos a construir los gráficos de residuales para ver si se logra identificar el problema.

\begin{align*} 
y_i &\sim  N(\mu_i, \sigma^2) \\ 
\mu_i &= 4 - 6 x_i \\
x_i &\sim U(-5, 6) \\
\log(\sigma^2) &= -1 + 0.5 x_i
\end{align*}

__Solución__

Lo primero que se debe hacer es simular los datos y ajustar el modelo.

```{r}
gen_dat <- function(n) {
  x <- runif(n=n, min=-5, max=6)
  media <- 4 - 6 * x
  varianza <- exp(-1 + 0.5 * x)
  y <- rnorm(n=n, mean=media, sd=sqrt(varianza))
  marco_datos <- data.frame(y=y, x=x)
  return(marco_datos)
}

datos <- gen_dat(n=500)
mod <- lm(y ~ x, data=datos)
```

Los gráficos de residuales explicados anteriormente se pueden obtener usando la función `plot` sobre el modelo ajustado `mod`.

```{r resid03, fig.height=6, fig.width=6, fig.align='center'}
par(mfrow=c(2, 2))
plot(mod, las=1, col='purple', which=1:3)
```

De los gráficos anteriores se observa claramente que lo residuales no dicen que algo está mal con el modelo ajustado.

Para estar más seguros de la normalidad de los errores vamos a aplicar la prueba [Shapiro-Wilks](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test). En esta prueba se tienen las siguiente hipótesis.

\begin{align}
H_0 &: \text{los residuales tienen distribución normal.} \\ 
H_1 &= \text{los residuales NO tienen distribución normal.}
\end{align}

Para aplicar la prueba podemos usar el siguiente código:

```{r}
ei <- residuals(mod)
shapiro.test(ei)
```

De la salida anterior vemos que el valor-p es menor que un nivel de significancia del 7 por ciento, eso significa que no hay evidencias para rechazar $H_0$.


## Gráficos de residuales usando car {-}
El paquete **car** de @R-car, tiene unas funciones especiales para crear otro tipo de gráficos de residuales y que son útiles para identificar posibles anomalías en el modelo ajustado. A continuación las funciones para crear nuevos gráficos de residuales.

- `residualPlots(model)`: dibuja una gráfica de los residuos de Pearson versus cada término del predictor lineal y los valores ajustados $\hat{\mu}_i$. También entrega los resultados de una prueba de hipótesis para saber si se debe agregar un término cuadrático de cada variable. 
- `mmps` o `marginalModelPlots(model)`: dibuja una gráfica de la respuesta $y_i$ versus cada covariable cuantitativa y los valores ajustados $\hat{\mu}_i$, es una variación la propuesta de @cook_weisber97.


### Ejemplo {-}
Este ejemplo corresponde al ejemplo mostrado en el capítulo 6 de @fox2019.

En este ejemplo se desea ajustar un modelo de regresión para explicar la media de la variable prestige en función de las variables education, income y type, usando la base de datos `Prestige` del paquete **car** [@R-car].

<p align="center">
  <img src="images/canadian.jpg" width="250">
</p>

```{r message=FALSE}
library(car)
prestige_mod1 <- lm(prestige ~ education + income + type, data=Prestige)
```

Para construir los gráficos de los residuos de Pearson versus cada término del predictor lineal y los valores ajustados $\hat{\mu}_i$ se usa la siguiente instrucción (`las=1` para poner los números vertical en el eje Y).

```{r resid_car01, fig.height=6, fig.width=6, fig.align='center'}
residualPlots(prestige_mod1, las=1)
```

De la figura anterior se observa lo siguiente:

- El gráfico de residuales vs education se asemeja a un "gráfico nulo", en la que ningún patrón particular es aparente.
- El gráfico de residuales vs income presenta una curvatura.
- El gráfico de residuales vs type (var. cuali.) presenta una apariencia de un "gráfico nulo", todas las cajas con a proximadamente el mismo centro y extensión.
- De los tres comentarios anteriores parece que falta el término $Income^2$ en el predictor lineal.

La sospecha de que falta el término $Income^2$ se ve reforzada por la tabla que acompaña la salida de `residualPlots(prestige_mod)`. En la línea para la variable `income` se tiene la prueba de hipótesis:

- $H_0:$ no se necesita $Income^2$,
- $H_A:$ si se necesita $Income^2$. 

El valor-P de esta prueba es 0.004854 y por lo tanto se justifica incluir $Income^2$.

Para dibujar los gráficos marginales de $y_i$ versus cada covariable cuantitativa y los valores ajustados $\hat{\mu}_i$ se usa la siguiente instrucción.

```{r resid_car02, fig.height=6, fig.width=6, fig.align='center'}
marginalModelPlots(prestige_mod1, las=1)
```

La línea de color azul es una regresión lowess entre $y_i$ y la variable que está en el eje horizontal. La línea de color rojo es una regresión lowess entre $\hat{\mu}_i$ y la variable que está en el eje horizontal. Según @fox2019, si el modelo se ajusta bien a los datos, las líneas (azul y roja) estarán próximas, por el contrario, si las líneas difieren demasiado, es evidencia de que el modelo no explica bien los datos.

De la figura anterior se observa que las líneas (azul y roja) difieren un poco en el panel de $y_i$ versus income, eso refuerza lo observado antes de que sería bueno agregar un término `I(income^2)`.

```{r}
prestige_mod2 <- lm (prestige ~ education + income + I(income^2) + type, data=Prestige)
```

```{r resid_car03, fig.height=8, fig.width=6, fig.align='center'}
residualPlots(prestige_mod2, las=1)
```

```{r}
anova(prestige_mod1, prestige_mod2)
```

## Prueba de falta de ajuste {-}

Para el caso de la RLS, se quiere probar:

$$
\begin{aligned}
\begin{cases}
H_0:\ E(Y_i) = E(Y\vert X_i) = \beta_0 + \beta_1 X_i\\ \\ 
H_1:\ E(Y_i) = E(Y\vert X_i) \neq \beta_0 + \beta_1 X_i
\end{cases}
\end{aligned}
$$

Para aplicar esta prueba construye la tabla anova de la siguiente manera:

\begin{tabular}{lcccc}
Fuente de & Suma de & Grados de & Cuadrado & $F$  \\ 
Variación & Cuadrados &  Libertad  & Medio & Calculado   \\\hline \\ 
Regresión & $SSR$ & 1 & $MSR=\frac{SSR}{1}=SSR$ & $F_0=\frac{MSR}{MSE}$ \\ \\ Error & SSE & $n-2$ & $MSE=\frac{SSE}{n-2}$ & \\\hline \\ 
Falta de Ajuste&  $SSLOF$ & $m-2$ & $MSLOF=\frac{SSLOF}{m-2}$ & $F_0=\frac{MSLOF}{MSPE}$ \\ \\ 
Error Puro & $SSPE$ & $n-m$ & $MSPE=\frac{SSPE}{n-m}$ & \\\hline \\ 
Total & $SST$ & $n-1$ & & 
\end{tabular}

Bajo la hipótesis nula ${H_0:\ E(Y_i) = \beta_0 + \beta_1x_i}$, el estadístico se distribuye como una $F$ con $(m - 2)$ y $(n - m)$ grados de libertad. Así, a un nivel de significancia ${\alpha}$ **se rechaza la hipótesis nula de que el modelo lineal es adecuado** (en favor de la hipótesis de que el modelo lineal tiene falta de ajuste) si ${F_0 > F_{\alpha, m - 2, n - m}}$.

### Ejemplo 1 {-}
Suponga que se tienen los siguientes datos.

```{r}
# Example for section 4.5 Montgomery, Peck & Vining (2006)
x <- c(1.0, 1.0, 2.0, 3.3, 3.3, 4.0, 4.0, 4.0, 4.7, 5.0,
       5.6, 5.6, 5.6, 6.0, 6.0, 6.5, 6.9)

y <- c(10.84, 9.30, 16.35, 22.88, 24.35, 24.56, 25.86,
       29.16, 24.59, 22.25, 25.90, 27.20, 25.61, 25.45,
       26.56, 21.03, 21.46)
```

¿Es el modelo de regresión lineal simple apropiado para explicar $Y$ en función de $X$?

__Solución__

Primero exploremos la relación entre las variables.

```{r lof01, fig.height=6, fig.width=6, fig.align='center'}
plot(x=x, y=y, pch=20, cex=2, col="red")
```

Luego vamos a ajustar el modelo.

```{r}
mod <- lm(y ~ x)
```

Luego construimos la tabla anova por medio de la función `lack_fit_test` del paquete **model**. Para instalar el paquete **model** propuesto por @R-model podemos usar el siguiente código.

```{r eval=FALSE}
if (!require("remotes")) install.packages("remotes")
remotes::install_github("fhernanb/model")
```

Luego de esto ya podemos usar la función `lack_fit_test`.

```{r}
library(model)
lack_fit_test(mod)
```

De la salida anterior tenemos un valor-P de 0.001389 con lo cual podemos decir que hay evidencias para rechazar $H_0$.

```{r lof02, fig.height=6, fig.width=6, fig.align='center'}
plot(x=x, y=y, pch=20, cex=2, col="red")
abline(mod, lty="dashed", col="blue", lwd=2)
```

### Ejemplo 2 {-}
Suponga que se tienen los siguientes datos.

```{r}
# Example 9.6 Montgomery & Runger (1996)
x <- c(1.0, 1.0, 2.0, 3.3, 3.3, 4.0, 4.0, 4.0, 5.0,
       5.6, 5.6, 5.6, 6.0, 6.0, 6.5, 6.9)

y <- c(2.3, 1.8, 2.8, 1.8, 3.7, 2.6, 2.6, 2.2, 2.0, 3.5,
       2.8, 2.1, 3.4, 3.2, 3.4, 5.0)
```

¿Es el modelo de regresión lineal simple apropiado para explicar $Y$ en función de $X$?

__Solución__

Primero exploremos la relación entre las variables.

```{r lof03, fig.height=6, fig.width=6, fig.align='center'}
plot(x=x, y=y, pch=20, cex=2, col="chartreuse3")
```

Luego vamos a ajustar el modelo.

```{r}
mod <- lm(y ~ x)
```

Luego construimos la tabla anova por medio de la función `lack_fit_test` del paquete **model**. Para instalar el paquete **model** podemos usar el siguiente código.

```{r eval=FALSE}
if (!require("remotes")) install.packages("remotes")
remotes::install_github("fhernanb/model")
```

Luego de esto ya podemos usar la función `lack_fit_test`.

```{r}
library(model)
lack_fit_test(mod)
```

De la salida anterior tenemos un valor-P de 0.32882 con lo cual podemos decir que NO hay evidencias para rechazar $H_0$.

```{r lof04, fig.height=6, fig.width=6, fig.align='center'}
plot(x=x, y=y, pch=20, cex=2, col="chartreuse3")
abline(mod, lty="dashed", col="mediumpurple2", lwd=2)
```
