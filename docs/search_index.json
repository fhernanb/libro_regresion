[
["index.html", "Modelos de Regresión con R Bienvenido Estructura del libro Software y convenciones Bloques informativos", " Modelos de Regresión con R Freddy Hernández Mauricio Mazo 2020-05-14 Bienvenido Este libro está destinado para estudiantes de ingeniería y estadística que deseen aprender sobre modelos de regresión y la forma de aplicarlos por medio del lenguaje de programación R. Freddy Hernández Mauricio Mazo Estructura del libro En el capítulo 1 se presenta el modelo de regresión lineal simple y en el Capítulo 2 se generaliza el modelo básico con varias covariables. En los capítulos 5 y 6 se muestra como construir intervalos de confianza y como realizar pruebas de hipótesis, respectivamente. Software y convenciones Para realizar este libro usamos los paquetes knitr (Xie 2015) y bookdown (Xie 2020) que permiten unir la ventajas de LaTeX y R en un mismo archivo. En todo el libro se presentarán códigos que el lector puede copiar y pegar en su consola de R para obtener los mismos resultados aquí del libro. Los códigos se destacan en una caja de color similar a la mostrada a continuación. 4 + 6 a &lt;- c(1, 5, 6) 5 * a 1:10 Los resultados o salidas obtenidos de cualquier código se destacan con dos símbolos de númeral (##) al inicio de cada línea o renglón, esto quiere decir que todo lo que inicie con ## son resultados obtenidos y NO los debe copiar. Abajo se muestran los resultados obtenidos luego de correr el código anterior. ## [1] 10 ## [1] 5 25 30 ## [1] 1 2 3 4 5 6 7 8 9 10 Bloques informativos En varias partes del libro usaremos bloques informativos para resaltar algún aspecto importante. Abajo se encuentra un ejemplo de los bloques y su significado. Nota aclaratoria. Sugerencia. Advertencia. References "],
["rls.html", "1 Regresión lineal simple Modelo estadístico Función lm Clase lm Apéndice", " 1 Regresión lineal simple En este capítulo se presenta una descripción breve del modelo de regresión lineal simple y la forma de estimar los parámetros del modelo con R. Modelo estadístico El modelo estadístico en regresión lineal simple se puede escribir de dos formas como se muestra a continuación. En esta forma la variable respuesta \\(y\\) se expresa como una suma de \\(\\beta_0 + \\beta_1 x_i\\) y un error aleatorio \\(e_i\\) el cual tiene distribución \\(N(0, \\sigma^2)\\). El modelo en esta forma se puede expresar como sigue. \\[\\begin{align} \\label{mod1} Y_i &amp;= \\beta_0 + \\beta_1X_i + e_i,\\\\ e_i &amp;\\sim N(0, \\sigma^2) \\end{align}\\] En esta forma la variable respuesta \\(y\\) tiene distribución normal con media que cambia en función de la variable \\(x\\) pero con varianza constante. El modelo en esta forma se puede expresar como sigue. \\[\\begin{align} \\label{mod2} Y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 X_i, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] En cualquiera de las dos formas el vector de parámetros del modelo es \\(\\boldsymbol{\\theta}=(\\beta_0, \\beta_1, \\sigma)^\\top\\). Para estimar este vector de parámetros se suelen utilizar dos métodos: mínimos cuadrados o máxima verosimilitud. La siguiente figura es tomada del libro (Kutner et al. 2005) muestra con claridad el supuesto de normalidad de la variable \\(Y\\), la dependencia de la media \\(\\mu\\) con \\(X\\) y la varianza constante. En la siguiente figura se muestran dos ilustraciones para donde los supuestos no se cumplen. Función lm La función lm de R se usa para ajustar un modelo de regresión lineal simple, la estructura de esta función se muestra a continuación. lm(formula, data, subset, weights, na.action, method = &quot;qr&quot;, model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, contrasts = NULL, offset, ...) A continuación se presenta una corta descripción de los parámetros más usados en la función. formula: es un objeto de la clase fórmula para indicar la variable respuesta y las covariables. Por ejemplo, si formula = y ~ x1 + x2 lo que se indica es que la variable respuesta es y, las covariables serían x1 y x2. data: es el marco de datos donde se buscarán las variables usadas en la fórmula. Si este parámetro queda vacío, R buscará las variables en el ambiente global. Ejemplo Como ilustración vamos a usar los datos del ejemplo 2.1 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 2.1 los autores desean ajustar un modelo de regresión lineal simple para explicar la Resistencia de una soldadura en función de la Edad de la soldadura. Solución A continuación el código para cargar los datos y para mostrar las 6 primeras observaciones de la base de datos, en total tenemos 20 observaciones. file &lt;- &quot;https://raw.githubusercontent.com/fhernanb/datos/master/propelente&quot; datos &lt;- read.table(file=file, header=TRUE) head(datos) # shows the first 6 rows ## Resistencia Edad ## 1 2158.70 15.50 ## 2 1678.15 23.75 ## 3 2316.00 8.00 ## 4 2061.30 17.00 ## 5 2207.50 5.50 ## 6 1708.30 19.00 Para crear un diagrama de dispersión que nos muestre la relación entre las dos variables usamos las siguientes instrucciones. library(ggplot2) ggplot(datos, aes(x=Edad, y=Resistencia)) + geom_point() + theme_light() De la figura anterior se ve claramente que a medida que aumenta la edad de la soldadura, la resistencia que ella ofrece disminuye. Adicionalmente, se observa que la relación entre las variables es lineal con una dispersión que parece constante. El modelo que se va a ajustar se muestra a continuación. \\[\\begin{align} Resistencia_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 Edad_i, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] Para obtener las estimaciones de los parámetros del modelo anterior se usa el código mostrado abajo. La función lm se aplica con la fórmula Resistencia ~ Edad para indicar que Resistencia es la variable respuesta y que Edad es la variable explicativa. Los resultados del la función lm se almacenan en el objeto mod1 para luego poder usar el modelo ajustado. La segunda línea del código mostrado abajo se usa para mostrar por pantalla un reporte sencillo del modelo ajustado. mod1 &lt;- lm(Resistencia ~ Edad, data=datos) mod1 # Para imprimir el objeto mod1 ## ## Call: ## lm(formula = Resistencia ~ Edad, data = datos) ## ## Coefficients: ## (Intercept) Edad ## 2627.82 -37.15 En la salida anterior se observan los valores estimados de \\(\\beta_0\\) y \\(\\beta_1\\) pero no aparece la estimación de \\(\\sigma\\). Para obtener una tabla de resumen con detalles del modelo ajustado, se usa la función genérica summary, a continuación el código necesario para obtener la tabla. summary(mod1) La siguiente figura muestra el resultado del código anterior. En la figura se resalta la información sobre los residuales y las estimaciones de \\(\\beta_0\\), \\(\\beta_1\\) y \\(\\sigma\\). Figure 1.1: Tabla de resumen para un modelo lineal. Con los resultados anteriores se puede expresar el modelo ajustado como se muestra a continuación. \\[\\begin{align} \\widehat{Resistencia}_i &amp;\\sim N(\\hat{\\mu}_i, \\hat{\\sigma}^2), \\\\ \\hat{\\mu}_i &amp;= 2627.822 -37.154 \\, Edad_i, \\\\ \\hat{\\sigma} &amp;= 96.11 \\end{align}\\] ¿Cómo se pueden interpretar los efectos \\(\\hat{\\beta}\\)? Por cada semana que envejezca la soldadura, se espera que la resistencia promedio disminuya en 37.154 psi. Si la soldadura es nueva (\\(Edad =0\\)), se espera que la resistencia promedio sea de 2627.822 psi. Para incluir la recta de regresión que representa el modelo ajustado anterior se puede usar el siguiente código. ggplot(datos, aes(x=Edad, y=Resistencia)) + geom_point() + geom_smooth(method=&#39;lm&#39;, formula=y~x, se=FALSE, col=&#39;dodgerblue1&#39;) + theme_light() Clase lm Todo objeto creado con la función lm( ) es de la clase lm, para verificar esto podemos escribir lo siguiente en la consola. class(mod1) ## [1] &quot;lm&quot; Dentro de todo objeto de la clase lm hay doce elementos o valores que se pueden utilizar. A continuación se muestra el código para saber los nombres de esos elementos. names(mod1) ## [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; &quot;rank&quot; ## [5] &quot;fitted.values&quot; &quot;assign&quot; &quot;qr&quot; &quot;df.residual&quot; ## [9] &quot;xlevels&quot; &quot;call&quot; &quot;terms&quot; &quot;model&quot; Cualquiera de los anteriores elementos se pueden extraer usando el operador $ entre el objeto y el elemento, por ejemplo, para extraer los coeficientes estimados se escribe lo siguiente: mod1$coefficients ## (Intercept) Edad ## 2627.82236 -37.15359 Los nombres de los elementos dan una idea clara de lo que ellos almacenan, si el lector quiere más detalles sobre los elementos, sólo debe solicitar la ayuda de la función con help(lm) y en la sección de Value encontrará la información. En el siguiente código se utiliza para extraer el elemento $fitted.value que contiene los valores predichos o ajustados \\(\\hat{y}_i\\). mod1$fitted.values ## 1 2 3 4 5 6 7 8 ## 2051.942 1745.425 2330.594 1996.211 2423.478 1921.904 1736.136 2534.938 ## 9 10 11 12 13 14 15 16 ## 2349.170 2219.133 2144.826 2488.496 1698.983 2265.575 1810.443 1959.058 ## 17 18 19 20 ## 2404.901 2163.402 2553.515 1829.020 A continuación se muestra el código para extraer el elemento $residuals que contiene los residuales usuales \\(\\widehat{e}_i= Y_i - \\widehat{Y}_i\\). mod1$residuals ## 1 2 3 4 5 6 ## 106.758301 -67.274574 -14.593631 65.088687 -215.977609 -213.604131 ## 7 8 9 10 11 12 ## 48.563824 40.061618 8.729573 37.567141 20.374323 -88.946393 ## 13 14 15 16 17 18 ## 80.817415 71.175153 -45.143358 94.442278 9.499187 37.097528 ## 19 20 ## 100.684823 -75.320154 Los valores ajustados y los residuales también se pueden recuperar usando las funciones fitted( ) y residuals( ). Consulte la ayuda de estas funciones para conocer otros detalles. Ejemplo Aquí se retoma el ejemplo de Resistencia en función de la Edad. El objetivo es crear una diagrama de dispersión con los puntos originales \\((X_i, Y_i)\\), las estimaciones \\(\\widehat{Y}_i\\) y los residuales \\(\\widehat{e}_i\\). Lo primero que se debe hacer es agregar a los datos originales el vector con las estimaciones \\(\\hat{y}_i\\), el código necesario se muestra a continuación. datos$predicciones &lt;- predict(mod1) En el diagrama dispersión los puntos originales \\((X_i, Y_i)\\) estarán en color negro y los puntos correspondientes a las estimaciones \\((X_i, \\hat{Y}_i)\\) estarán en color rojo, estos últimos coincidirán con la recta estimada en color gris. Los residuales \\(e_i\\) se mostrarán como líneas a trazos de color rojo. El código necesario se muestra a continuación. ggplot(datos, aes(x=Edad, y=Resistencia)) + geom_smooth(method=&quot;lm&quot;, se=FALSE, color=&quot;lightgrey&quot;) + geom_segment(aes(xend=Edad, yend=predicciones), col=&#39;red&#39;, lty=&#39;dashed&#39;) + geom_point() + geom_point(aes(y=predicciones), col=&#39;red&#39;) + theme_light() ## `geom_smooth()` using formula &#39;y ~ x&#39; Apéndice 1.0.1 Estimación por mínimos cuadrados Para estimar \\(\\beta_0\\) y \\(\\beta_1\\) utilizamos el método de mínimos cuadrados ordinarios, minimizando la suma cuadrática del error: \\[\\begin{eqnarray*} S(\\beta_0, \\beta_1)&amp;=&amp;\\sum_{i=1}^ne_i^2\\\\ &amp;=&amp;\\sum_{i=1}^n(Y_i-\\beta_0-\\beta_1X_i)^2 \\end{eqnarray*}\\] Derivando e igualando a cero, es decir, \\[\\frac{\\partial S(\\beta_0, \\beta_1)}{\\partial \\beta_0}=0\\] \\[\\frac{\\partial S(\\beta_0, \\beta_1)}{\\partial \\beta_1}=0\\] obtenemos que los estimadores para \\(\\beta_0\\) y \\(\\beta_1\\) están dados por \\[\\widehat{\\beta}_0=\\overline{Y}-\\widehat{\\beta}_1\\overline{X}\\quad \\text{y}\\quad \\widehat{\\beta}_1=\\frac{S_{xy}}{S_{xx}}\\] donde \\(S_{xx}=\\sum_{i=1}^n(X_i-\\overline{X})^2\\) &amp; \\(S_{yy}=\\sum_{i=1}^n(Y_i-\\overline{Y})^2\\) &amp; \\(S_{xy}=S_{yx}=\\sum_{i=1}^n(X_i-\\overline{X})(Y_i-\\overline{Y})\\) \\ 1.0.2 Estimación por máxima verosimilitud Sabemos que para nuestro modelo de regresión lineal simple, \\[Y_i\\sim N\\left(\\beta_0+\\beta_1X_i, \\sigma^2\\right),\\quad \\text{para todo $i=1, 2, \\ldots, n$}.\\] Y como los errores \\(e_1, e_2, \\ldots, e_n\\) son independientes, entonces \\(Y_1, Y_2, \\ldots, Y_n\\) también son independientes. Así, la función de verosimilitud estaría dada por: \\[\\begin{eqnarray*} L\\left(\\beta_0, \\beta_1, \\sigma^2 | X_1, \\ldots, X_n, Y_1, \\ldots, Y_n \\right)&amp;=&amp;\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(Y_i-\\beta_0-\\beta_1X_i)^2\\right\\}\\\\ &amp;=&amp;\\frac{1}{(2\\pi\\sigma^2)^{n/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(Y_i-\\beta_0-\\beta_1X_i)^2\\right\\} \\end{eqnarray*}\\] Tomando logaritmo natural a ambos lados y denotando la log-verosimilitud por \\[\\ln \\left[L\\left(\\beta_0, \\beta_1, \\sigma^2 | X_1, \\ldots, X_n, Y_1, \\ldots, Y_n \\right)\\right]=l\\left(\\beta_0, \\beta_1, \\sigma^2 | X_1, \\ldots, X_n, Y_1, \\ldots, Y_n \\right),\\] tenemos que \\[\\begin{eqnarray*} l\\left(\\beta_0, \\beta_1, \\sigma^2 | X_1, \\ldots, X_n, Y_1, \\ldots, Y_n \\right) &amp;=&amp;-\\left(\\frac{n}{2}\\right)\\ln(2\\pi)-\\left(\\frac{n}{2}\\right)\\ln\\left(\\sigma^2\\right)-\\left(\\frac{1}{2\\sigma^2}\\right)\\sum_{i=1}^n(Y_i-\\beta_0-\\beta_1X_i)^2 \\end{eqnarray*}\\] Derivando parcialmente con respecto a \\(\\beta_0\\), \\(\\beta_1\\) y \\(\\sigma^2\\) e igualando a cero, obtenemos los estimadores de máxima verosimilitud: \\[\\widetilde{\\beta}_0=\\overline{Y}-\\widetilde{\\beta}_1\\overline{X}\\] \\[\\widetilde{\\beta}_1=\\frac{S_{xy}}{S_{xx}}\\] \\[\\widetilde{\\sigma}^2=\\frac{\\sum_{i=1}^n(Y_i-\\widetilde{\\beta}_0-\\widetilde{\\beta}_1X_i)^2}{n}.\\] Los estimadores de máxima verosimilitud para regresión lineal simple, pueden ser obtenidos mediante la optimización directa de la función de log-verosimilitud. References "],
["rlm.html", "2 Regresión lineal múltiple Modelo estadístico", " 2 Regresión lineal múltiple En este capítulo se presenta una descripción breve del modelo de regresión lineal múltiple y la forma de estimar los parámetros del modelo con R. Modelo estadístico El modelo estadístico en regresión lineal múltiple es una generalización del regresión lineal simple para \\(k\\) covariables. El modelo en este caso se puede escribir de dos formas como se muestra a continuación. En esta forma la variable respuesta \\(y\\) se expresa como una suma de \\(\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_k x_{ki}\\) y un error aleatorio \\(e_i\\) el cual tiene distribución \\(N(0, \\sigma^2)\\). El modelo en esta forma se puede expresar como sigue. \\[\\begin{align} \\label{mod1} y_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_k x_{ki} + e_i, \\\\ e_i &amp;\\sim N(0, \\sigma^2) \\end{align}\\] En esta forma la variable respuesta \\(y\\) tiene distribución normal con media que cambia en función de las variables \\(x_k\\) pero con varianza constante. El modelo en esta forma se puede expresar como sigue. \\[\\begin{align} \\label{mod2} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_k x_{ki}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] En cualquiera de las dos formas el vector de parámetros del modelo es \\(\\boldsymbol{\\theta}=(\\beta_0, \\beta_1, \\cdots, \\beta_k, \\sigma)^\\top\\). Ejemplo Como ilustración vamos a usar los datos del ejemplo 3.1 del libro de (Montgomery 2006). En el ejemplo 3.1 los autores ajustaron un modelo de regresión lineal múltiple para explicar el Tiempo necesario para que un trabajador haga el mantenimiento y surta una máquina dispensadora de refrescos en función de las variables Número de Cajas y Distancia. Los datos del ejemplo están disponibles en el paquete MPV (por los apellidos de los autores). A continuación el código para cargar los datos y una muestra de las 6 primeras observaciones de la base de datos, en total se disponen de 20 observaciones. require(MPV) colnames(softdrink) &lt;- c(&#39;tiempo&#39;, &#39;cantidad&#39;, &#39;distancia&#39;) head(softdrink) ## tiempo cantidad distancia ## 1 16.68 7 560 ## 2 11.50 3 220 ## 3 12.03 3 340 ## 4 14.88 4 80 ## 5 13.75 6 150 ## 6 18.11 7 330 Un gráfico en 3d es obligratorio para explorar la relación entre las variables, este diagrama de puede obtener usando el paquete scatterplot3d. A continuación el código para construirlo. library(scatterplot3d) attach(softdrink) scatterplot3d(x=cantidad, y=distancia, z=tiempo, pch=16, cex.lab=1, highlight.3d=TRUE, type=&quot;h&quot;, xlab=&#39;Cantidad de cajas&#39;, ylab=&#39;Distancia (pies)&#39;, zlab=&#39;Tiempo (min)&#39;) De la figura anterior se ve claramente que a medida que aumenta el número de cajas y la distancia los tiempos tienden a ser mayores. El mismo diagrama de dispersión anterior se puede crear usando el paquete plotly. El lector puede jugar con el diagrama, puede moverlo, girarlo, acercarse y muchas cosas más, la curiosidad le mostrará las diferentes posibilidades. library(plotly) plot_ly(x=cantidad, y=distancia, z=tiempo, type=&quot;scatter3d&quot;, color=tiempo) %&gt;% layout(scene = list(xaxis = list(title = &#39;Cantidad&#39;), yaxis = list(title = &#39;Distancia (pies)&#39;), zaxis = list(title = &#39;Tiempo (min)&#39;))) Otro gráfico de dispersión en 3d se puede construir usando el paquete rgl. A continuación está el código para obtener el diagrama de dispersión. De tarea se deja que el lector copie el código en la consola y reconstruya el gráfico. library(rgl) plot3d(x=cantidad, y=distancia, z=tiempo, type=&#39;s&#39;, col=&#39;pink&#39;, xlab=&#39;Cantidad&#39;, ylab=&#39;Distancia (pies)&#39;, zlab=&#39;Tiempo (min)&#39;) Basándonos en el diagrama de dispersión 3d, el modelo que se va a ajustar se muestra a continuación. \\[\\begin{align} Tiempo_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 Cantidad_i + \\beta_2 Distancia_i, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] mod &lt;- lm(tiempo ~ cantidad + distancia, data=softdrink) summary(mod) ## ## Call: ## lm(formula = tiempo ~ cantidad + distancia, data = softdrink) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7880 -0.6629 0.4364 1.1566 7.4197 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.341231 1.096730 2.135 0.044170 * ## cantidad 1.615907 0.170735 9.464 3.25e-09 *** ## distancia 0.014385 0.003613 3.981 0.000631 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.259 on 22 degrees of freedom ## Multiple R-squared: 0.9596, Adjusted R-squared: 0.9559 ## F-statistic: 261.2 on 2 and 22 DF, p-value: 4.687e-16 Con los resultados anteriores se puede expresar el modelo ajustado como se muestra a continuación. \\[\\begin{align} \\widehat{Tiempo}_i &amp;\\sim N(\\hat{\\mu}_i, \\hat{\\sigma}^2), \\\\ \\hat{\\mu}_i &amp;= 2.341 + 1.616 \\, Cantidad_i + 0.014 \\, Distancia_i, \\\\ \\hat{\\sigma} &amp;= 3.259 \\end{align}\\] ¿Cómo se pueden interpretar los efectos \\(\\hat{\\beta}\\)? Si el camión queda un pie más lejos (30.48 cm) de la máquina, se espera que el tiempo promedio de mantenimineto aumente en 0.014 minutos. Si el camión queda 100 pies más lejos (30.48 mt) de la máquina, se espera que el tiempo promedio de mantenimiento aumente en 14 minutos. Por cada caja adicional de refresco que se deba llevar, se espera que el tiempo promedio aumente en 1.616 minutos. Si el camión quedó a 0 pies de distancia y no hay que llevar cajas de refresco, se espera que el tiempo promedio de mantenimiento sea de 2.341 minutos. La interpretación de cada \\(\\hat{\\beta}\\) se hace suponiendo que las demás variables quedan constantes en algún valor. Para incluir el plano de regresión que representa el modelo ajustado anterior se puede usar el siguiente código. # Se crea el grafico 3d y se guarda en un objeto, por ejemplo mi_3d mi_3d &lt;- scatterplot3d(x=cantidad, y=distancia, z=tiempo, pch=16, cex.lab=1, highlight.3d=TRUE, type=&quot;h&quot;, xlab=&#39;Cantidad de cajas&#39;, ylab=&#39;Distancia (pies)&#39;, zlab=&#39;Tiempo (min)&#39;) # Para agregar el plano usamos $plane3d( ) con argumento modelo ajustado mi_3d$plane3d(mod, lty.box=&quot;solid&quot;, col=&#39;mediumblue&#39;) References "],
["predict.html", "3 Predicción Función predict Intervalo de confianza para la respuesta media \\(E(y|x_0)\\) Intervalo de confianza para la predicción de nuevas observaciones", " 3 Predicción En este capítulo se presenta una descripción breve de como realizar predicciones a partir de un modelo de regresión lineal. Función predict La función predict es una función genérica de clase S3 que se puede aplicar a un modelo ajustado para obtener los valores de \\(\\hat{y}\\). Abajo se muestra la estructura de la función predict con la lista de sus argumentos. predict.lm(object, newdata, se.fit = FALSE, scale = NULL, df = Inf, interval = c(&quot;none&quot;, &quot;confidence&quot;, &quot;prediction&quot;), level = 0.95, type = c(&quot;response&quot;, &quot;terms&quot;), terms = NULL, na.action = na.pass, pred.var = res.var/weights, weights = 1, ...) Ejemplo Suponga que queremos ajustar un modelo de regresión para explicar el número de trabajadores empleados (Employed) en función de las covariables Unemployed, Armed.Forces y Year del conjunto de datos longley. Luego de ajustar el modelo queremos predecir el valor de \\(E(Employed|x=x_0)\\) en dos situaciones: Año 1963 con 420 desempleados y 270 personas en fuerzas armadas. Año 1964 con 430 desempleados y 250 personas en fuerzas armadas. Solución Lo primero que se debe hacer es ajustar el modelo así. mod &lt;- lm(Employed ~ Unemployed + Armed.Forces + Year, data=longley) library(broom) tidy(mod, quick=TRUE) ## # A tibble: 4 x 2 ## term estimate ## &lt;chr&gt; &lt;dbl&gt; ## 1 (Intercept) -1797. ## 2 Unemployed -0.0147 ## 3 Armed.Forces -0.00772 ## 4 Year 0.956 De la tabla anterior tenemos que el modelo ajustado es el siguiente: \\[ \\widehat{\\text{Employed}} = -1797.22 - 0.01(\\text{Unemployed}) - 0.01(\\text{Armed.Forces}) + 0.96(\\text{Year}) + \\epsilon \\] Podríamos usar la expresión anterior y reemplazar los valores de año, desempleados y personas en fuerzas armadas, dadas arriba, para calcular \\(E(Employed|x=x_0)\\). Sin embargo, aquí lo vamos a realizar usando la función predict. Lo segundo que debemos hacer es construir un nuevo marco de datos con la información de las covariables, usando los mismos nombres y los mismos tipos de variables (cuali o cuanti) que en el conjunto de datos con el cual se entrenó el modelo. nuevo &lt;- data.frame(Year=c(1963, 1964), Unemployed=c(420, 430), Armed.Forces=c(270, 250)) nuevo ## Year Unemployed Armed.Forces ## 1 1963 420 270 ## 2 1964 430 250 Ahora ya podemos usar la función predict para obtener lo solicitado. predict(object=mod, newdata=nuevo) ## 1 2 ## 71.89467 72.85853 De la salida anterior tenemos los valores de \\(\\widehat{Employed}\\). ¿Qué sucede si en el nuevo marco de datos anterior las variables se llaman diferente a las variables conjunto de datos de entrenamiento? Error, nos sale un error. No se le ocurra usar nombres diferentes. Intervalo de confianza para la respuesta media \\(E(y|x_0)\\) En regresión lineal simple, Si \\(\\hat{\\mu}_{y|x_0}\\) es la media estimada para la variable respuesta cuando \\(x=x_0\\), entonces un IC del \\((1−\\alpha⁄2)\\)×100% para \\(E(y|x_0)\\)_0) está dado por: \\[ \\hat{\\mu}_{y|x_0} \\pm t_{\\alpha / 2, n - 2} \\, \\sqrt{MSE \\left(\\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{\\sum(x_i - \\bar{x}^2)} \\right)} \\] Intervalo de confianza para la predicción de nuevas observaciones En regresión lineal simple, Si \\(\\hat{y}_0\\) es el valor estimado para la variable respuesta cuando \\(x=x_0\\), entonces un IC del \\((1−\\alpha⁄2)\\)×100% para \\(y_0\\)está dado por: \\[ \\hat{y}_0 \\pm t_{\\alpha / 2, n - 2} \\, \\sqrt{MSE \\left(1 +\\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{\\sum(x_i - \\bar{x}^2)} \\right)} \\] Ejemplo Como ilustración vamos a usar los datos del ejemplo 2.1 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 2.1 los autores ajustan un modelo de regresión lineal simple para explicar la Resistencia de una soldadura en función de la Edad de la soldadura. El objetivo es obtener: IC del 95% para \\(E(y|x_0)\\) cuando \\(x_0=\\overline{Edad}=13.3625\\) semanas. IC del 95% para \\(\\hat{y}_0\\) cuando \\(x_0=10\\) semanas. Crear el histograma de dispersión agregando las líneas de los IC para \\(E(y|x_0)\\) y \\(\\hat{y}_0\\). Solución Lo primero es disponer los datos. file &lt;- &quot;https://raw.githubusercontent.com/fhernanb/datos/master/propelente&quot; datos &lt;- read.table(file=file, header=TRUE) Luego se ajusta el modelo. mod1 &lt;- lm(Resistencia ~ Edad, data=datos) Para obtener el IC del 95% para \\(E(y|x_0)\\) cuando \\(x_0=\\overline{Edad}=13.3625\\) semanas se usa el siguiente código. nuevo &lt;- data.frame(Edad=13.3625) predict(object=mod1, newdata=nuevo, interval=&quot;confidence&quot;, level=0.95) ## fit lwr upr ## 1 2131.357 2086.209 2176.506 Para obtener el IC del 95% para \\(\\hat{y}_0\\) cuando \\(x_0=10\\) semanas se usa el siguiente código. nuevo &lt;- data.frame(Edad=10) predict(object=mod1, newdata=nuevo, interval=&quot;prediction&quot;, level=0.95) ## fit lwr upr ## 1 2256.286 2048.385 2464.188 Observe que en el primer caso se usó interval=\"confidence\" mientras que en el segundo se usó interval=\"prediction\". Ahora vamos a obtener todos los IC \\(\\hat{y}_0\\) y los vamos a almacenar en el objeto future_y que luego luego vamos a agregar al marco de datos original. future_y &lt;- predict(object=mod1, interval=&quot;prediction&quot;, level=0.95) nuevos_datos &lt;- cbind(datos, future_y) Con el código mostrado a continuación se construye el diagrama de dispersión y se agrega la línea de regresión (en azul) y los IC para \\(E(y|x_0)\\) (en rosado) por medio de geom_smooth. Los IC para \\(\\hat{y}_0\\) (en rojo) se agregan por medio de geom_line. library(ggplot2) ggplot(nuevos_datos, aes(x=Edad, y=Resistencia))+ geom_point() + geom_line(aes(y=lwr), color=&quot;red&quot;, linetype=&quot;dashed&quot;) + geom_line(aes(y=upr), color=&quot;red&quot;, linetype=&quot;dashed&quot;) + geom_smooth(method=lm, formula=y~x, se=TRUE, level=0.95, col=&#39;blue&#39;, fill=&#39;pink2&#39;) + theme_light() De la figura anterior se observa claramente que los IC para \\(\\hat{y}_0\\) son siempre más anchos que los IC para \\(E(y|x_0)\\). "],
["simul.html", "4 Simulación Preguntas sobre simulación en StackOverFlow Simulando datos de un modelo lineal Función simulate Otras herramientas para simular Videos sugeridos", " 4 Simulación En este capítulo se muestra como simular datos que sigan un modelo o estructura dada. Aprender a simular datos es de mucha utilidad para comprender la naturaleza de los datos y para poner a prueba algunos procedimientos de modelos de regresión. Preguntas sobre simulación en StackOverFlow Una de las preguntas más frecuente que hacen los usuarios en StackOverFlow es: “How to simulate linear models in R?”. Muchas respuestas se han dado para ayudar a esos usuarios que necesitan simular datos con una estructura dada. A continuación se muestran algunas de esas preguntas/respuestas hechas en StackOverFlow, invito a lector para que visite los enlaces y explore las respuestas dadas. How to generate observations from a linear model in R. How to generate random Y at specific X from a linear model in R?. Simulate data in R from a linear model where the parameters are correlated. Create Simulated Data Multiple Regression in R. Simulate data from regression model with exact parameters in R. Las respuestas a cómo simular datos de un modelo lineal son muy variadas, algunas sencillas, otras un poco más complejas, y por esa razón en la siguiente sección se mostrará como simular datos de una forma didáctica. Simulando datos de un modelo lineal Para simular de forma exitosa datos de un modelo lineal, se recomienda tener el modelo escrito en forma simbólica el modelo, eso facilita identificar la variable respuesta, su distribución y los parámetros que van a depender de las variables independientes. A continuación se muestra un ejemplo de como simular observaciones de un modelo lineal. Ejemplo Crear una función que simule n observaciones del siguiente modelo que tiene el vector de parámetros \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma=4)^\\top\\). \\[\\begin{align*} y_i &amp;\\sim N(\\mu_i, \\sigma^2) \\\\ \\mu_i &amp;= 4 - 6 x_i \\\\ x_i &amp;\\sim U(-5, 6) \\\\ \\sigma^2 &amp;= 16 \\end{align*}\\] Solución Todo modelo en lenguaje simbólico se lee de arriba hacia abajo \\(\\Downarrow\\) pero al escribirlo en R se hace de abajo hacia arriba \\(\\Uparrow\\). A continuación se muestra la función solicitada la cual sólo tiene un argumento y que entrega como resultado un marco de datos con la información. Estimado lector, mire con detalle el modelo simbólico e identifique todos esos elementos en el código de abajo. gen_dat &lt;- function(n) { varianza &lt;- 16 x &lt;- runif(n=n, min=-5, max=6) media &lt;- 4 - 6 * x y &lt;- rnorm(n=n, mean=media, sd=sqrt(varianza)) marco_datos &lt;- data.frame(y=y, x=x) return(marco_datos) } Vamos a poner a prueba la función para simular 5 observaciones de la siguiente manera. datos &lt;- gen_dat(n=5) datos ## y x ## 1 17.137379 -2.758737 ## 2 -7.832963 2.090143 ## 3 -24.872553 4.878397 ## 4 33.450994 -4.451146 ## 5 23.019364 -3.322686 Vamos ahora a simular 200 observaciones, a dibujar un diagrama de dispersión y a estimar el vector de parámetros \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma=4)^\\top\\). datos &lt;- gen_dat(n=200) library(ggplot2) ggplot(datos, aes(x=x, y=y)) + geom_point() + theme_light() De la figura anterior se observa que la nube tiene pendiente negativa y eso se debe a \\(\\beta_1=-6\\); la nube tiene la misma dispersión y eso de debe a que \\(\\sigma\\) es constante e igual a 4. Para estimar \\(\\boldsymbol{\\Theta}=(\\beta_0=4, \\beta_1=-6, \\sigma=4)^\\top\\) podemos usar el siguiente código. mod &lt;- lm(y ~ x, data=datos) theta_hat &lt;- c(coef(mod), sigma=summary(mod)$sigma) theta_hat ## (Intercept) x sigma ## 4.134907 -6.084929 3.891170 De la salida anterior vemos que el vector estimado \\(\\hat{\\boldsymbol{\\Theta}}\\) está muy cerca del vector de parámetros \\(\\boldsymbol{\\Theta}\\) El código usado en este ejemplo para simular datos de un modelo lineal es un código sencillo y didáctico. Este código busca que el lector aprenda a escribir de una forma sencilla las relaciones entre la variable respuesta, las variables independientes y la influencia de los parámetros. Este código NO es un código óptimo desde el punto de vista computacional. Muy seguramente usa muchos recursos de memoria y puede demorar un poco para simular datos. Sin embargo, es un código FÁCIL de entender. Función simulate La función simulate del paquete básico stats permite simular respuestas a partir de un modelo de clase lm o glm. La estructura de la función es la siguiente: simulate(object, nsim = 1, seed = NULL, ...) Ejemplo Use las 5 primeras observaciones base de datos cars y con esos ajuste un modelo lineal para explicar la distancia promedio para detener el vehículo en función de la velocidad a la cual estaba el vehículo cuando se presionaron los frenos. Luego use ese modelo para simular distancias de frenado. Solución datos &lt;- cars[1:5, ] mod &lt;- lm(dist ~ speed, data=datos) simulate(object=mod, nsim=1, seed=1234) ## sim_1 ## 1 -3.769550 ## 2 8.175135 ## 3 21.954305 ## 4 -5.645603 ## 5 19.110007 Otras herramientas para simular Abajo una lista de herramientas para simular datos a partir de un modelo. Paquete simglm: Simulate Models Based on the Generalized Linear Model. Paquete simrel: Simulation of Multivariate Linear Model Data. Make your R simulation models 20 times faster. Videos sugeridos A continuación se muestran algunos videos que muestran cómo simular datos de un modelo lineal usando R. "],
["ic.html", "5 Intervalos de confianza Función confint Función confint_sigma2", " 5 Intervalos de confianza En este capítulo se muestra como construir intervalos de confianza para los parámetros \\(\\beta\\) y \\(\\sigma\\) de un modelo de regresión lineal. Función confint La función confint de R se usa para obtener intevalos de confianza de los parámetros de un modelo de regresión lineal, la estructura de esta función se muestra a continuación. confint(object, parm, level = 0.95, ...) A continuación se presenta una corta descripción de los parámetros de la función. object: es un objeto con el modelo ajustado. parm: es un vector con los nombres de las variables para los cuales nos interesa construir el intervalo de confianza. Si no se especifica ninguna variable se obtienen intervalos de confianza para todos los parámetros. level: nivel de confianza. Ejemplo Como ilustración vamos a usar los datos del ejemplo mostrado en el capítulo 1. En ese ejemplo se ajustó un modelo de regresión lineal simple para explicar la Resistencia de una soldadura en función de la Edad de la misma. El objetivo es construir un intervalo de confianza del 95% para el parámetro \\(\\beta_1\\). Solución A continuación el código para cargar los datos y ajustar el modelo de interés. file &lt;- &quot;https://raw.githubusercontent.com/fhernanb/datos/master/propelente&quot; datos &lt;- read.table(file=file, header=TRUE) mod1 &lt;- lm(Resistencia ~ Edad, data=datos) El objetivo ahora es construir un intervalo de confianza del 95% para el parámetro \\(\\beta_1\\). La instrucción para obtener el intervalo de confianza se muestra a continuación. confint(object=mod1, parm=&quot;Edad&quot;, level=0.95) ## 2.5 % 97.5 % ## Edad -43.22338 -31.0838 Función confint_sigma2 La función confint_sigma2 pertenece al paquete model y sirve para obtener un intervalo de confianza para el parámetro \\(\\sigma^2\\). El paquete model (Hernandez and Usuga 2020) está alojado en github y para poder instalarlo se sebe usar el siguiente código. if (!require(&#39;devtools&#39;)) install.packages(&#39;devtools&#39;) devtools::install_github(&#39;fhernanb/model&#39;, force=TRUE) Ejemplo Considere el ejemplo anterior pero ahora el interés es obtener un intervalo de confinaza del 95% para \\(\\sigma^2\\). Solución Si deseamos construir un intervalo de confianza del 95% para \\(\\sigma^2\\) del ejemplo anterior se debe escribir el siguiente código. library(model) confint_sigma2(object=mod1, level=0.95) ## 2.5 % 97.5 % ## Sigma2 5273.516 20199.24 References "],
["ph.html", "6 Pruebas de hipótesis Pruebas sobre los coeficientes \\(\\beta\\) Función summary para \\(\\beta_{k0} = 0\\) Función beta_test para \\(\\beta_{k0} \\neq 0\\)", " 6 Pruebas de hipótesis En este capítulo se muestra como realizar pruebas de hipótesis para un modelo de regresión lineal. La prueba explicada a continuación se conoce como prueba de Wald en honor a Abraham Wald (1902-1950). Pruebas sobre los coeficientes \\(\\beta\\) Cuando se tiene un modelo de regresión con \\(p\\) variables, es usual que nos interese estudiar \\[H_0: \\beta_k = \\beta_{k0},\\] frente a una de las tres siguientes hipótesis alternas: \\[H_A: \\beta_k &lt; \\beta_{k0}, \\quad H_A: \\beta_k \\neq \\beta_{k0}, \\quad H_A: \\beta_k &gt; \\beta_{k0},\\] para algún \\(k=0, 1, 2, \\ldots, p\\). Cuando se realiza una prueba de hipótesis sobre uno de los coeficientes \\(\\beta\\), se asume que las variables restantes permanecen en el modelo, es decir que este tipo de pruebas son pruebas marginales. Función summary para \\(\\beta_{k0} = 0\\) Para realizar pruebas de hipótesis cuando el valor de referencia \\(\\beta_{k0}\\) es igual a cero se puede usar la función summary. Ejemplo Aquí vamos a retomar el ejemplo 2.1 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 2.1 los autores ajustaron un modelo de regresión lineal simple para explicar la Resistencia de una soldadura en función de la Edad de la misma. ¿Será la variable Edad una variable significativa para el modelo? es decir, ¿será el coeficiente de la Edad igual a cero o no? Las anteriores preguntas se pueden resumir por medio del siguiente conjunto de hipótesis. \\[H_0: \\beta_{Edad} = 0,\\] \\[H_A: \\beta_{Edad} \\neq 0\\] Para responder a esta pregunta vamos a ajustar el modelo de la forma usual y luego vamos a construir la tabla de resumen del modelo, el código para hacer esto es el siguiente. file &lt;- &quot;https://raw.githubusercontent.com/fhernanb/datos/master/propelente&quot; datos &lt;- read.table(file=file, header=TRUE) mod &lt;- lm(Resistencia ~ Edad, data=datos) summary(mod) ## ## Call: ## lm(formula = Resistencia ~ Edad, data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -215.98 -50.68 28.74 66.61 106.76 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2627.822 44.184 59.48 &lt; 2e-16 *** ## Edad -37.154 2.889 -12.86 1.64e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 96.11 on 18 degrees of freedom ## Multiple R-squared: 0.9018, Adjusted R-squared: 0.8964 ## F-statistic: 165.4 on 1 and 18 DF, p-value: 1.643e-10 De la tabla anterior tenemos que el valor-P asociado a Edad es 1.64e-10, por lo tanto a un nivel de significancia usual de 5%, hay evidencias para rechazar \\(H_0\\) y se concluye que la variable Edad si aporta información para predecir la media de la Resistencia. Función beta_test para \\(\\beta_{k0} \\neq 0\\) Para realizar pruebas de hipótesis cuando el valor de referencia \\(\\beta_{k0}\\) es diferente de cero, se puede usar la función beta_test del paquete model (Hernandez and Usuga 2020). Este paquete está alojado en github y para poder instalarlo se sebe usar el siguiente código. if (!require(&#39;devtools&#39;)) install.packages(&#39;devtools&#39;) devtools::install_github(&#39;fhernanb/model&#39;, force=TRUE) La estructura de la función se muestra a continuación. beta_test(object, alternative = c(&quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot;), parm, ref.value) Los argumentos de esta función son: object: un objeto de la clase lm. alternative: una cadena de caracteres indicando el signo de la hipótesis alterna, los valores posibles son two.sided (valor por defecto), greater o less. parm: vector con el nombre de la variable. ref.value: valor de referencia \\(\\beta_{k0}\\) de la prueba. Ejemplo Aquí vamos a retomar el ejemplo 2.1 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 2.1 los autores ajustaron un modelo de regresión lineal simple para explicar la Resistencia de una soldadura en función de la Edad de la misma. El proveedor de la soldadura afirma que la resistencia media para soldaduras nuevas es 2700 psi. Pruebe la hipótesis de que la resistencia media es diferente a un nivel de significancia del 5%. La anterior pregunta se pueden resumir por medio del siguiente conjunto de hipótesis. \\[H_0: \\beta_{0} = 2700,\\] \\[H_A: \\beta_{0} \\neq 2700\\] Para responder a esta pregunta vamos usar la función beta_test. library(model) beta_test(object=mod, parm=&#39;(Intercept)&#39;, ref.value=2700, alternative=&#39;two.sided&#39;) ## Estimate Std.Err t value Pr(&gt;t) ## (Intercept) 2627.822 44.184 -1.6336 0.1197 Como el valor-P obtenido es 0.1197, entonces la resistencia media para soldaduras nuevas sigue siendo de 2700 psi, en otras palabras, no hay evidencias para rechazar \\(H_0\\), esto a un nivel de significancia del 5%. References "],
["ph2.html", "7 Pruebas de significancia Prueba sobre todos los coeficientes Prueba para comparar modelos anidados Función anova summary versus anova Prueba razón de verosimilitud Comparaciones múltiples", " 7 Pruebas de significancia En este capítulo se muestra como realizar pruebas de significancia en un modelo de regresión. Las pruebas explicadas son las siguientes: Prueba sobre todos los coeficientes (prueba de significancia de la regresión). Prueba para comparar modelos anidados (prueba parcial F). Prueba sobre todos los coeficientes Supongamos que tenemos un modelo de regresión múltiple como se muestra a continuación. \\[\\begin{align} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_k x_{ki}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] Para este modelo nos podemos preguntar si alguna de las covariables aporta información al modelo o si ninguna aporta información al modelo. Esta duda se puede resumir simbólicamente por medio del siguiente conjunto de hipótesis. \\[\\begin{align} H_0 &amp;: \\beta_1=\\beta_2=\\ldots=\\beta_k=0 \\\\ H_1 &amp;= \\text{al menos uno de los} \\, \\beta_j\\neq0 \\, \\text{con} \\, j=1,2,\\ldots,k, \\end{align}\\] La prueba para analizar las hipótesis anteriores se llama prueba de significancia de la regresión. En todo modelo de regresión vamos a tener una variabilidad Total (\\(SS_T\\)), una variabilidad explicada por el modelo de Regresión (\\(SS_R\\)) y una variabilidad Residual (\\(SS_{Res}\\)) que no logra ser explicada por el modelo, abajo una figura ilustrativa de las tres variabilidades. En esta prueba la idea es determinar si la variabilidad explicada por la Regresión (\\(SS_R\\)) es una parte considerable de la variabilidad Total (\\(SS_T\\)) o no. Para realizar esta prueba se construye la tabla anova (analysis of variance) tal como se muestra a continuación. Asumiendo \\(H_0\\) verdadera, la distribución del estadístico \\(F_0\\) es \\(F_{k, n-k-1}\\). Ejemplo Como ilustración vamos a usar los datos del ejemplo 3.1 del libro de (Montgomery 2006). En el ejemplo 3.1 los autores ajustaron un modelo de regresión lineal múltiple para explicar el Tiempo necesario para que un trabajador haga el mantenimiento y surta una máquina dispensadora de refrescos en función de las variables Número de Cajas y Distancia. ¿Será que las variables Número de Cajas y Distancia son significativas en el modelo? Solución En este problema nos interesa estudiar el siguiente conjunto de hipótesis. \\[\\begin{align} H_0 &amp;: \\beta_{cant}=\\beta_{dis}=0 \\\\ H_1 &amp;= \\text{al menos uno de los coefiencientes} \\, \\beta_{cant} \\, \\text{o} \\, \\beta_{dis} \\, \\text{es diferente de cero} \\end{align}\\] Para responder esta pregunta vamos a aplicar la prueba de significancia de la regresión. Lo primero que se debe hacer es ajustar el modelo. require(MPV) colnames(softdrink) &lt;- c(&#39;tiempo&#39;, &#39;cantidad&#39;, &#39;distancia&#39;) mod &lt;- lm(tiempo ~ cantidad + distancia, data=softdrink, x=TRUE) Luego de ajustar el modelo debemos calcular los elementos de la tabla anova, para eso usamos el siguiente código. y &lt;- softdrink$tiempo n &lt;- length(y) ss_t &lt;- sum(y^2) - sum(y)^2 / n ss_r &lt;- matrix(coef(mod), nrow=1) %*% t(mod$x) %*% matrix(y, ncol=1) - sum(y)^2 / n ss_res &lt;- ss_t - ss_r ms_r &lt;- ss_r / (length(coef(mod))-1) ms_res &lt;- ss_res / (n-length(coef(mod))) F0 &lt;- ms_r / ms_res valorP &lt;- pf(F0, df1=length(coef(mod))-1, df2=(n-length(coef(mod))), lower.tail=FALSE) tabla &lt;- matrix(NA, ncol=5, nrow=3) tabla[1, ] &lt;- c(ss_r, length(coef(mod))-1, ms_r, F0, valorP) tabla[2, 1:3] &lt;- c(ss_res, n-length(coef(mod)), ms_res) tabla[3, 1:2] &lt;- c(ss_t, n-1) colnames(tabla) &lt;- c(&#39;Suma Cuadrados&#39;, &#39;gl&#39;, &#39;Cuadrado medio&#39;, &#39;F0&#39;, &#39;Valor-P&#39;) rownames(tabla) &lt;- c(&#39;Reg&#39;, &#39;Resid&#39;, &#39;Total&#39;) tabla ## Suma Cuadrados gl Cuadrado medio F0 Valor-P ## Reg 5550.8109 2 2775.40546 261.2351 4.687422e-16 ## Resid 233.7317 22 10.62417 NA NA ## Total 5784.5426 24 NA NA NA De la tabla anterior se observa que el valor-P es muy pequeño por lo tanto hay evidencias para rechazar \\(H_0: \\beta_{cant}=\\beta_{dis}=0\\), eso significa que al menos una (o ambas) de las variables si ayudan a explicar la media de la variable respuesta. Otra forma de aplicar la prueba de significancia de la regresión es usando la función summary la cual nos entrega una parte de la tabla anova anterior (no toda la tabla anova). summary(mod) ## ## Call: ## lm(formula = tiempo ~ cantidad + distancia, data = softdrink, ## x = TRUE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7880 -0.6629 0.4364 1.1566 7.4197 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.341231 1.096730 2.135 0.044170 * ## cantidad 1.615907 0.170735 9.464 3.25e-09 *** ## distancia 0.014385 0.003613 3.981 0.000631 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.259 on 22 degrees of freedom ## Multiple R-squared: 0.9596, Adjusted R-squared: 0.9559 ## F-statistic: 261.2 on 2 and 22 DF, p-value: 4.687e-16 En la última línea de la salida anterior tenemos la información de la prueba de hipótesis sobre significancia de la regresión. El valor-P de esta prueba es 4.687e-16 y por lo tanto podemos rechazar \\(H_0\\) a un nivel de significancia usual del 5%, eso significa que al menos una de las dos covariables del modelo es significativa para explicar el tiempo medio. El no rechazar \\(H_0: \\beta_1 = \\beta_2 = \\ldots = \\beta_p = 0\\) significa que ninguna de las variables aporta información para explicar la media de \\(Y\\). Lo que se debe hacer luego es buscar nuevas covariables que sean significativas. El rechazar \\(H_0: \\beta_1 = \\beta_2 = \\ldots = \\beta_p = 0\\) significa que una, o dos, o tres, o cuatro, …, o que todas las \\(p\\) covariables son significativas. Pero, ¿cómo saber cuales variables son significativas? Prueba para comparar modelos anidados Esta prueba se usa para comparar modelos que comparten una estructura anidada. A continuación se muestran dos modelos (reducido y completo) anidados a manera de ilustración. Modelo reducido \\[\\begin{align} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] Modelo completo \\[\\begin{align} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + \\beta_4 x_{4i}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] La pregunta que surge aquí es: ¿vale la pena incluir las variables \\(x_3\\) y \\(x_4\\) simultáneamente al modelo reducido? ¿esas variables mejoran el modelo reducido? ¿será mejor el modelo reducido o el modelo completo? Los interrogantes anteriores se pueden resumir simbólicamente así: \\[\\begin{align} H_0 &amp;: \\beta_3=\\beta_4=0 \\\\ H_1 &amp;= \\text{al menos uno de los coefiencientes} \\, \\beta_{3} \\, \\text{o} \\, \\beta_{4} \\, \\text{es diferente de cero} \\end{align}\\] Para realizar esta prueba se usa el siguiente estadístico \\[ F_0 = \\frac{\\frac{SS_R(complete) - SS_R(reduced)}{p_1-p_0}}{MS_{Res}}, \\] donde \\(SS_R(complete)\\) es la suma de cuadrados de la regresión para el modelo completo, \\(SS_R(reduced)\\) es la suma de cuadrados de la regresión para el modelo reducido, \\(p_1\\) es el número de \\(\\beta\\)’s en el modelo completo, \\(p_0\\) es el número de \\(\\beta\\)’s en el modelo reducido y \\(MS_{Res}\\) es la estimación de \\(\\sigma^2\\) en el modelo completo. La distribución del estadístico \\(F_0\\) es: \\(F_{p_1-p_0, n-p_1}\\) si \\(H_0\\) es cierta. \\(F_{p_1-p_0, n-p_1, \\lambda}\\) si \\(H_1\\) es cierta, siendo \\(\\lambda\\) el parámetro de no centralidad de una distribución F. Para conocer la expresión de \\(\\lambda\\) se recomienda revisar la página 90 de (Montgomery, Peck, and Vining 2012) y los comentarios al respecto. Ejemplo Usando la base de datos table.b4 del paquete MPV (Braun 2019), queremos comparar dos modelos anidados: el modelo reducido con la fórmula y ~ x1 + x2, y el modelo completo con la fórmula y ~ x1 + x2 + x3 + x4. ¿Será que la inclusión simultánea de las variables x3 y x4 mejora el modelo para explicar la variable respuesta y? Use \\(\\alpha=0.03\\) para concluir. Solución Primero veamos los datos. require(MPV) data(table.b4) head(table.b4, n=4) ## y x1 x2 x3 x4 x5 x6 x7 x8 x9 ## 1 29.5 5.0208 1 3.531 1.500 2 7 4 62 0 ## 2 27.9 4.5429 1 2.275 1.175 1 6 3 40 0 ## 3 25.9 4.5573 1 4.050 1.232 1 6 3 54 0 ## 4 29.9 5.0597 1 4.455 1.121 1 6 3 42 0 Ajustemos los dos modelos de interés. redu_mod &lt;- lm(y ~ x1 + x2, data=table.b4, x=TRUE) comp_mod &lt;- lm(y ~ x1 + x2 + x3 + x4, data=table.b4, x=TRUE) En este ejercicio nos interesa estudiar el siguiente conjunto de hipótesis. \\[\\begin{align} H_0 &amp;: \\beta_3 = \\beta_4 = 0 \\\\ H_1 &amp;= \\text{al menos uno de los coefiencientes} \\, \\beta_{3} \\, \\text{o} \\, \\beta_{4} \\, \\text{es diferente de cero} \\end{align}\\] Ahora construyamos el estadístico \\(F_0\\). n &lt;- 24 # numero de observaciones p0 &lt;- 3 # numero de betas en modelo reducido p1 &lt;- 5 # numero de betas en modelo completo ssr_reduced &lt;- sum(table.b4$y) - sum(redu_mod$residuals^2) ssr_complete &lt;- sum(table.b4$y) - sum(comp_mod$residuals^2) ms_res &lt;- summary(comp_mod)$sigma^2 F0 &lt;- ((ssr_complete - ssr_reduced) / (p1-p0)) / ms_res F0 ## [1] 0.2831532 Ahora vamos a calcular el parámetro de no centralidad \\(\\lambda\\). Recuerde revisar la página 90 de (Montgomery, Peck, and Vining 2012) para conocer su expresión. beta2 &lt;- matrix(c(0.3233333, -0.2176622), ncol=1) x1 &lt;- comp_mod$x[, 1:3] x2 &lt;- comp_mod$x[, 4:5] a1 &lt;- t(beta2) %*% t(x2) a2 &lt;- diag(n) - x1 %*% solve(t(x1) %*% x1) %*% t(x1) a3 &lt;- x2 %*% beta2 lambda &lt;- (a1 %*% a2 %*% a3) / summary(comp_mod)$sigma^2 lambda ## [,1] ## [1,] 0.5663064 Ahora vamos a calcular el valor-P de la prueba usando la distribución F no central y la distribució F (usual) así: pf(q=F0, df1=p1-p0, df2=n-p1, ncp=lambda, lower.tail=FALSE) ## [1] 0.8088857 pf(q=F0, df1=p1-p0, df2=n-p1, lower.tail=FALSE) ## [1] 0.7565282 Usando el último valor-P que es mayor que un nivel de significancia \\(\\alpha\\), no hay evidencias para rechazar \\(H_0: \\beta_3 = \\beta_4 = 0\\), y por lo tanto podemos concluir que las variables x3 y x4 no mejoran el modelo. Función anova La función anova permite realizar pruebas de hipótesis como las mostradas en las secciones anteriores, en particular la función sirve para: comparar secuencialmente las variables de un modelo. comparar modelos anidados. El método S3 anova.lm (o simplemente anova) tiene la estructura mostrada a continuación. anova(object, test, scale=0) Los argumentos de esta función son: object: un objeto de la clase lm. test: una cadena de caracteres indicando el tipo de prueba, F, Chisq o Cp, el valor por defecto es F. scale: valor de la estimación de \\(\\sigma^2\\). Cuando es igual a cero se usa el estimador del modelo con más parámetros (m2). La función anova se puede aplicar a un solo modelo y el resultado será una prueba de hipótesis secuencial en las variables. La función anova se puede aplicar a varios modelos y el resultado será una comparación de modelos. A continuación se muestran dos ejemplos en los cuales se ilustra la utilidad de la función anova. Ejemplo En este ejemplo se mostrará la segunda utilidad de la función anova. Para esto vamos a utilizar la base de datos Cars93 del paquete MASS. El objetivo es construir un modelo para explicar la media del Price de los autos en función de las variables Horsepower, Type y Weight. La solución de este ejercicio tendrá dos partes, en la primera se construirán varios modelos, iniciando con uno sin covariables (mod0) hasta uno con todas las covariables (mod3). En la segunda parte se analizará el modelo con todas las covariables directamente. A continuación el código para crear y comparar los modelos sin covariables y el modelo con solo Horsepower. library(MASS) mod0 &lt;- lm(Price ~ 1, data=Cars93) mod1 &lt;- lm(Price ~ Horsepower, data=Cars93) anova(mod0, mod1) ## Analysis of Variance Table ## ## Model 1: Price ~ 1 ## Model 2: Price ~ Horsepower ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 92 8584.0 ## 2 91 3250.9 1 5333.1 149.29 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 De la salida anterior se tiene que el valor-P es &lt; 2.2e-16 y por lo tanto se concluye que la variable Horsepower mejora el modelo (la misma conclusión se pudo obtener del summary). Ahora vamos a crear y comparar el modelo con sólo Horsepower con el modelo con Horsepower y Type. mod2 &lt;- lm(Price ~ Horsepower + Type, data=Cars93) anova(mod1, mod2) ## Analysis of Variance Table ## ## Model 1: Price ~ Horsepower ## Model 2: Price ~ Horsepower + Type ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 91 3250.9 ## 2 86 2758.1 5 492.81 3.0733 0.01337 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 De la salida anterior se tiene que el valor-P es 0.01337 y por lo tanto se concluye que el modelo mod2 con dos covariables explica mejor la variable Price. Ahora vamos a crear y comparar el modelo con Horsepower y Type con el modelo con las tres covariables. mod3 &lt;- lm(Price ~ Horsepower + Type + Weight, data=Cars93) anova(mod2, mod3) ## Analysis of Variance Table ## ## Model 1: Price ~ Horsepower + Type ## Model 2: Price ~ Horsepower + Type + Weight ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 86 2758.1 ## 2 85 2751.3 1 6.7934 0.2099 0.648 De esta última salida vemos que el valor-P es 0.648, esto indica que la inclusión de la variable Weight no mejora el modelo mod2 (la misma conclusión se pudo obtener del summary). En esta segunda parte del ejemplo se usará la función anova directamente sobre el modelo completo mod3, a continuación los resultados. anova(mod3) ## Analysis of Variance Table ## ## Response: Price ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Horsepower 1 5333.1 5333.1 164.7661 &lt; 2e-16 *** ## Type 5 492.8 98.6 3.0451 0.01411 * ## Weight 1 6.8 6.8 0.2099 0.64803 ## Residuals 85 2751.3 32.4 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 En la tabla anterior aparecen los resultados de una prueba de hipótesis secuencial a partir de la fórmula de mod3. La fórmula de mod3 es Price ~ Horsepower + Type + Weight, por lo tanto en la primera línea de la tabla aparece la variable Horsepower, luego en la segunda aparece Type y así hasta la última variable Weight. El valor-P reportado en la primer línea es &lt; 2e-16, esto indica el modelo con Horsepower es mejor que el modelo sin covariables; el valor-P de la segunda línea es 0.01411, esto indica que es mejor un modelo con las covariables Horsepower y Type; por último el valor-P de la tercer línea es 0.64803, esto indica que la variable Weight no mejora el modelo, es decir, que es mejor un modelo con solo Horsepower y Type. Ejemplo Usando la base de datos table.b4 del paquete MPV (Braun 2019), queremos comparar dos modelos anidados: el modelo reducido con la fórmula y ~ x1 + x2, y el modelo completo con la fórmula y ~ x1 + x2 + x3 + x4. ¿Será que la inclusión simultánea de las variables x3 y x4 mejora el modelo para explicar la variable respuesta y? Use \\(\\alpha=0.03\\) para concluir. Solución Para este ejemplo vamos a usar los datos que se muestran a continuación. require(MPV) data(table.b4) head(table.b4, n=4) ## y x1 x2 x3 x4 x5 x6 x7 x8 x9 ## 1 29.5 5.0208 1 3.531 1.500 2 7 4 62 0 ## 2 27.9 4.5429 1 2.275 1.175 1 6 3 40 0 ## 3 25.9 4.5573 1 4.050 1.232 1 6 3 54 0 ## 4 29.9 5.0597 1 4.455 1.121 1 6 3 42 0 Ahora vamos a ajustar ambos modelos usando el siguiente código. mod1 &lt;- lm(y ~ x1 + x2, data=table.b4) mod2 &lt;- lm(y ~ x1 + x2 + x3 + x4, data=table.b4) El objetivo en este ejercicio analizar el siguiente conjunto de hipótesis. \\[H_0: \\text{las variables x3 y x4 no mejoran el modelo},\\] \\[H_A: \\text{al menos una de ellas si mejora el modelo}\\] Para comparar los dos modelos usamos la siguiente instrucción. anova(mod1, mod2, test=&#39;F&#39;) ## Analysis of Variance Table ## ## Model 1: y ~ x1 + x2 ## Model 2: y ~ x1 + x2 + x3 + x4 ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 21 163.71 ## 2 19 158.98 2 4.7384 0.2832 0.7565 De la salida anterior se observa que el valor-P de la prueba es de 0.7565, usando un nivel de significancia del 5%, se concluye que la inclusión de las variables x3 y x4 no mejoran el modelo. summary versus anova La función summary permite evaluar el efecto de una variable asumiendo que las restantes variables siguen en el modelo, esto es llamado prueba de hipótesis marginal. Cuando se tiene una variable cualitativa (con \\(k\\) niveles) dentro del modelo, ella aparecerá en la tabla del summary por medio de \\(k-1\\) variables indicadoras y por lo tanto se tendrán \\(k-1\\) valores-P asociados. Usar esos valores-P para decidir si una variable cualitativa es importante en el modelo puede ser engañoso, a continuación un ejemplo de esta situación. Ejemplo El ejemplo aquí mostrado está basado en una pregunta de StackOverFlow. El ejemplo consiste en simular un conjunto de 30 valores de \\(y \\sim N(\\mu_g, 1)\\), donde las observaciones 1 a 10 tienen \\(\\mu=0\\), las observaciones 11 a 20 tienen \\(\\mu=-0.5\\) y las restantes diez tienen \\(\\mu=0.5\\). Para diferenciar las observaciones se tendrá la variable de agruación cualitativa g que contendrá las letras A, B y C diez veces cada una. El código para simular los datos se muestra a continuación. set.seed(8867) # this makes the example exactly reproducible y &lt;- c(rnorm(10, mean=0, sd=1), rnorm(10, mean=-0.5, sd=1), rnorm(10, mean=0.5, sd=1)) g &lt;- rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), each=10) Ahora vamos a ajustar el modelo con fórmula y ~ g para estudiar el efecto de la agrupación g en la media de la variable respuesta y. model &lt;- lm(y ~ g) Obviamente esperamos concluir que la media de la variable y dependa de la variable de agrupación g. Para esto vamos a explorar el resultado con la función summary. summary(model) ## ## Call: ## lm(formula = y ~ g) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.59080 -0.54685 0.04124 0.79890 2.56064 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.4440 0.3855 -1.152 0.260 ## gB -0.9016 0.5452 -1.654 0.110 ## gC 0.6729 0.5452 1.234 0.228 ## ## Residual standard error: 1.219 on 27 degrees of freedom ## Multiple R-squared: 0.2372, Adjusted R-squared: 0.1807 ## F-statistic: 4.199 on 2 and 27 DF, p-value: 0.02583 De la salida anterior vemos que los efectos gB y gC tienen valores-P altos, superiores al usual 5%, y por lo tanto estaríamos tentados a decir que la variable g no tiene efecto sobre la media de y. El lector podría encontrar esto puede ser un poco desconcertante. Vamos a realizar el análisis pero ahora con la función anova. anova(model) ## Analysis of Variance Table ## ## Response: y ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## g 2 12.484 6.2418 4.199 0.02583 * ## Residuals 27 40.135 1.4865 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 En la fila donde aparece la variable g tenemos el resultado de la prueba de hipótesis \\[H_0: \\text{la variable g no influye en la media de y},\\] \\[H_A: \\text{la variable g si influye en la media de y}\\] El valor-P de esta prueba es de 0.02583, esto indica que hay evidencias para rechazar \\(H_0\\), es decir, encontramos que la variable g si influye sobre la media de la variable y. Cuando se quiera explorar el efecto de una variable cualitativa en un modelo es mejor usar la función anova que los resultados del summary. Prueba razón de verosimilitud Esta prueba evalúa la bondad de ajuste de dos modelos estadísticos competitivos en función de la razón de sus verosimilitudes, específicamente uno encontrado por maximización en todo el espacio de parámetros y otro encontrado después de imponer alguna restricción (\\(H_0\\)). El estadístico de la prueba razón de verosimilitud se muestra a continuación. \\[ \\lambda = -2 \\log \\left[ \\frac{L(\\Theta_0)}{L(\\Theta)} \\right] = -2 \\left[ l(\\Theta_0)-l(\\Theta) \\right], \\] donde \\(L\\) representa el valor de la verosimilitud y \\(l\\) el valor de log-verosimilitud. Bajo la hipótesis nula, \\(\\lambda \\sim \\chi^2_{k}\\) donde \\(k\\) es la diferencia entre el número de parámetros de los modelos comparados. Ejemplo Usando la base de datos table.b4 del paquete MPV (Braun 2019), queremos comparar dos modelos anidados: el modelo reducido con la fórmula y ~ x1 + x2, y el modelo completo con la fórmula y ~ x1 + x2 + x3 + x4. ¿Será que la inclusión simultánea de las variables x3 y x4 mejora el modelo para explicar la variable respuesta y? Use \\(\\alpha=0.03\\) para concluir. Solución Para este ejemplo vamos a usar los datos que se muestran a continuación. require(MPV) data(table.b4) head(table.b4, n=4) ## y x1 x2 x3 x4 x5 x6 x7 x8 x9 ## 1 29.5 5.0208 1 3.531 1.500 2 7 4 62 0 ## 2 27.9 4.5429 1 2.275 1.175 1 6 3 40 0 ## 3 25.9 4.5573 1 4.050 1.232 1 6 3 54 0 ## 4 29.9 5.0597 1 4.455 1.121 1 6 3 42 0 Ahora vamos a ajustar ambos modelos usando el siguiente código. mod0 &lt;- lm(y ~ x1 + x2, data=table.b4) mod1 &lt;- lm(y ~ x1 + x2 + x3 + x4, data=table.b4) El objetivo en este ejercicio analizar el siguiente conjunto de hipótesis. \\[H_0: \\text{las variables x3 y x4 no mejoran el modelo},\\] \\[H_A: \\text{al menos una de ellas si mejora el modelo}\\] Para aplicar la prueba razón de verosimilitud usamos el siguiente código. Los grados de libertad en esta prueba son 2 porque esa es la diferencia entre el número de parámetros de los modelos. lambda &lt;- -2 * (logLik(mod0) - logLik(mod1)) lambda ## &#39;log Lik.&#39; 0.7048811 (df=4) pchisq(q=lambda, df=2, lower.tail=FALSE) ## &#39;log Lik.&#39; 0.7029704 (df=4) Como el valor-P es grande, no hay evidencias para rechazar \\(H_0: \\beta_3 = \\beta_4 = 0\\), y por lo tanto podemos concluir que las variables x3 y x4 no mejoran el modelo. Comparaciones múltiples En esta sección se muestra como utilizar el paquete multcomp (Hothorn, Bretz, and Westfall 2020) que está basado en el libro “Multiple comparisons using R” (Frank Bretz 2010) para estudiar pruebas de hipótesis múltiples. Ejemplo Usando la base de datos table.b4 del paquete MPV (Braun 2019), queremos ajustar el siguiente modelo: \\[\\begin{align} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + \\beta_4 x_{4i}, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] ¿Será que la inclusión simultánea de las variables x3 y x4 mejora el modelo para explicar la variable respuesta y? Use \\(\\alpha=0.03\\) para concluir. Solución Lo primero que debemos hacer es ajustar el modelo de interés. require(MPV) data(table.b4) mod &lt;- lm(y ~ x1 + x2 + x3 + x4, data=table.b4) coef(mod) ## (Intercept) x1 x2 x3 x4 ## 9.8408825 2.4374996 6.4373377 0.3233333 -0.2176622 En este ejemplo nos interesa estudiar las siguientes dos hipótesis simultáneamente (no individualmente). \\[\\begin{align*} H_0 &amp;: \\beta_{3} = 0 &amp; H_0 &amp;: \\beta_{4} = 0 \\\\ H_A &amp;: \\beta_{3} \\neq 0 &amp; H_A &amp;: \\beta_{4} \\neq 0 \\end{align*}\\] Los dos conjuntos de hipótesis anteriores se pueden escribir matricialmente usando una matriz de constrate \\(\\boldsymbol{C}\\) que multiplica al vector de parámetros \\(\\boldsymbol{\\beta}\\) y luego igualando es producto con el vector \\(\\boldsymbol{a}=(0, 0)^\\top\\) que contiene lados derechos de las hipótesis anteriores. \\[ \\boldsymbol{C} \\boldsymbol{\\beta} = \\begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\\\ \\beta_4 \\\\ \\end{pmatrix} = \\begin{pmatrix} \\beta_3 \\\\ \\beta_4 \\end{pmatrix} \\] Teniendo definida la matriz \\(\\boldsymbol{C}\\), el vector \\(\\boldsymbol{a}\\) la prueba simultánea de las hipótesis se puede hacer de la siguiente manera. library(multcomp) C &lt;- matrix(c(0, 0, 0, 1, 0, 0, 0, 0, 0, 1), ncol=5, byrow=TRUE) mult_test &lt;- glht(model=mod, linfct=C, alternative=&#39;two.sided&#39;, rhs=c(0, 0)) summary(mult_test, test = adjusted(type=&quot;single-step&quot;)) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Fit: lm(formula = y ~ x1 + x2 + x3 + x4, data = table.b4) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## 1 == 0 0.3233 0.4324 0.748 0.704 ## 2 == 0 -0.2177 3.7475 -0.058 0.998 ## (Adjusted p values reported -- single-step method) De la salida anterior se obtiene que los dos valores-P “ajustados” (ver sección 2.1.2 de (Frank Bretz 2010)) son: \\[ q_1 = 0.704 \\qquad q_2 = 0.998 \\] lo que significa que no hay evidencias para rechazar \\(H_0 : \\beta_{3} = 0\\) ni evidencias para rechazar \\(H_0 : \\beta_{4} = 0\\) porque ambos valores-P “ajustados” fueron mayores del nivel de significancia de 0.03. En otras palabras, ni x3 ni x4 aportan información para explicar la media de y. Si un valor-P “ajustado” es menor que el \\(\\alpha\\), se rechaza su correspondiente hipótesis nula \\(H_0\\), pero si el valor-P “ajustado” es mayor que el \\(\\alpha\\), no se rechaza \\(H_0\\). En una aplicación es posible que se rechacen todas/algunas/ninguna de las \\(H_0\\). References "],
["mod-poli.html", "8 Modelos polinomiales Funciones I() y poly() Función bs Función lowess Función loess Optimización con superficies de respuesta Polinomios ortogonales", " 8 Modelos polinomiales En este capítulo se presenta una descripción breve de como ajustar modelos polinomiales con R. Funciones I() y poly() Las funciones I() y poly() son utilizadas para incluir elementos polinomiales en un modelo de regresión. Use I() para incluir un término específico en un modelo, por ejemplo, I(x^3) indica que queremos solo el término \\(x^3\\). Use poly() para incluir todos los términos de un polinomio hasta cierto grado, por ejemplo, poly(x, degree=3) indica que queremos incluir \\(x\\), \\(x^2\\) y \\(x^3\\). Ejemplo Como ilustración vamos a usar los datos del ejemplo 7.1 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 7.1 se busca crear un modelo que explique la resistencia a la tensión de una bolsa en función del porcentaje de madera dura. A continuación se muestran los datos usados en el ejemplo. datos &lt;- structure(list(concentracion = c(1, 1.5, 2, 3, 4, 4.5, 5, 5.5, 6, 6.5, 7, 8, 9, 10, 11, 12, 13, 14, 15), resistencia = c(6.3, 11.1, 20, 24, 26.1, 30, 33.8, 34, 38.1, 39.9, 42, 46.1, 53.1, 52, 52.5, 48, 42.8, 27.8, 21.9)), class = &quot;data.frame&quot;, row.names = c(NA, -19L)) El siguiente código es usado para construir el diagrama de dispersión entre las variables resistencia y concentración. library(ggplot2) ggplot(datos, aes(x=concentracion, y=resistencia)) + geom_point() + theme_light() De este diagrama se ve claramente que hay una relación de tipo no lineal entre las variables. ¿Será mejor un modelo de grado 2 que un modelo de grado 1? Vamos a ajustar ambos modelos y luego los comparamos, el elemento cuadrático lo vamos a crear usando la función I(). mod1 &lt;- lm(resistencia ~ concentracion, data=datos) mod2 &lt;- lm(resistencia ~ concentracion + I(concentracion^2), data=datos) Para hacer una comparación de ambos modelos vamos a agregar al diagrama de dispersión original la recta y la curva asociadas a los modelos mod1 y mod2 respectivamente. ggplot(datos, aes(x=concentracion, y=resistencia)) + geom_point() + geom_smooth(method=&#39;lm&#39;, formula=y~x, se=FALSE, col=&#39;dodgerblue1&#39;) + geom_smooth(method=&#39;lm&#39;, formula=y~x+I(x^2), se=FALSE, col=&#39;tomato&#39;) + theme_light() De la figura anterior se observa claramente que el modelo lineal no es capaz de explicar los datos, se observan zonas donde el mod1 siempre sub-estima y otras zonas donde siempre sobre-estima. Vamos a comparar ahora los modelos por medio de un análisis de varianza, el código para hacer esto es el siguiente. anova(mod1, mod2) ## Analysis of Variance Table ## ## Model 1: resistencia ~ concentracion ## Model 2: resistencia ~ concentracion + I(concentracion^2) ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 17 2373.46 ## 2 16 312.64 1 2060.8 105.47 1.894e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 El valor-P de la tabla anterior nos indica que es mejor mod2. A continuación se analizan los residuales (\\(e_i\\) vs \\(\\hat{y}_i\\)) para ambos modelos. par(mfrow=c(1, 2)) plot(mod1, which=1, caption=&#39;Modelo lineal&#39;) plot(mod2, which=1, caption=&#39;Modelo cuadratico&#39;) En la parte izquierda de la figura anterior se ve que para el modelo lineal mod1 los residuales presentan una curvatura evidente, esto significa que falta un elemento de grado dos en la estructura del modelo mod1. Al lado derecho de la figura están los residuales para el modelo cuadrático, de esta figura se observa que los residuales son menores (en valor absoluto) que los residuales del mod1 y que no presentan un patrón claro como en el caso anterior. Otro punto a favor del modelo cuadrático es su \\(R^2_{Adj}\\) que es de 0.897 frente al 0.265 del modelo lineal. De lo anterior se concluye que es mejor el modelo cuadrático para explicar la resistencia en función de la concentración, el modelo ajustado está dado en la siguiente expresión. \\[\\begin{align} {Resi}_i &amp;\\sim N(\\hat{\\mu}_i, \\sigma^2), \\\\ \\hat{\\mu}_i &amp;= -6.674 + 11.764 Conc - 0.635 Conc^2, \\\\ \\hat{\\sigma} &amp;= 4.42 \\end{align}\\] Ejemplo Como ilustración vamos a usar los datos del ejemplo 7.2 del libro de Montgomery, Peck and Vining (2003). En el ejemplo 7.2 se busca crear un modelo que explique la caída de voltaje en función del tiempo por medio dos posibles modelos: un modelo polinomial de grado tres. un spline cúbico con 2 nodos en \\(t=6.5\\) y \\(t=13\\). Los datos utilizados en el ejemplo se muestran a continuación. drop &lt;- c(8.33, 8.23, 7.17, 7.14, 7.31, 7.60, 7.94, 8.30, 8.76, 8.71, 9.71, 10.26, 10.91, 11.67, 11.76, 12.81, 13.30, 13.88, 14.59, 14.05, 14.48, 14.92, 14.37, 14.63, 15.18, 14.51, 14.34, 13.81, 13.79, 13.05, 13.04, 12.60, 12.05, 11.15, 11.15, 10.14, 10.08,9.78,9.80,9.95,9.51) time &lt;- seq(from=0, to=20, by=0.5) datos &lt;- data.frame(time=time, drop=drop) Usando los datos anteriores podemos construir un diagrama de dispersión para entender la relación de las variables y la ubicación de los posibles nodos (sitios donde hay cambio de curvatura). plot(datos, ylab=&quot;Voltage drop&quot;, xlab=&quot;Time (seconds)&quot;, pch=19, ylim=c(0, 15)) abline(v=6.5, lty=&quot;dotted&quot;, col=&#39;tomato&#39;) abline(v=13, lty=&quot;dotted&quot;, col=&#39;tomato&#39;) text(x=6.5, y=0.3, &#39;t=6.5&#39;, col=&#39;tomato&#39;) text(x=13, y=0.3, &#39;t=13&#39;, col=&#39;tomato&#39;) Primero vamos a ajustar el modelo polinomial cúbico, el codigo necesario es el siguiente. mod1 &lt;- lm(drop ~ time + I(time^2) + I(time^3), data=datos) summary(mod1) ## ## Call: ## lm(formula = drop ~ time + I(time^2) + I(time^3), data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.3503 -0.7340 -0.1859 0.6440 1.8390 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.4910163 0.5336473 12.163 1.71e-14 *** ## time 0.7031952 0.2339552 3.006 0.004738 ** ## I(time^2) 0.0340179 0.0273762 1.243 0.221829 ## I(time^3) -0.0033072 0.0008992 -3.678 0.000743 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9335 on 37 degrees of freedom ## Multiple R-squared: 0.8773, Adjusted R-squared: 0.8673 ## F-statistic: 88.14 on 3 and 37 DF, p-value: &lt; 2.2e-16 De la anterior salida se pueden destacar los siguientes resultados: Los residuales varían entre -1.35 y 1.83. El \\(R^2_{Adj}=0.8673\\). La estimación de \\(\\sigma\\) es 0.9335. El término \\(t^3\\) es significativo en el modelo a un nivel de significancia del 5%, eso implica que todos los términos de grado 2 y grado 1 deben permanecer en el modelo, sean o no significativos. Ahora vamos a ajustar el modelo spline cúbico con 2 nodos en \\(t=6.5\\) y \\(t=13\\), el codigo necesario es el siguiente. xplus &lt;- function(x) ifelse(x &gt;= 0, x, 0) # Auxiliar function time6.5 &lt;- xplus(time - 6.5) time13 &lt;- xplus(time - 13) mod2 &lt;- lm(drop ~ time + I(time^2) + I(time^3) + I(time6.5^3) + I(time13^3), data=datos) summary(mod2) ## ## Call: ## lm(formula = drop ~ time + I(time^2) + I(time^3) + I(time6.5^3) + ## I(time13^3), data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.45168 -0.18499 -0.03547 0.20577 0.61694 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.465678 0.200520 42.219 &lt; 2e-16 *** ## time -1.453124 0.181586 -8.002 2.04e-09 *** ## I(time^2) 0.489889 0.043018 11.388 2.54e-13 *** ## I(time^3) -0.029467 0.002848 -10.347 3.44e-12 *** ## I(time6.5^3) 0.024706 0.004039 6.116 5.43e-07 *** ## I(time13^3) 0.027112 0.003578 7.577 6.98e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2678 on 35 degrees of freedom ## Multiple R-squared: 0.9904, Adjusted R-squared: 0.9891 ## F-statistic: 725.5 on 5 and 35 DF, p-value: &lt; 2.2e-16 De la anterior salida se pueden destacar los siguientes resultados: Los residuales están más cerca del cero cuando se comparan con los residuales del mod1. El \\(R^2_{Adj}=0.9891\\) aumentó bastante. La estimación de \\(\\sigma\\) es 0.2678. Todos los términos son significativos. Para hacer una comparación visual de ambos modelos vamos a construir nuevamente el diagrama de dispersión original y agregaremos las curvas ajustadas de ambos modelos. El código para hacer esto se muestra a continuación. plot(datos, ylab=&quot;Voltage drop&quot;, xlab=&quot;Time (seconds)&quot;, pch=19, ylim=c(0, 15)) i &lt;- order(time) lines(time[i], fitted(mod1)[i], col=2, lwd=3) lines(time[i], fitted(mod2)[i], col=4, lwd=3) legend(&quot;bottomright&quot;, lwd=3, col=c(4,2), bty=&quot;n&quot;, legend=c(&quot;Cubic spline model&quot;, &quot;Cubic polynomial model&quot;)) Al observar la figura anterior se nota con claridad que el modelo cubic spline (azul) logra explicar mejor los datos, tanto en los extremos como en la parte central, eso significa que es mejor usar el modelo cubic spline para hacer predicciones futuras. Usando la tabla de resumen obtenida con summary(mod2) se puede escribir el modelo cubic spline ajustado así: \\[\\begin{align} {Drop}_i &amp;\\sim N(\\hat{\\mu}_i, \\sigma^2), \\\\ \\hat{\\mu}_i &amp;= 8.4657 -1.4531 t + 0.4899 t^2 -0.0295 t^3 + 0.0247 (t-6.5)^3_{+} + 0.0271 (t-13)^3_{+}, \\\\ \\hat{\\sigma} &amp;= 0.2678 \\end{align}\\] Función bs La función bs del paquete splines se puede utilizar para incluir splines básicos en un modelo de regresión, la estructura básica de la función se muestra a continuación. bs(x, df = NULL, knots = NULL, degree = 3, intercept = FALSE, Boundary.knots = range(x)) Los argumentos básicos de la función son: x: the predictor variable. Missing values are allowed. df: degrees of freedom. knots: the internal breakpoints that define the spline. degree: degree of the piecewise polynomial—default is 3 for cubic splines. Ejemplo En este ejemplo vamos a retomar el ejemplo 7.2 del libro de Montgomery, Peck and Vining (2003) y que fue explicado anteriormente. El objetivo es repetir el modelo mod2 pero con la ayuda de la función bs, a ese nuevo modelo lo vamos a llamar mod3. El código necesario se muestra a continuación. require(splines) mod3 &lt;- lm(drop ~ bs(time, knots=c(6.5, 13), degree=3), data=datos) summary(mod3) ## ## Call: ## lm(formula = drop ~ bs(time, knots = c(6.5, 13), degree = 3), ## data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.45168 -0.18499 -0.03547 0.20577 0.61694 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.4657 0.2005 42.219 &lt; 2e-16 ## bs(time, knots = c(6.5, 13), degree = 3)1 -3.1484 0.3934 -8.002 2.04e-09 ## bs(time, knots = c(6.5, 13), degree = 3)2 4.3532 0.2843 15.312 &lt; 2e-16 ## bs(time, knots = c(6.5, 13), degree = 3)3 8.5518 0.3691 23.169 &lt; 2e-16 ## bs(time, knots = c(6.5, 13), degree = 3)4 0.5990 0.3059 1.958 0.058192 ## bs(time, knots = c(6.5, 13), degree = 3)5 1.2414 0.2871 4.324 0.000121 ## ## (Intercept) *** ## bs(time, knots = c(6.5, 13), degree = 3)1 *** ## bs(time, knots = c(6.5, 13), degree = 3)2 *** ## bs(time, knots = c(6.5, 13), degree = 3)3 *** ## bs(time, knots = c(6.5, 13), degree = 3)4 . ## bs(time, knots = c(6.5, 13), degree = 3)5 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2678 on 35 degrees of freedom ## Multiple R-squared: 0.9904, Adjusted R-squared: 0.9891 ## F-statistic: 725.5 on 5 and 35 DF, p-value: &lt; 2.2e-16 Al comparar los resultados de summary(mod2) con summary(mod3) vemos sólo una pequeña coincidencia. ¿Serán iguales, similares o diferentes el mod2 y mod3? Para compararlos vamos a crear nuevamente el diagrama de dispersión original y vamos a agregar las curvas ajustadas para los tres modelos. El modelo mod1 estará en color rojo, el modelo mod2 en color azul y línea gruesa, y el modelo mod3 en color naranja y línea delgada. a continuación el código usado. plot(datos, ylab=&quot;Voltage drop&quot;, xlab=&quot;Time (seconds)&quot;, pch=19, ylim=c(0,15)) lines(time[i], fitted(mod1)[i], col=&#39;red&#39;, lwd=3) lines(time[i], fitted(mod2)[i], col=&#39;blue&#39;, lwd=6) lines(time[i], fitted(mod3)[i], col=&#39;orange&#39;, lwd=1) legend(&quot;bottomright&quot;, lwd=c(3, 6, 2), col=c(&#39;red&#39;, &#39;blue&#39;, &#39;orange&#39;), legend=c(&quot;Cubic polynomial model&quot;, &quot;Cubic spline manually&quot;, &quot;Using bs()&quot;), bty=&quot;n&quot;) abline(v=c(6.5, 13), lty=&#39;dotted&#39;, col=&quot;tomato&quot;) # adding cutpoints De la figura anterior se observa que el modelo mod3 coincide con el modelo mod2. Función lowess La función lowess (LOcally WEighted Scatterplot Smoothing) permite constuir una curva suavizada a partir de muchas regresiones de orden uno localizadas, usando una ventana que incluye un porcentaje f de puntos. A continuación se muestra una figura ilustrativa para entender lo que hace lowess. (#fig:animacion_lowess)Ilustración de lowess. La estructura de la función lowess se muestra a continuación. lowess(x, y = NULL, f = 2/3, iter = 3, delta = 0.01 * diff(range(x))) Los argumentos básicos de la función son: x: vector con los valores de la covariable. y: vector con los valores de la variable respuesta. f: porcentaje de puntos dentro de la ventana, por defecto es 2/3. Ejemplo Como ejemplo vamos a usar los datos de la base Prestige que se encuentra en el paquete car. Queremos constuir un modelo lowess para explicar la variable prestige en función de la variable income. A continuación el código para crear el diagrama de dispersión que muestra la relación entre las variables. library(car) plot(prestige ~ income, xlab=&quot;Average Income&quot;, ylab=&quot;Prestige&quot;, data=Prestige, pch=19) Para crear el modelo lowess a los datos anteriores se usa el siguiente código. mod_lowess &lt;- lowess(x=Prestige$income, y=Prestige$prestige, f=2/3) El objeto mod_lowess es una lista con las coordenadas \\(x\\) e \\(y\\) por donde pasa la curva suavizada. A continuación el código para agregar la curva al diagrama de dispersión. plot(prestige ~ income, xlab=&quot;Average Income&quot;, ylab=&quot;Prestige&quot;, data=Prestige, pch=19) lines(mod_lowess, lwd=4, col=&#39;tomato&#39;) De la figura anterior vemos que la curva suavizada logra capturar el patrón de variación de los datos. ¿Qué sucede con la curva cuando cambiamos el parámetro f? El efecto de f se puede ver con claridad en la siguiente figura. Cuando f es pequeño la curva es muy rugosa, para valores altos de f la curva se suaviza. (#fig:effect_of_f)Efecto de f en lowess. Función loess La función loess (LOcally Estimated Scatterplot Smoothing) permite constuir una curva o superficie suavizada a partir de muchas regresiones de orden uno o dos localizadas, usando una ventana que incluye un porcentaje span de puntos. La función loess es una generalización de lowess. La estructura de la función loess se muestra a continuación. loess(formula, data, weights, subset, na.action, model = FALSE, span = 0.75, enp.target, degree = 2, parametric = FALSE, drop.square = FALSE, normalize = TRUE, family = c(&quot;gaussian&quot;, &quot;symmetric&quot;), method = c(&quot;loess&quot;, &quot;model.frame&quot;), control = loess.control(...), ...) Los argumentos básicos de la función son: formula: fórmula usual (y ~ x1 + x2 + x3 + x4) para indicar la variable respuesta y las covariables. Máximo se pueden incluir 4 covariables. data: marco de datos con las variables. degree: el grado de los polinomios locales a usar, se puede elegir entre grado 1 o grado 2. span: vector con los valores de la variable respuesta. Los otros parámetros tienen valores por defecto que se pueden cambiar para obtener mejores ajustes. Ejemplo Como ejemplo vamos a usar los datos de la base Prestige que se encuentra en el paquete car. Queremos constuir un modelo loess para explicar la variable prestige en función de las variables income y education. A continuación el código para crear el diagrama de dispersión que muestra la relación entre las variables. library(plotly) plot_ly(x=Prestige$income, y=Prestige$education, z=Prestige$prestige, type=&quot;scatter3d&quot;, color=Prestige$prestige) %&gt;% layout(scene = list(xaxis = list(title = &#39;Income&#39;), yaxis = list(title = &#39;Education&#39;), zaxis = list(title = &#39;Prestige&#39;))) Para crear el modelo loess a los datos anteriores se usa el siguiente código. mod_loess &lt;- loess(prestige ~ income + education, data=Prestige, degree=2, span=0.75) A continuación el código para agregar la superficie al diagrama de dispersión. Los objetos inc y edu son secuencias de valores en el rango de los datos originales. El objeto newdata es un marco de datos con todas las combinaciones de valores de inc y edu. El objeto fit.prestige es una matriz con los valores estimados de la variable prestige. Luego todos esos objetos entran a la función plot_ly. inc &lt;- with(Prestige, seq(min(income), max(income), len=25)) edu &lt;- with(Prestige, seq(min(education), max(education), len=25)) newdata &lt;- expand.grid(income=inc, education=edu) fit.prestige &lt;- matrix(predict(mod_loess, newdata), 25, 25) plot_ly(x=inc, y=edu, z=fit.prestige) %&gt;% add_surface() %&gt;% layout(scene = list(xaxis = list(title = &#39;Income&#39;), yaxis = list(title = &#39;Education&#39;), zaxis = list(title = &#39;Prestige&#39;))) Es posible crear un gráfico con los puntos originales y la superficie del modelo, a continuación el código necesario. library(&quot;plot3D&quot;) scatter3D(x=Prestige$income, y=Prestige$education, z=Prestige$prestige, ticktype=&quot;detailed&quot;, pch=20, bty=&quot;f&quot;, colkey=FALSE, phi=30, theta=45, type=&quot;h&quot;, xlab=&#39;Income&#39;, ylab=&#39;Education&#39;, zlab=&#39;Prestige&#39;, surf=list(x=inc, y=edu, z=fit.prestige, NAcol=&quot;black&quot;, shade=0.1)) ¿Qué sucede con la superficie cuando cambiamos el parámetro span? El efecto de span se puede ver con claridad en la siguiente figura. Cuando span es pequeño la superficie es muy rugosa, para valores altos de span la suferficie se suaviza. (#fig:effect_of_span)Efecto de span en loess. Optimización con superficies de respuesta Cuando se tiene una superficie de respuesta, obtenida por métodos paramétricos o no paramétricos, dos preguntas posibles son: ¿Cuáles valores de las covariables maximizan la variable respuesta? ¿Cuáles valores de las covariables minimizan la variable respuesta? Ambos problemas se denominan problemas de optimización. Cuando se tiene una o dos covariables, el problema es sencillo, y se puede resolver dibujando la curva o la superficie, y visualmente se puede obtener el valor o valores de las \\(x&#39;\\)s que optimizan la variable respuesta. Cuando se tienen tres o más covariables es necesario usar métodos de optimización, algunas de las funciones más usuales de R para hacer esto son: función nlminb, función optim. Función nlminb La estructura de esta función es la siguiente: nlminb(start, objective, gradient = NULL, hessian = NULL, ..., scale = 1, control = list(), lower = -Inf, upper = Inf) Los parámetros de la función son: start: vector con los valores donde inicia la búsqueda. objective: función a MINIMIZAR. El primer argumento de esta función debe ser un vector y ella debe entregar un valor. gradient: función opcional que calcula el gradiente. hessian: función opcional que calcula la hessiana. lower: vector con los valores mínimos de la región de búsqueda. upper: vector con los valores máximos de la región de búsqueda. Maximizar la función \\(f(x)\\) es equivalente a minimizar la función \\(-f(x)\\). Esto es importante para hacer optimización. Ejemplo Vamos a utilizar aquí unos datos de un experimento en el cual se estudió la influencia de la temperatura y la concentración sobre el rendimiento obtenido en un proceso químico. A continuación los datos del experimento. temp &lt;- c(200, 250, 200, 250, 189.65, 260.35, 225, 225, 225, 225, 225, 225) conc &lt;- c(15, 15, 25, 25, 20, 20, 12.93, 27.07, 20, 20, 20, 20) rend &lt;- c(43, 78, 69, 73, 48, 76, 65, 74, 76, 79, 83, 81) Vamos a construir un diagrama de dispersión para ver la relación de las variables. library(scatterplot3d) scatterplot3d(x=temp, y=conc, z=rend, pch=16, cex.lab=1.5, highlight.3d=TRUE, type=&quot;h&quot;) El objetivo es ajustar el siguiente modelo: \\[\\begin{align} y_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 temp_{i} + \\beta_2 conc_{i} + \\beta_3 temp_i^2 + \\beta_4 conc_i^2 + \\beta_5 temp \\times conc, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] El código para ajustar el modelo es el siguiente. mod &lt;- lm(rend ~ temp + conc + I(temp^2) + I(conc^2) + temp * conc) Usando el modelo ajustado mod es posible dibujar la superfice de respuesta para determinar de forma visual los valores que maximizan el rendimiento. # Se crean 30 valores de las variables para crear la rejilla Temperatura &lt;- seq(from=189.65, to=260.35, length.out=30) Concentracion &lt;- seq(from=12.93, to=27.07, length.out=30) # Rend es la funcion a dibujar Rend &lt;- function(temp, conc) { res &lt;- coef(mod) * c(1, temp, conc, temp^2, conc^2, temp * conc) sum(res) } Rend &lt;- Vectorize(Rend) # La funcion a dibujar debe estar vectorizada # La matriz Rendimiento con las alturas de la superficie se crea con outer Rendimiento &lt;- outer(Temperatura, Concentracion, Rend) # Para dibujar la superficie de respuesta persp(x=Temperatura, y=Concentracion, z=Rendimiento, theta=40, phi=30, ticktype = &quot;detailed&quot;, col=&#39;salmon1&#39;) Se puede también construir un gráfico con curvas de nivel para determinar de forma visual los valores que maximizan el rendimiento. contour(x=Temperatura, y=Concentracion, z=Rendimiento, nlevels=10, col=gray(0.3), lwd=2, lty=&#39;solid&#39;, xlab=&#39;Temperatura&#39;, ylab=&#39;Concentracion&#39;, las=1) Un gráfico de calor es también útil para determinar de forma visual los valores que maximizan el rendimiento. filled.contour(x=Temperatura, y=Concentracion, z=Rendimiento, nlevels=10, xlab=&#39;Temperatura&#39;, ylab=&#39;Concentracion&#39;, las=1, color.palette = cm.colors) Para encontrar los valores exactos que maximizan el rendimiento se usa la función nlminb. A continuación se crea la función minus_rend que representa \\(-f(x)\\) la cual va a ser minimizada. Se define el punto de inicio de la búsqueda en el objeto inicio y luego el resultado de nlminb se almacena en el objeto res. minus_rend &lt;- function(x) { temp &lt;- x[1] conc &lt;- x[2] new.data &lt;- data.frame(temp=c(1, temp), conc=c(1, conc)) -predict(mod, new.data)[2] } inicio &lt;- c(192, 15) # valores iniciales para la busqueda names(inicio) &lt;- c(&#39;Temperatura&#39;, &#39;Concentracion&#39;) # Colocando nombres res &lt;- nlminb(start=inicio, objective=minus_rend, lower=c(189.65, 12.93), # minimos de las variables upper=c(260.35, 27.07), # maximos de las variables control=list(trace=0)) res$par # Valores optimos ## Temperatura Concentracion ## 238.95190 19.94697 -res$objective # Valor del objetivo ## [1] 82.46933 Dentro del objeto res hay mucha más información. Es fundamental que el lector explore esos elementos con la ayuda de la función nlminb. Una reto interesante para el lector es que replique el ejemplo con la función optim para ver otra forma alternativa de optimizar. Polinomios ortogonales Estamos preparando el contenido, revisar luego. "],
["selec.html", "9 Selección de variables Akaike Information Criterion (\\(AIC\\)) Funciones logLik y AIC Métodos Función stepAIC Funciones addterm y dropterm Paquete olsrr Paquete mixlm Paquete leaps", " 9 Selección de variables En este capítulo se muestra como realizar selección de variables en un modelo de regresión lineal. Akaike Information Criterion (\\(AIC\\)) El \\(AIC\\) se define como: \\[AIC = - 2 \\times logLik + k \\times n_{par},\\] donde \\(logLik\\) corresponde al valor de log-verosimilitud del modelo para el vector de parámetros \\(\\hat{\\Theta}\\), \\(k\\) es un valor de penalización por el exceso de parámetros y \\(n_{par}\\) corresponde al número de parámetros del modelo. Se debe recordar siempre que: El mejor modelo es aquel que \\(logLik\\) ↑. El mejor modelo es aquel que \\(AIC\\) ↓. Cuando el valor de penalización \\(k=\\log(n)\\) entonces el \\(AIC\\) se llamada en \\(BIC\\) o \\(SBC\\) (Schwarz’s Bayesian criterion). Funciones logLik y AIC La función logLik sirve para obtener el valor de log-verosimilitud de un modelo y la función AIC entrega el Akaike Information Criterion. La estructura de ambas funciones se muestra a continuación. logLik(object) AIC(object, k=2) Métodos Los métodos para realizar selcción de variables se pueden clasificar de la siguiente manera: Todas las regresiones posibles. Selección de variables. Forward Backward A continuación una imagen ilustrativa para entender ambos métodos. Figure 9.1: Ilustración de los métodos Forward y Backward. Un término ingresa al modelo si su presencia disminuye el \\(AIC\\). Un términa sale del modelo si su ausencia disminuye el \\(AIC\\). Función stepAIC La función stepAIC del paquete MASS (Ripley 2019) es útil para hacer selección de variables en un modelo de regresión. La estructura de la función se muestra a continuación. stepAIC(object, scope, scale = 0, direction = c(&quot;both&quot;, &quot;backward&quot;, &quot;forward&quot;), trace = 1, keep = NULL, steps = 1000, use.start = FALSE, k = 2, ...) Algunos de los argumentos son: object: un objeto con un modelo. scope: fórmula(s) con los límites de búsqueda. direction: los posibles valores son both, backward, forward. trace: valor lógico para indicar si se desea ver el paso a paso de la selección. k: valor de penalidad, por defecto es 2. Ejemplo En este ejemplo se busca encontrar un modelo de regresion lineal que explique la variable respuesta \\(y\\) en función de las covariables \\(x_1\\) a \\(x_{11}\\), los datos provienen del ejercicio 9.5 del libro de Montgomery, Peck and Vining (2003). A continuación se muestra el encabezado de la base de datos y la definición de las variables. Figure 9.2: Ilustración de los métodos Forward y Backward. Nota: Type of transmission (1=automatic, 0=manual). Antes de iniciar es necesario revisar si hay NA's y eliminarlos. library(MPV) # Aqui estan los datos table.b3[22:26, ] # Can you see the missing values? ## y x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 ## 22 21.47 360.0 180 290 8.4 2.45 2 3 214.2 76.3 4250 1 ## 23 16.59 400.0 185 NA 7.6 3.08 4 3 196.0 73.0 3850 1 ## 24 31.90 96.9 75 83 9.0 4.30 2 5 165.2 61.8 2275 0 ## 25 29.40 140.0 86 NA 8.0 2.92 2 4 176.4 65.4 2150 0 ## 26 13.27 460.0 223 366 8.0 3.00 4 3 228.0 79.8 5430 1 datos &lt;- table.b3[-c(23, 25), ] El objeto datos tiene la base de datos sin las líneas con NA, lo mismo se hubiese podido realizar usando la función na.omit. A continuación se muestran los diagramas de dispersión para las variables de la base de datos. ## ## Attaching package: &#39;psych&#39; ## The following object is masked from &#39;package:car&#39;: ## ## logit ## The following objects are masked from &#39;package:ggplot2&#39;: ## ## %+%, alpha Aplicación del método backward Vamos a crear un modelo saturado, es decir, el modelo mayor a considerar. full.model &lt;- lm(y ~ ., data=datos) summary(full.model) ## ## Call: ## lm(formula = y ~ ., data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.3441 -1.6711 -0.4486 1.4906 5.2508 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 17.339838 30.355375 0.571 0.5749 ## x1 -0.075588 0.056347 -1.341 0.1964 ## x2 -0.069163 0.087791 -0.788 0.4411 ## x3 0.115117 0.088113 1.306 0.2078 ## x4 1.494737 3.101464 0.482 0.6357 ## x5 5.843495 3.148438 1.856 0.0799 . ## x6 0.317583 1.288967 0.246 0.8082 ## x7 -3.205390 3.109185 -1.031 0.3162 ## x8 0.180811 0.130301 1.388 0.1822 ## x9 -0.397945 0.323456 -1.230 0.2344 ## x10 -0.005115 0.005896 -0.868 0.3971 ## x11 0.638483 3.021680 0.211 0.8350 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.227 on 18 degrees of freedom ## Multiple R-squared: 0.8355, Adjusted R-squared: 0.7349 ## F-statistic: 8.31 on 11 and 18 DF, p-value: 5.231e-05 De la tabla anterior se puede pensar en que hay un efecto de enmascaramiento entre las variables ya que ninguna parece significativa marginalmente. Se usa la función stepAIC y se elije trace=TRUE para obtener detalles del proceso de selección. library(MASS) # Para poder usar la funcion stepAIC modback &lt;- stepAIC(full.model, trace=TRUE, direction=&quot;backward&quot;) ## Start: AIC=78.96 ## y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 ## ## Df Sum of Sq RSS AIC ## - x11 1 0.465 187.87 77.036 ## - x6 1 0.632 188.03 77.063 ## - x4 1 2.418 189.82 77.346 ## - x2 1 6.462 193.86 77.979 ## - x10 1 7.836 195.24 78.190 ## - x7 1 11.065 198.47 78.683 ## &lt;none&gt; 187.40 78.962 ## - x9 1 15.758 203.16 79.384 ## - x3 1 17.770 205.17 79.679 ## - x1 1 18.736 206.14 79.820 ## - x8 1 20.047 207.45 80.011 ## - x5 1 35.864 223.26 82.215 ## ## Step: AIC=77.04 ## y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 ## ## Df Sum of Sq RSS AIC ## - x6 1 0.536 188.40 75.121 ## - x4 1 2.363 190.23 75.411 ## - x2 1 6.642 194.51 76.078 ## - x10 1 7.985 195.85 76.285 ## &lt;none&gt; 187.87 77.036 ## - x7 1 14.124 201.99 77.211 ## - x9 1 16.914 204.78 77.622 ## - x3 1 17.815 205.68 77.754 ## - x1 1 18.280 206.15 77.822 ## - x8 1 20.301 208.17 78.114 ## - x5 1 36.370 224.24 80.345 ## ## Step: AIC=75.12 ## y ~ x1 + x2 + x3 + x4 + x5 + x7 + x8 + x9 + x10 ## ## Df Sum of Sq RSS AIC ## - x4 1 3.451 191.85 73.666 ## - x2 1 6.932 195.33 74.205 ## - x10 1 9.351 197.75 74.574 ## &lt;none&gt; 188.40 75.121 ## - x7 1 14.473 202.87 75.342 ## - x3 1 17.802 206.20 75.830 ## - x9 1 18.146 206.55 75.880 ## - x1 1 18.780 207.18 75.972 ## - x8 1 21.244 209.65 76.326 ## - x5 1 39.332 227.73 78.809 ## ## Step: AIC=73.67 ## y ~ x1 + x2 + x3 + x5 + x7 + x8 + x9 + x10 ## ## Df Sum of Sq RSS AIC ## - x2 1 10.780 202.63 73.306 ## - x7 1 11.113 202.97 73.355 ## &lt;none&gt; 191.85 73.666 ## - x10 1 14.988 206.84 73.923 ## - x1 1 16.602 208.46 74.156 ## - x9 1 18.072 209.92 74.366 ## - x3 1 21.314 213.17 74.826 ## - x8 1 28.835 220.69 75.867 ## - x5 1 40.323 232.18 77.389 ## ## Step: AIC=73.31 ## y ~ x1 + x3 + x5 + x7 + x8 + x9 + x10 ## ## Df Sum of Sq RSS AIC ## - x7 1 10.457 213.09 72.815 ## - x3 1 10.595 213.23 72.835 ## - x1 1 11.998 214.63 73.032 ## - x9 1 12.643 215.28 73.122 ## - x10 1 13.887 216.52 73.295 ## &lt;none&gt; 202.63 73.306 ## - x8 1 27.665 230.30 75.145 ## - x5 1 30.191 232.82 75.472 ## ## Step: AIC=72.82 ## y ~ x1 + x3 + x5 + x8 + x9 + x10 ## ## Df Sum of Sq RSS AIC ## - x3 1 4.8720 217.96 71.494 ## - x9 1 5.2049 218.29 71.539 ## - x1 1 5.3212 218.41 71.555 ## &lt;none&gt; 213.09 72.815 ## - x10 1 18.3677 231.46 73.296 ## - x5 1 23.3458 236.44 73.934 ## - x8 1 26.0316 239.12 74.273 ## ## Step: AIC=71.49 ## y ~ x1 + x5 + x8 + x9 + x10 ## ## Df Sum of Sq RSS AIC ## - x1 1 0.765 218.73 69.599 ## - x9 1 5.863 223.82 70.290 ## &lt;none&gt; 217.96 71.494 ## - x10 1 20.291 238.25 72.164 ## - x5 1 23.020 240.98 72.506 ## - x8 1 31.634 249.59 73.559 ## ## Step: AIC=69.6 ## y ~ x5 + x8 + x9 + x10 ## ## Df Sum of Sq RSS AIC ## - x9 1 5.097 223.82 68.290 ## &lt;none&gt; 218.73 69.599 ## - x5 1 40.404 259.13 72.684 ## - x8 1 57.407 276.13 74.591 ## - x10 1 135.105 353.83 82.029 ## ## Step: AIC=68.29 ## y ~ x5 + x8 + x10 ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 223.82 68.290 ## - x5 1 36.314 260.14 70.800 ## - x8 1 52.960 276.78 72.661 ## - x10 1 194.838 418.66 85.076 Para obtener un resumen del proceso se usa: modback$anova ## Stepwise Model Path ## Analysis of Deviance Table ## ## Initial Model: ## y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 ## ## Final Model: ## y ~ x5 + x8 + x10 ## ## ## Step Df Deviance Resid. Df Resid. Dev AIC ## 1 18 187.4007 78.96155 ## 2 - x11 1 0.4648362 19 187.8655 77.03587 ## 3 - x6 1 0.5356445 20 188.4012 75.12128 ## 4 - x4 1 3.4514854 21 191.8526 73.66591 ## 5 - x2 1 10.7796848 22 202.6323 73.30587 ## 6 - x7 1 10.4571693 23 213.0895 72.81545 ## 7 - x3 1 4.8720101 24 217.9615 71.49363 ## 8 - x1 1 0.7654631 25 218.7270 69.59881 ## 9 - x9 1 5.0970905 26 223.8241 68.28989 Para ver la tabla de resultados del modelo modback. summary(modback) ## ## Call: ## lm(formula = y ~ x5 + x8 + x10, data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.6101 -1.9868 -0.6613 2.0369 5.8811 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.590404 11.771925 0.390 0.6998 ## x5 2.597240 1.264562 2.054 0.0502 . ## x8 0.217814 0.087817 2.480 0.0199 * ## x10 -0.009485 0.001994 -4.757 6.38e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.934 on 26 degrees of freedom ## Multiple R-squared: 0.8035, Adjusted R-squared: 0.7808 ## F-statistic: 35.44 on 3 and 26 DF, p-value: 2.462e-09 Aplicación del método forward Para aplicar este metodo se debe crear un modelo vacío (empty.model) del cual iniciará el proceso. Es necesario definir un punto final de búsqueda, ese punto es una fórmula que en este caso llamaremos horizonte. A continuación el codigo. empty.model &lt;- lm(y ~ 1, data=datos) horizonte &lt;- formula(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11) Se usa la función stepAIC y se elije trace=FALSE para que NO se muestren los detalles del proceso de selección. modforw &lt;- stepAIC(empty.model, trace=FALSE, direction=&quot;forward&quot;, scope=horizonte) modforw$anova ## Stepwise Model Path ## Analysis of Deviance Table ## ## Initial Model: ## y ~ 1 ## ## Final Model: ## y ~ x1 + x4 ## ## ## Step Df Deviance Resid. Df Resid. Dev AIC ## 1 29 1139.1050 111.10402 ## 2 + x1 1 866.49528 28 272.6097 70.20532 ## 3 + x4 1 18.57161 27 254.0381 70.08861 Para ver la tabla de resultados del modelo modforw. summary(modforw) ## ## Call: ## lm(formula = y ~ x1 + x4, data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.5011 -2.1243 -0.3884 1.9964 6.9582 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.179421 18.787955 0.382 0.705 ## x1 -0.044479 0.005225 -8.513 3.98e-09 *** ## x4 3.077228 2.190294 1.405 0.171 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.067 on 27 degrees of freedom ## Multiple R-squared: 0.777, Adjusted R-squared: 0.7605 ## F-statistic: 47.03 on 2 and 27 DF, p-value: 1.594e-09 Como la variable \\(x_4\\) no es significativa, entonces se puede refinar o actualizar el modelo modforw sacando \\(x_4\\), esto se puede realizar fácilmente por medio de la función update así: modforw &lt;- update(modforw, y ~ x1) summary(modforw) ## ## Call: ## lm(formula = y ~ x1, data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.6063 -2.0276 -0.0457 1.4531 7.0213 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 33.490010 1.535476 21.811 &lt; 2e-16 *** ## x1 -0.047026 0.004985 -9.434 3.43e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.12 on 28 degrees of freedom ## Multiple R-squared: 0.7607, Adjusted R-squared: 0.7521 ## F-statistic: 89 on 1 and 28 DF, p-value: 3.429e-10 En este enlace usted podrá encontrar la respuesta que le dieron a Audrey al preguntar “Why stepAIC gives a model with insignificant variables?”. Aplicación del método both Para aplicar este método se debe crear un modelo vacío del cual iniciará el proceso. Es necesario definir un punto final de búsqueda, ese punto es una formula que en este caso llamaremos horizonte. A continuación el código. modboth &lt;- stepAIC(empty.model, trace=FALSE, direction=&quot;both&quot;, scope=horizonte) modboth$anova ## Stepwise Model Path ## Analysis of Deviance Table ## ## Initial Model: ## y ~ 1 ## ## Final Model: ## y ~ x1 + x4 ## ## ## Step Df Deviance Resid. Df Resid. Dev AIC ## 1 29 1139.1050 111.10402 ## 2 + x1 1 866.49528 28 272.6097 70.20532 ## 3 + x4 1 18.57161 27 254.0381 70.08861 El modelo modboth y modforw son el mismo. A continuación vamos a realizar una comparación de los modelos obtenidos. Comparando \\(R^2_{Adj}\\) Para extraer el \\(R^2_{Adj}\\) de la tabla de resultados se usa: summary(modback)$adj.r.squared ## [1] 0.7808368 summary(modforw)$adj.r.squared ## [1] 0.7521337 Comparando \\(\\hat{\\sigma}\\) Para extraer el \\(\\hat{\\sigma}\\) de la tabla de resultados se usa: summary(modback)$sigma ## [1] 2.934045 summary(modforw)$sigma ## [1] 3.120266 Comparando los residuales par(mfrow=c(1, 2)) plot(modback, main=&quot;Backward&quot;, pch=19, cex=1, which=1) plot(modforw, main=&quot;Forward&quot;, pch=19, cex=1, which=1) Ejercicios ¿Qué patrón observa en los gráficos? Para cada uno de los dos modelos incluya términos cuadráticos con el objetivo de explicar ese patrón cuadrático no explicado y mostrado en los gráficos de residuales anteriores. Funciones addterm y dropterm Estas dos funciones pertenecen al paquete MASS (Ripley 2019) y son útiles para agregar/quitar 1 variable con respecto al modelo ingresado. A continuación la estructura de las funciones. addterm(object, ...) dropterm (object, ...) Ejemplo Usando datos anteriores ajuste un modelo para explicar y en función de x2 y x5, luego use addterm para determinar cual de las variables x1, x4 y x6 se debería ingresar. mod1 &lt;- lm(y ~ x2 + x5, data=datos) maximo &lt;- formula(~ x1 + x2 + x3 + x4 + x5 + x6) addterm(mod1, scope=maximo) ## Single term additions ## ## Model: ## y ~ x2 + x5 ## Df Sum of Sq RSS AIC ## &lt;none&gt; 353.19 79.974 ## x1 1 88.511 264.67 73.319 ## x3 1 47.296 305.89 77.661 ## x4 1 19.915 333.27 80.233 ## x6 1 19.452 333.73 80.274 De la salida anterior se ve que ingresar x1 mejoraría el modelo porque lo llevaría de un \\(AIC=79.974\\) a uno con \\(AIC=73.319\\). Paquete olsrr El paquete olsrr (Hebbali 2020) contiene varias funciones útiles para modelación, en particular se destaca la función ols_step_all_possible que se puede utilizar para obtener todas las regresiones posibles. Si un modelo tiene inicialmente \\(k\\) variables cuantitativas entonces se pueden construir \\(2^k\\) modelos diferentes con subconjuntos de las variables originales. A continuación un ejemplo de cómo crece el número de todas las regresiones posibles en función del número \\(k\\) de covariables. ## k num_de_regresiones ## [1,] 2 4 ## [2,] 4 16 ## [3,] 8 256 ## [4,] 16 65536 ## [5,] 32 4294967296 Ejemplo En este ejemplo vamos a usar la base de datos mtcars para crear todas las regresiones posibles para explicar mpg en función de las variables disp, hp, wt, qsec, a continuación una parte de la base de datos. head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 A continuación el código para ajustar el modelo saturado y luego crear todas las regresiones posibles. model &lt;- lm(mpg ~ disp + hp + wt + qsec, data=mtcars) library(olsrr) res &lt;- ols_step_all_possible(model) res ## Index N Predictors R-Square Adj. R-Square Mallow&#39;s Cp ## 3 1 1 wt 0.7528328 0.7445939 12.480939 ## 1 2 1 disp 0.7183433 0.7089548 18.129607 ## 2 3 1 hp 0.6024373 0.5891853 37.112642 ## 4 4 1 qsec 0.1752963 0.1478062 107.069616 ## 8 5 2 hp wt 0.8267855 0.8148396 2.369005 ## 10 6 2 wt qsec 0.8264161 0.8144448 2.429492 ## 6 7 2 disp wt 0.7809306 0.7658223 9.879096 ## 5 8 2 disp hp 0.7482402 0.7308774 15.233115 ## 7 9 2 disp qsec 0.7215598 0.7023571 19.602810 ## 9 10 2 hp qsec 0.6368769 0.6118339 33.472150 ## 14 11 3 hp wt qsec 0.8347678 0.8170643 3.061665 ## 11 12 3 disp hp wt 0.8268361 0.8082829 4.360702 ## 13 13 3 disp wt qsec 0.8264170 0.8078189 4.429343 ## 12 14 3 disp hp qsec 0.7541953 0.7278591 16.257790 ## 15 15 4 disp hp wt qsec 0.8351443 0.8107212 5.000000 Los resultados anteriores se pueden ver de forma gráfica así: plot(res) Se le recomienda al lector explorar las viñetas del paquete olsrr para conocer todas las bondades del paquete. Paquete mixlm El paquete mixlm (Liland 2019) contiene un buen número de funciones para modelación. Algunas de las funciones a destacar son forward, backward, stepWise. Este paquete contiene otras funciones lm y glm que se pueden confundir con las funciones lm y glm del paquete stats. Por esta razón el usuario debe tener cuidado de usar la apropiada, en estos casos se recomienda usar stats::lm(y ~ x) o mixlm::lm(y ~ x) para obligar a R a que use la que el usuario desea. Ejemplo En este ejemplo se retoman los datos del ejercicio 9.5 del libro de Montgomery, Peck and Vining (2003). En este ejemplo se busca encontrar un modelo de regresion lineal que explique la variable respuesta \\(y\\) en función de las covariables \\(x_1\\) a \\(x_{11}\\), usando el modelo backward y que todas las variables sean significativas a un nivel del 4%. Para realizar lo solicitado se usa el siguiente código: library(MPV) # Aqui estan los datos datos &lt;- table.b3[-c(23, 25), ] # Eliminando 2 observaciones con NA modelo &lt;- lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11, data=datos) library(mixlm) backward(modelo, alpha=0.04) ## Backward elimination, alpha-to-remove: 0.04 ## ## Full model: y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 ## &lt;environment: 0x0000000037e465c8&gt; ## ## Step RSS AIC R2pred Cp F value Pr(&gt;F) ## x11 1 187.87 77.036 0.41925 10.04465 0.0446 0.83503 ## x6 2 188.40 75.121 0.51334 8.09610 0.0542 0.81844 ## x4 3 191.85 73.666 0.53495 6.42762 0.3664 0.55178 ## x2 4 202.63 73.306 0.54991 5.46301 1.1799 0.28968 ## x7 5 213.09 72.815 0.61766 4.46743 1.1353 0.29819 ## x3 6 217.96 71.494 0.63898 2.93539 0.5259 0.47566 ## x1 7 218.73 69.599 0.66089 1.00892 0.0843 0.77406 ## x9 8 223.82 68.290 0.73638 -0.50150 0.5826 0.45244 ## x5 9 260.14 70.800 0.70705 0.98652 4.2184 0.05017 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Call: ## lm(formula = y ~ x8 + x10, data = datos) ## ## Coefficients: ## (Intercept) x8 x10 ## 16.23496 0.21234 -0.01022 De la salida anterior vemos que el modelo final es y ~ x8 + x10. Si comparamos este modelo con el obtenido al usar la función stepAIC, vemos que se eliminó la variable x5 ya que su valor-P era 5.02%, superior al límite definido aquí del 4%. Paquete leaps El paquete leaps (Fortran code by Alan Miller 2020) creado por Thomas Lumley está basado en Fortran y es útil cuando nos interese encontrar subconjuntos de covariables para optimizar las características de un modelo. La función regsubsets realiza una búsqueda exhaustiva de los mejores subconjuntos de variables \\(x\\) para explicar \\(y\\). La búsqueda utiliza un algoritmo eficiente de ramificación y unión. La estructura de la función es la siguiente: regsubsets(x, data, nbest, nvmax, ...) Algunos de los parámetros más usuados en la función son: x: fórmula usual. data: marco de datos. nbest: número de subconjuntos de cada tamaño a guardar. nvmax: máximo número de subconjuntos a evaluar. Ejemplo En este ejemplo vamos a usar la base de datos mtcars para encontrar los dos mejores modelos con 1, 2, 3 y 4 covariables para explicar mpg en función de las variables disp, hp, wt, qsec. Para hacer la búsqueda usamos el siguiente código. nbest=2 porque queremos los mejores dos modelos con cada número de covariables posible. library(leaps) model_subset &lt;- regsubsets(mpg ~ disp + hp + wt + qsec, data=mtcars, nbest=2, nvmax=13) El model_subset es un objeto de la clase regsubsets y es posible usar la función S3 summary para objetos de esa clase. A continuación los elementos que componen summary. names(summary(model_subset)) ## [1] &quot;which&quot; &quot;rsq&quot; &quot;rss&quot; &quot;adjr2&quot; &quot;cp&quot; &quot;bic&quot; &quot;outmat&quot; &quot;obj&quot; El primer elemento del summary se obtiene así: summary(model_subset)$which ## (Intercept) disp hp wt qsec ## 1 TRUE FALSE FALSE TRUE FALSE ## 1 TRUE TRUE FALSE FALSE FALSE ## 2 TRUE FALSE TRUE TRUE FALSE ## 2 TRUE FALSE FALSE TRUE TRUE ## 3 TRUE FALSE TRUE TRUE TRUE ## 3 TRUE TRUE TRUE TRUE FALSE ## 4 TRUE TRUE TRUE TRUE TRUE De las dos primeras líneas de la salida anterior se observa que los dos mejores modelos con una sola covariable son mpg ~ wt y mpg ~ disp. De forma similar, los dos mejores modelos con dos covariables son mpg ~ hp + wt y mpg ~ wt + qsec. De forma análoga se interpretan las líneas de la salida anterior. Es posible mostrar gráficamente los resultados anteriores usando el método S3 plot para objetos de la clase regsubsets. A continuación la estructura de la función plot. El parámetro scale nos permite explorar los mejores modelos para cada uno de los cuatro criterios \\(BIC\\), \\(C_p\\), \\(R^2_{adj}\\) y \\(R^2\\). plot(x, labels=obj$xnames, main=NULL, scale=c(&quot;bic&quot;, &quot;Cp&quot;, &quot;adjr2&quot;, &quot;r2&quot;), col=gray(seq(0, 0.9, length = 10)),...) A continuación el código para mostrar gráficamente los mejores modelos usando el criterio \\(R^2_{adj}\\) y \\(BIC\\). par(mfrow=c(1, 2)) plot(model_subset, scale=&quot;adjr2&quot;, main=expression(R[Adj]^2)) plot(model_subset, scale=&quot;bic&quot;, main=&quot;BIC&quot;) De la figura de la izquierda vemos que: El modelo con mayor \\(R^2_{adj}\\) es mpg ~ hp + wt + qsec. El modelo mpg ~ hp + wt tiene igual \\(R^2_{adj}\\) que mpg ~ wt + qsec. El mejor modelo con una sola covariable es mpg ~ wt. La figura de la derecha se puede analizar de forma análoga. Para obtener los valores exacto de \\(R^2_{adj}\\) y \\(BIC\\) mostrados en la figura anterior se usa el siguiente código. summary(model_subset)$adjr2 ## [1] 0.7445939 0.7089548 0.8148396 0.8144448 0.8170643 0.8082829 0.8107212 summary(model_subset)$bic ## [1] -37.79462 -33.61466 -45.70597 -45.63781 -43.74996 -42.24960 -40.35723 Para encontrar el modelo con el mejor \\(BIC\\) se puede usar lo siguiente: which(summary(model_subset)$bic == min(summary(model_subset)$bic)) ## [1] 3 Para determinar la estructura del modelo 3 identificado en la salida anterior usamos: summary(model_subset)$which[3, ] ## (Intercept) disp hp wt qsec ## TRUE FALSE TRUE TRUE FALSE References "],
["varcuali.html", "10 Modelos con variables cualitativas ¿Es posible incluir variables cualitativas? Variable indicadora, dummy, ficticia o binaria Creando variables indicadoras Modelos con variables cualitativas Significancia de variables cualitativas", " 10 Modelos con variables cualitativas En este capítulo se muestra cómo incluir variables cualitativas en un modelo de regresión con R. ¿Es posible incluir variables cualitativas? Una de las preguntas frecuentes entre los que inician el estudio de los modelos de regresión es: ¿se pueden incluir variables cualitativas en un modelo de regresión? La respuesta es SI, definitivamente si. A continuación una figura que ilustra algunas de las variables que se pueden incluir en la construcción de un modelo de regresión. Figure 10.1: Variables variables cualitativas a incluir en un modelo. Variable indicadora, dummy, ficticia o binaria La palabra indicadora, dummy, ficticia o binaria es la denominación genérica para una variable que toma valores de 0 o de 1 y que se utiliza para re-expresar variables cualitativas. Observe la figura 10.2. En la parte izquierda se tiene una base original de ejemplo con las variables precio, área y piscina, asociadas a seis apartamentos. La variable cualitativa Piscina de niveles sin, pequeña y grande, el nivel sin es el nivel de referencia natural. Al lado derecho de la figura 10.2 está la base transformada y vemos que hay 4 variables. Las nuevas variables PisPeq y PisGra son 2 variables indicadoras que logran resumir la información de la variable Piscina que tiene 3 variables. Para comprender como las 2 variables indicadoras pueden resumir la información de la variable Piscina, vamos a considerar los siguientes tres casos: Si PisPeq = 0 y PisGra = 0, entonces el apartamento está SIN piscina. Si PisPeq = 1 y PisGra = 0, entonces el apartamento tiene piscina PEQUEÑA. Si PisPeq = 0 y PisGra = 1, entonces el apartamento tiene piscina GRANDE. Figure 10.2: Transformando una base de datos con variables cualitativas. Como regla general, si una variable cualitativa tiene \\(k\\) niveles, se necesitarán de \\(k-1\\) variables indicadoras para resumir la variable cualitativa. Creando variables indicadoras Crear manualmente variables indicadoras para re-expresar variables cualitativas es una tarea muy sencilla, manualmente la podemos hacer. Sin embargo, R posee una herramienta que nos permite convertir la base de datos original en una base de datos transformada (con variables indicadoras). Para este fin se usa la función model.matrix. Ejemplo Retomando la base de datos original mostrada en la figura 10.2 vamos a crear la matriz de diseño \\(\\boldsymbol{X}\\) para ajustar el modelo siguiente: \\[\\begin{align} Precio_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 Area_i + \\beta_2 PisciPequena_i + \\beta_3 PisiGrande_i, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] Lo primero a realizar es ingresar los datos para el ejemplo mostrado en la figura 10.2. El código necesario se muestra a continuación. Precio &lt;- c(12, 15, 25, 11, 16, 7) Area &lt;- c(3, 4, 1, 6, 5, 3) Pisci &lt;- factor(x=c(&#39;Grande&#39;, &#39;Sin&#39;, &#39;Pequena&#39;, &#39;Pequena&#39;, &#39;Sin&#39;, &#39;Grande&#39;), levels=c(&#39;Sin&#39;,&#39;Pequena&#39;,&#39;Grande&#39;)) Al crear el vector Pisci se usó el argumento levels dentro de la función factor para indicarle a R que el nivel de referencia es Sin, seguido de Pequena y luego Grande. Para obtener la matriz \\(\\boldsymbol{X}\\) con las variables indicadoras (no con la variable original Pisci) se hace lo siguiente: model.matrix(Precio ~ Area + Pisci) ## (Intercept) Area Pisci1 Pisci2 ## 1 1 3 -1 -1 ## 2 1 4 1 0 ## 3 1 1 0 1 ## 4 1 6 0 1 ## 5 1 5 1 0 ## 6 1 3 -1 -1 ## attr(,&quot;assign&quot;) ## [1] 0 1 2 2 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$Pisci ## [1] &quot;contr.sum&quot; Modelos con variables cualitativas Para ajustar un modelo de regresión lineal con variables cualitativas se procede de la forma usual como se ajustan modelos con lm, no es necesario crear de antemano la matriz \\(\\boldsymbol{X}\\), esto porque lm internamente crea la matriz de diseño \\(\\boldsymbol{X}\\). Ejemplo En este ejemplo vamos a utilizar la base de datos Cars93 del paquete MASS. El objetivo es ajustar el siguiente modelo para explicar el precio del auto en función del tamaño del motor y del tipo de auto, es decir, el objetivo es ajustar el siguiente modelo. \\[\\begin{align} Precio_i &amp;\\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i &amp;= \\beta_0 + \\beta_1 EngSiz_i + \\beta_2 TComp_i + \\beta_3 TSpor_i + \\beta_4 TMid_i + \\beta_5 TLarg_i + \\beta_6 TVan_i, \\\\ \\sigma^2 &amp;= \\text{constante} \\end{align}\\] Lo primero a realizar es cargar el paquete y explorar las variables de interés con la ayuda de la función str. require(MASS) str(Cars93[, c(&#39;Price&#39;, &#39;EngineSize&#39;, &#39;Type&#39;)]) ## &#39;data.frame&#39;: 93 obs. of 3 variables: ## $ Price : num 15.9 33.9 29.1 37.7 30 15.7 20.8 23.7 26.3 34.7 ... ## $ EngineSize: num 1.8 3.2 2.8 2.8 3.5 2.2 3.8 5.7 3.8 4.9 ... ## $ Type : Factor w/ 6 levels &quot;Compact&quot;,&quot;Large&quot;,..: 4 3 1 3 3 3 2 2 3 2 ... La variable Type tiene 6 niveles, para ver todos niveles usamos el siguiente código. levels(Cars93$Type) ## [1] &quot;Compact&quot; &quot;Large&quot; &quot;Midsize&quot; &quot;Small&quot; &quot;Sporty&quot; &quot;Van&quot; De la salida anterior se observan que los niveles son Compact, Large, Midsize, Small, Sporty y Van. Al observar cuidadosamente los niveles vemos que ellos están ordenados por orden lexicográfico, primero Compact por iniciar con la letra C, por último Van por iniciar con la letra V. Al mirar el modelo requerido se nota que el nivel Small no aparece en la ecuación de \\(\\mu\\), esto significa que ese es el nivel de referencia que se encuentra en el intercepto \\(\\beta_0\\). Para redefinir los niveles en el orden requerido usamos el siguiente código. Cars93$Type &lt;- factor(Cars93$Type, levels=c(&#39;Small&#39;, &#39;Compact&#39;, &#39;Sporty&#39;, &#39;Midsize&#39;, &#39;Large&#39;, &#39;Van&#39;)) levels(Cars93$Type) # Para verificar el cambio ## [1] &quot;Small&quot; &quot;Compact&quot; &quot;Sporty&quot; &quot;Midsize&quot; &quot;Large&quot; &quot;Van&quot; A continuación vamos a crear un diagrama de dispersión para ver la relación entre las variables del problema. library(ggplot2) ggplot(Cars93, aes(x=EngineSize, y=Price, color=Type)) + geom_point() + theme_light() Ahora si podemos ajustar el modelo solicitado usando el siguiente código. mod &lt;- lm(Price ~ EngineSize + Type, data=Cars93) summary(mod) ## ## Call: ## lm(formula = Price ~ EngineSize + Type, data = Cars93) ## ## Residuals: ## Min 1Q Median 3Q Max ## -15.742 -4.568 -0.845 2.473 34.031 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.7242 3.2178 2.090 0.0396 * ## EngineSize 4.6215 1.1099 4.164 7.40e-05 *** ## Type(Small) -3.9298 2.0032 -1.962 0.0530 . ## Type(Compact) 0.7145 1.7218 0.415 0.6792 ## Type(Sporty) 1.1480 1.7612 0.652 0.5162 ## Type(Midsize) 6.3565 1.4775 4.302 4.45e-05 *** ## Type(Large) -1.8764 2.4533 -0.765 0.4465 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## s: 7.068 on 86 degrees of freedom ## Multiple R-squared: 0.4995, ## Adjusted R-squared: 0.4646 ## F-statistic: 14.3 on 6 and 86 DF, p-value: 3.071e-11 Usando la información de la salida anterior se puede construir el siguiente modelo ajustado. \\[\\begin{align} \\widehat{Precio}_i &amp;\\sim N(\\hat{\\mu}_i, \\hat{\\sigma}^2), \\\\ \\hat{\\mu}_i &amp;= 2.794 + 4.621 EngSiz_i + 4.644 TComp_i + 5.078 TSpor_i + \\ldots \\\\ \\hat{\\sigma} &amp;= 7.068 \\end{align}\\] Significancia de variables cualitativas Cuando se incluye una variable cualitativa de \\(k\\) niveles en un modelo de regresión, aparecen \\(k-1\\) variables indicadoras y por lo tanto \\(k-1\\) valores-P en la tabla resumen. Una pregunta frecuente entre los usuarios es ¿cómo saber si una variable cualitativa es significativa para el modelo? Para saber si una variable cualitativa es significativa para un modelo hay tres formas: Mirar si el valor-P de cualquiera de las variables indicadoras es menor que en el nivel de significancia en el summary(mod). Crear una anova y ver si la variable cualitativa es significativa en el modelo es decir, usando anova(mod). Crear un modelo reducido sin la variable cualitativa y usar un análisis de varianza, anova(mod.redu, mod). Ejemplo En este ejemplo vamos a retomar los datos del ejemplo anterior en el cual se usa la base de datos Cars93 del paquete MASS. El objetivo es ajustar un modelo para explicar el precio del auto en función del tamaño del motor y del tipo de auto. ¿Será la variable tipo de auto significativa para el modelo? Para responder la pregunta anterior vamos a usar las tres formas listadas anteriormente. Primero vamos a ajustar el modelo de interés nuevamente. require(MASS) Cars93$Type &lt;- factor(Cars93$Type, levels=c(&#39;Small&#39;, &#39;Compact&#39;, &#39;Sporty&#39;, &#39;Midsize&#39;, &#39;Large&#39;, &#39;Van&#39;)) # Para usar Small como referencia mod &lt;- lm(Price ~ EngineSize + Type, data=Cars93) Forma 1 En la forma 1 debemos mirar si el valor-P de cualquiera de las variables indicadoras es menor que en el nivel de significancia en el summary(mod). Al mirar el resultado del summary(mod) se observa que el valor-P asociado a la variable TypeMidsize es menor que el valor usuar de significancia 5%, por lo tanto la variable Type es sifinificativa para el modelo. summary(mod) ## ## Call: ## lm(formula = Price ~ EngineSize + Type, data = Cars93) ## ## Residuals: ## Min 1Q Median 3Q Max ## -15.742 -4.568 -0.845 2.473 34.031 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.7242 3.2178 2.090 0.0396 * ## EngineSize 4.6215 1.1099 4.164 7.40e-05 *** ## Type(Small) -3.9298 2.0032 -1.962 0.0530 . ## Type(Compact) 0.7145 1.7218 0.415 0.6792 ## Type(Sporty) 1.1480 1.7612 0.652 0.5162 ## Type(Midsize) 6.3565 1.4775 4.302 4.45e-05 *** ## Type(Large) -1.8764 2.4533 -0.765 0.4465 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## s: 7.068 on 86 degrees of freedom ## Multiple R-squared: 0.4995, ## Adjusted R-squared: 0.4646 ## F-statistic: 14.3 on 6 and 86 DF, p-value: 3.071e-11 Forma 2 En la forma 2 debemos crear una anova y ver si la variable cualitativa es significativa en el modelo es decir, usando anova(mod). Al usar la función anova sobre un modelo mod obtenido con la función lm, apareceran tantas filas (con valor-P) como número de variables tenga el modelo ajustado. El conjunto de hipótesis para cada una de las filas es: \\[\\begin{align} H_0 &amp;: \\text{la variable de la FILA no aporta información para el modelo}, \\\\ H_A &amp;: \\text{la variable de la FILA si aporta información para el modelo} \\end{align}\\] A continuación el código para usar la forma 2.. anova(mod) ## Analysis of Variance Table ## ## Response: Price ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## EngineSize 1 3063.8 3063.78 61.3270 1.16e-11 *** ## Type 5 1223.8 244.77 4.8994 0.000542 *** ## Residuals 86 4296.4 49.96 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 De la salida anterior se observa que el valor-P asociado a Type es de 0.000542, usando un nivel de significancia usual del 5% se concluye que hay evidencias para rechazar \\(H_0\\), es decir, la variable Type si aporta información al modelo. Forma 3 En la forma 3 debemos crear un modelo reducido sin la variable cualitativa y usar un análisis de varianza, anova(mod.redu, mod). Al usar la función anova el conjunto de hipótesis es: \\[\\begin{align} H_0 &amp;: \\text{la variable Type no aporta información para el modelo}, \\\\ H_A &amp;: \\text{la variable Type si aporta información para el modelo} \\end{align}\\] A continuación el código para usar la forma 3. El modelo mod.redu contiene un modelo sin la variable cualitativa de interés Type. mod.redu &lt;- lm(Price ~ EngineSize, data=Cars93) anova(mod.redu, mod) ## Analysis of Variance Table ## ## Model 1: Price ~ EngineSize ## Model 2: Price ~ EngineSize + Type ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 91 5520.2 ## 2 86 4296.4 5 1223.8 4.8994 0.000542 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 De la salida anterior se tiene un valor-P de 0.000542, usando un nivel de significancia usual del 5% se concluye que hay evidencias para rechazar \\(H_0\\), es decir, la variable Type si aporta información para el modelo y por lo tanto es una variable útil. La decisión final con las formas 1, 2 y 3 siempre coinciden. La forma 2 y la forma 3 no son la misma. Algunas veces una variable cualitativa puede ser significativa en el modelo pero los valores-P asociados a sus variables indicadoras (auxiliares) son todos mayores al valor \\(\\alpha\\), el resultado del summary puede ser engañoso. Para esto se recomienda usar la función anova. Por favor vea los ejemplos con variables cualitativas del capítulo 6. "],
["algmat.html", "11 Algebra matricial con R Matrices Operaciones básicas sobre una matriz Rango de una matriz", " 11 Algebra matricial con R En este capítulo se muestran algunas funciones útiles para álgebra lineal con R. Matrices Una matriz es un arreglo bidimensional (filas y columna) de números. La función para crear una matriz es matrix. A continuación se muestran los argumentos de la función. matrix(data=NA, nrow=1, ncol=1, byrow=FALSE, dimnames=NULL) Ejemplo Crear en R la matriz \\(M\\) siguiente. \\[ M = \\begin{pmatrix} 1 &amp; 2 \\\\ 1 &amp; 5 \\end{pmatrix} \\] Solución Para crear la matriz podemos usar el siguiente código. M &lt;- matrix(c(1, 2, 1, 5), nrow=2, byrow=TRUE) M ## [,1] [,2] ## [1,] 1 2 ## [2,] 1 5 Operaciones básicas sobre una matriz En la siguiente tabla se listan algunas de las funciones que se pueden utilizar sobre matrices. Los objetos A y B son matrices mientras que los objetos x y b son vectores. Operador Descripción A * B Element-wise multiplication A %*% B Matrix multiplication A %o% B Outer product. \\(AB^\\top\\). t(A) Transpose diag(x) Creates diagonal matrix with elements of x in the principal diagonal diag(A) Returns a vector containing the elements of the principal diagonal diag(k) If k is a scalar, this creates a \\(k \\times k\\) identity matrix. Go figure. solve(A, b) Returns vector x in the equation b = Ax (i.e., A-1b) solve(A) Inverse of A where A is a square matrix. ginv(A) Moore-Penrose Generalized Inverse of A. ginv(A) requires loading the MASS package. cbind(A,B,...) Combine matrices(vectors) horizontally. Returns a matrix. rbind(A,B,...) Combine matrices(vectors) vertically. Returns a matrix. rowMeans(A) Returns vector of row means. rowSums(A) Returns vector of row sums. colMeans(A) Returns vector of column means. colSums(A) Returns vector of column sums. Rango de una matriz El rango de una matriz es el número máximo de columnas (filas respectivamente) que son linealmente independientes. Ejemplo Calcular el rango de la matriz \\(M\\) siguiente. \\[ M = \\begin{pmatrix} 1 &amp; 2 &amp; 5 \\\\ 1 &amp; 5 &amp; 2 \\\\ 1 &amp; 4 &amp; 7 \\end{pmatrix} \\] Solución Lo primero es crear la matriz \\(M\\). M &lt;- matrix(c(1, 2, 5, 1, 5, 2, 1, 4, 7), ncol=3, byrow=TRUE) M ## [,1] [,2] [,3] ## [1,] 1 2 5 ## [2,] 1 5 2 ## [3,] 1 4 7 Una forma de obtener el rango es por medio de la función qr que hace una descomposición QR de la matriz. qr(M)$rank ## [1] 3 De la salida anterior vemos que el rango de \\(M\\) es 3, eso quiere decir que el número máximo de columnas linealmente independientes es 3. Otra forma para obtener el rango de la matriz es por medio de la función rankMatrix del paquete Matrix (Bates and Maechler 2019) así: library(Matrix) rankMatrix(M)[1] ## [1] 3 Ejemplo Calcular el rango de la matriz \\(N\\) siguiente. \\[ N = \\begin{pmatrix} 1 &amp; 2 &amp; 3 \\\\ 1 &amp; 5 &amp; 6 \\\\ 1 &amp; 7 &amp; 8 \\end{pmatrix} \\] Solución Lo primero es crear la matriz \\(N\\). N &lt;- matrix(c(1, 2, 3, 1, 5, 6, 1, 7, 8), ncol=3, byrow=TRUE) N ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 1 5 6 ## [3,] 1 7 8 Al mirar con calma las columnas de la matriz se observa un detalle, la tercera columna de \\(N\\) se obtiene al sumar la primera y segunda columna de \\(N\\), eso significa que la tercera columna es combinación lineal de las dos primeras. Vamos a calcular el rango de \\(N\\). qr(N)$rank ## [1] 2 El valor de 2 obtenido no nos sorprende porque ya habíamos detectado que la tercera columna es combinación lineal de las dos primeras. References "],
["important.html", "12 Otros aspectos importantes ¿Qué otras funciones hay en R para ajustar un modelo? Modelos de regresión con grandes conjuntos de datos Fast lm in R", " 12 Otros aspectos importantes En este capítulo se presentan algunos aspectos importantes relacionados con modelación y que no se pudieron incluir en los capítulos anteriores. ¿Qué otras funciones hay en R para ajustar un modelo? Hay 5 funciones en el paquete básico stats para ajustar un modelo de regresión, esas funciones son: lm(formula, data, subset, weights, na.action, method = &quot;qr&quot;, model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, contrasts = NULL, offset, ...) lm.fit(x, y, offset = NULL, method = &quot;qr&quot;, tol = 1e-7, singular.ok = TRUE, ...) lm.wfit(x, y, w, offset = NULL, method = &quot;qr&quot;, tol = 1e-7, singular.ok = TRUE, ...) .lm.fit(x, y, tol = 1e-7) lsfit(x, y, wt = NULL, intercept = TRUE, tolerance = 1e-07, yname = NULL) De todas las anteriores funciones la más conocida y usada es lm. Lo invito a que consulte la ayuda de las funciones y explore las ventajas que cada una de ellas tiene. Modelos de regresión con grandes conjuntos de datos En ocasiones tenemos grandes bases de datos y cuando queremos ajustar un modelo de regresión se nos pueden presentar problemas porque saturamos la memoria de nuestro computador. En este enlace usted podrá encontrar una publicación de Yixuan Qiu en el 2011 quien explica qué hacer para abordar este tipo de situaciones. Fast lm in R Martin Maechler en 2015 escribió una publicación en Rpubs en la cual compara el tiempo que tardan las funciones lm, lsfit y .lm.fit para ajustar un modelo de regresión. Martin Maechler creó 5 funciones basadas en lm, lsfit y .lm.fit para obtener los parámetros de un modelo. Abajo una figura con los resultados de la comparación de tiempos. ¿Cuáles opciones demoran menos tiempo? "],
["references.html", "References", " References "]
]
