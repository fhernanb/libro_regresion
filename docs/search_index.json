[
["diag2.html", "10 Diagn√≥sticos parte II Matriz sombrero o hat ¬øQu√© es extrapolaci√≥n oculta? Punto at√≠pico y punto influyente Distancia de Cook DFFITS DFBETAS", " 10 Diagn√≥sticos parte II En este cap√≠tulo se presentan otras herramientas √∫tiles para realizar diagn√≥sticos. Matriz sombrero o hat La matriz sombrero o matriz Hat se define as√≠: \\[ \\boldsymbol{H} = \\boldsymbol{X}(\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1}\\boldsymbol{X}^\\top \\] Esta matriz contiene en su diagonal las distancias relativas desde el centroide de los datos hasta cada uno de los puntos. En la siguiente figura se ilustra el concepto de distancia relativa entre el centroide (color rojo) de las variables explicativas y cada uno de los puntos para un caso con tres variables explicativas \\(x_1\\), \\(x_2\\) y \\(x_3\\). La cantidad \\(h_{ii}\\) se llama leverage y corresponde al elemento \\(i\\) de la diagonal de la matriz sombrero \\(\\boldsymbol{H}\\). Los valores de \\(h_{ii}\\) siempre est√°n entre 0 y 1. Si la observaci√≥n \\(i\\)-√©sima tiene un valor grande de \\(h_{ii}\\) significa que ella tiene valores inusuales de \\(\\boldsymbol{x}_i\\), mientras que valores peque√±os de \\(h_{ii}\\) significa que la observaci√≥n se encuentra cerca del centroide de los datos. La distancia \\(h_{ii}\\) no incluye informaci√≥n de la variable respuesta \\(y\\), solo de las covariables, esto se nota claramente en la f√≥rmula de \\(\\boldsymbol{H}\\) dada arriba. ¬øPara qu√© se usan los \\(h_{ii}\\) en la pr√°ctica? En el siguiente apartado se explicar√° el uso de los \\(h_{ii}\\). ¬øQu√© es extrapolaci√≥n oculta? Suponga tenemos un modelo de regresi√≥n una variable respuesta y dos covariables \\(x_1\\) y \\(x_2\\). En la siguiente figura se ilustra los posibles datos desde una vista superior (sin ver los valores de \\(y\\)). Esa elipse o forma se llama Regressor Variable Hull (RVH) o cascar√≥n de los datos. Una vez se tenga el modelo ajustado podr√≠amos usar valores de \\(x_1\\) y \\(x_2\\) para estimar la media de \\(y\\). Lo ideal es usar el modelo para predecir la media de \\(y\\) con valores de \\(x_1\\) y \\(x_2\\) que se encuentren dentro del cascar√≥n. Si tratamos de estimar la media de \\(y\\) para valores de las covariables fuera del cascar√≥n, como en el caso del punto rojo, no podemos garantizar que el modelo tenga un buen desempe√±o debido a que el modelo no se entren√≥ con ese tipo de ejemplos. El problema de extrapolaci√≥n oculta se presenta cuando tratamos de predecir informaci√≥n de \\(y\\) con covariables fuera del cascar√≥n. La extrapolaci√≥n oculta es f√°cil de identificarla cuando s√≥lo se tiene dos covariables, pero, ¬øc√≥mo saber si se est√° haciendo extrapolaci√≥n oculta cuando se tienen varias covariables. Supongamos que queremos saber si el vector de covariables \\(\\boldsymbol{x}_0=(x_1, x_2, \\ldots, x_p)^\\top\\) est√° o no dentro del cascar√≥n, dicho de otra manera, ¬øse cometer√≠a extrapolaci√≥n oculta usando \\(\\boldsymbol{x}_0\\)?. Los pasos para determinar si \\(\\boldsymbol{x}_0\\) est√° o no dentro del cascar√≥n son: Calcular la matriz \\(\\boldsymbol{H}\\). Obtener los valores \\(h_{ii}\\) de la matriz \\(\\boldsymbol{H}\\). Identificar \\(h_{max} = max\\{h_{11}, h_{22}, \\ldots, h_{nn}\\}\\). Calcular \\(h_{00} = \\boldsymbol{x}_0 (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{x}_0^\\top\\). Si \\(h_{00} &gt; h_{max}\\) el punto \\(\\boldsymbol{x}_0\\) est√° fuera del cascar√≥n y se podr√≠a est√°r cometiendo extrapolaci√≥n oculta. Los valores \\(h_{ii}\\) se pueden obtener al calcular la matriz \\(\\boldsymbol{H}\\). Otra forma de obtener los \\(h_{ii}\\) es ajustando el modelo de regresi√≥n y luego usando la funci√≥n hatvalues(model) o lm.influence(model). Ejemplo Calcular los valores \\(h_{ii}\\) para un modelo de regresi√≥n y ~ x + z con los siguientes datos. y &lt;- c(2, 3, 6, 5) x &lt;- c(3, 5, 6, 7) z &lt;- c(5, 4, 6, 3) Soluci√≥n A seguir se muestran las tres formas para obtener los valores \\(h_{ii}\\). # Forma 1 X &lt;- cbind(1, x, z) H &lt;- X %*% solve(t(X) %*% X) %*% t(X) H ## [,1] [,2] [,3] [,4] ## [1,] 8.333333e-01 3.333333e-01 -3.552714e-15 -0.1666667 ## [2,] 3.333333e-01 3.333333e-01 -9.992007e-16 0.3333333 ## [3,] -2.664535e-15 -1.110223e-15 1.000000e+00 0.0000000 ## [4,] -1.666667e-01 3.333333e-01 -1.332268e-15 0.8333333 diag(H) ## [1] 0.8333333 0.3333333 1.0000000 0.8333333 # Forma 2 mod &lt;- lm(y ~ x + z) hatvalues(mod) ## 1 2 3 4 ## 0.8333333 0.3333333 1.0000000 0.8333333 # Forma 3 lm.influence(mod)$hat ## 1 2 3 4 ## 0.8333333 0.3333333 1.0000000 0.8333333 Reto para el lector Use la informaci√≥n del ejemplo anterior y determine si la observaci√≥n con valores de \\(x=4\\) y \\(z=1\\) est√° o no dentro del cascar√≥n de los datos, en otras palabras, determine si se podr√≠a cometer extrapolaci√≥n oculta al usar el modelo ajustado con \\(x=4\\) y \\(z=1\\). Punto at√≠pico y punto influyente Los conceptos de at√≠pico e influyente son diferentes y se definen as√≠: Punto at√≠pico (outlier): es una observaci√≥n que es num√©ricamente distante del resto de los datos. Punto influyente: punto que tiene impacto en las estimativas del modelo. En la siguiente figura se ilustra la diferencia entre los conceptos de at√≠pico e influyente. ¬øC√≥mo se puede saber si un punto es influyente? Para saber si un punto es influyente debemos tener una m√©trica o medida para determinar si √©l es influyente, una medida podr√≠a ser la Distancia de Cook. Distancia de Cook Es una medida de c√≥mo influye la observaci√≥n \\(i\\)-√©sima sobre la estimaci√≥n de \\(\\boldsymbol{\\beta}\\) al ser retirada del conjunto de datos. Una distancia de Cook grande significa que una observaci√≥n tiene un peso grande en la estimaci√≥n de \\(\\boldsymbol{\\beta}\\). \\[ D_i = \\frac{\\sum_{j=1}^{n} (\\hat{y}_j - \\hat{y}_{j(i)} )^2 }{p \\hat{\\sigma^2}}, \\] donde la notaci√≥n \\((i)\\) significa ‚Äúsin la observaci√≥n \\(i\\)-√©sima‚Äù, eso quiere decir que \\(\\hat{y}_{j(i)}\\) es la estimaci√≥n de \\(j\\)-√©sima sin haber tenido en cuenta \\(i\\)-√©sima observaci√≥n en el ajuste del modelo. La cantidad \\(p\\) se refiere a todos los \\(\\beta\\)‚Äôs en el modelo (\\(\\beta_0, \\beta_1, \\beta_2, \\ldots, \\beta_k\\)). Son puntos influyentes las observaciones que presenten \\(D_i=\\frac{4}{n-p-2}\\). Ejemplo: ¬øc√≥mo se relaciona el peso corporal con la circunferencia de la mu√±eca, cuello y estatura? En este ejemplo se usar√° una base de datos que contiene medidad corporales para un grupo de estudiantes universitarios que vieron el curso de modelos de regresi√≥n en el a√±o 2013. Abajo se muestra una figura ilustrativa de los datos. El objetivo es ajustar un modelo de regresi√≥n para explicar el peso promedio en funci√≥n de la circunferencia de la mu√±eca, cuello y estatura. Luego de ajustar el modelo se deben identificar los posible estudiantes influyentes y el efecto de ellos en el modelos. Soluci√≥n Lo primero es cargar los datos en nuestra sesi√≥n de R. url &lt;- &quot;https://raw.githubusercontent.com/fhernanb/datos/master/medidas_cuerpo2&quot; datos &lt;- read.table(file=url, sep=&quot;\\t&quot;, header=TRUE) head(datos, n=5) ## Peso Sexo Estatura circun_cuello circun_muneca ## 1 47.6 F 1.57 29.5 13.9 ## 2 68.1 M 1.66 38.4 16.0 ## 3 68.0 M 1.90 36.5 16.6 ## 4 80.0 M 1.76 38.0 17.1 ## 5 68.1 M 1.83 38.0 17.1 Antes de ajustar cualquier modelo es fundamental hacer un an√°lisis descriptivo de los datos. Comenzaremos construyendo un diagrama de dispersi√≥n con pairs. panel.cor &lt;- function(x, y, digits=2, prefix=&quot;&quot;, cex.cor, ...) { usr &lt;- par(&quot;usr&quot;); on.exit(par(usr)) par(usr=c(0, 1, 0, 1)) r &lt;- cor(x, y) txt &lt;- format(c(r, 0.123456789), digits=digits)[1] txt &lt;- paste(prefix, txt, sep=&quot;&quot;) if(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt) text(0.5, 0.5, txt, cex=cex.cor * r, col=gray(1-r)) } # Creamos el grafico SOLO para las variables cuantitativas pairs(datos[, c(&quot;Peso&quot;, &quot;Estatura&quot;, &quot;circun_cuello&quot;, &quot;circun_muneca&quot;)], pch=19, las=1, upper.panel=panel.smooth, lower.panel=panel.cor) De la figura anterior se observa que hay un punto que se aleja de la nube, es un estudiante que pesa un poco m√°s de 100 kilogramos. Vamos ahora a ajustar nuestro primer modelo. mod1 &lt;- lm(Peso ~ Estatura + circun_cuello + circun_muneca, data=datos) summary(mod1) ## ## Call: ## lm(formula = Peso ~ Estatura + circun_cuello + circun_muneca, ## data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.8842 -3.3779 -0.8704 2.5255 19.5692 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -62.0183 21.2383 -2.920 0.00793 ** ## Estatura 9.4404 20.0299 0.471 0.64206 ## circun_cuello 2.2587 0.8452 2.672 0.01391 * ## circun_muneca 1.9891 2.7458 0.724 0.47644 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.134 on 22 degrees of freedom ## Multiple R-squared: 0.7582, Adjusted R-squared: 0.7252 ## F-statistic: 22.99 on 3 and 22 DF, p-value: 5.637e-07 Como en la tabla anterior aparecen variables que nos son significativas vamos a realizar una selecci√≥n de variables usando el paquete mixlm creado por Liland (2019). Vamos a realizar una selecci√≥n de variables de manera que s√≥lo queden variables significativas con un \\(\\alpha=0.04\\). mod2 &lt;- mixlm::backward(mod1, alpha=0.04) ## Backward elimination, alpha-to-remove: 0.04 ## ## Full model: Peso ~ Estatura + circun_cuello + circun_muneca ## &lt;environment: 0x00000000390759c8&gt; ## ## Step RSS AIC R2pred Cp F value Pr(&gt;F) ## Estatura 1 836.03 96.235 0.64981 2.2221 0.2221 0.6421 ## circun_muneca 2 886.31 95.753 0.67223 1.5587 1.3833 0.2516 summary(mod2) ## ## Call: ## lm(formula = Peso ~ circun_cuello, data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -11.6933 -3.3996 -0.2729 2.6448 18.2076 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -44.6178 13.4939 -3.307 0.00296 ** ## circun_cuello 3.0990 0.3739 8.288 1.68e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## s: 6.077 on 24 degrees of freedom ## Multiple R-squared: 0.7411, ## Adjusted R-squared: 0.7303 ## F-statistic: 68.69 on 1 and 24 DF, p-value: 1.678e-08 En la siguiente tabla se comparan los modelos 1 y 2 ajustados hasta ahora. De la tabla anterior podemos destacar lo siguiente: El intercepto estimado cambia bastante. En el modelo 2 la variable cuello aumenta su efecto. El R2 se mantiene constante. La varianza de los errores disminuye, eso significa que el modelo 2 deja menos sin explicar. Vamos ahora a crear el diagrama de dispersi√≥n con el modelo ajustado. # Para construir el grafico de dispersion with(datos, plot(x=circun_cuello, y=Peso, pch=19, las=1, xlab=&quot;Circunferencia cuello (cm)&quot;, ylab=&quot;Peso (Kg)&quot;)) # Ahora agregamos la linea de tendencia abline(mod2, lwd=3, col=&#39;blue2&#39;) # por ultimo un texto con la ecuacion o modelo ajustado text(x=34, y=95, expression(hat(Peso) == -44.61 + 3.10 * C.cuello), col=&#39;blue3&#39; ) De la figura anterior vemos que hay un estudiante (el de 100 kilos de peso) que est√° muy alejado de la recta de regresi√≥n. Vamos a calcular las distancia de Cook para las observaciones del modelo 2 as√≠: cooks.distance(mod2) ## 1 2 3 4 5 6 ## 2.597726e-03 3.718175e-02 1.437645e-04 3.872482e-02 2.098520e-02 2.691879e-03 ## 7 8 9 10 11 12 ## 4.858671e-03 2.777286e-01 1.098212e-03 2.062656e-03 9.764606e-01 7.749089e-02 ## 13 14 15 16 17 18 ## 7.199329e-02 1.118988e-03 1.743413e-02 8.336090e-04 2.922296e-02 6.289646e-04 ## 19 20 21 22 23 24 ## 3.650759e-02 1.223109e-02 1.940319e-02 2.854936e-02 7.612115e-03 3.328311e-02 ## 25 26 ## 3.585844e-03 1.457791e-06 Es mejor representar las distancias de Cook en forma gr√°fica para identificar los posible puntos influyentes as√≠: cutoff &lt;- 4 / (26-2-2) plot(mod2, which=4, cook.levels=cutoff, las=1) abline(h=cutoff, lty=&quot;dashed&quot;, col=&quot;springgreen3&quot;) De esta figura es claro que las observaciones 11 y 8 tienen \\(D_i\\) por encima de la cota y se consideran observaciones influyentes. Ahora vamos a revisar los residuales del modelo 2. par(mfrow=c(2, 2)) plot(mod2, col=&#39;deepskyblue4&#39;) De la anterior figura vemos que las observaciones 8, 11 y 13 fueron identificadas por tener valores de residuales grandes. Vamos ahora a identificar las observaciones 8, 11, 12 y 13 en un diagrama de dispersi√≥n. La observaci√≥n 11 es un hombre que pesa m√°s de 100 kilos y que solo mide 1.79 metros. Las observaciones 8, 12 y 13 son mujeres con las mayores diferencias entre \\(y_i\\) y \\(\\hat{y}_i\\), para ellas el modelo sobreestima el peso corporal. En la siguiente tabla se muestran los resultados de ajustar nuevamente el modelo 2 bajo tres situaciones: con todas las observaciones, sin la observaci√≥n 11 y sin las observaciones 8, 11, 12 y 13. De la tabla vemos que la observaci√≥n 11 es muy influyente, al sacar esa observaci√≥n el modelo aumenta su \\(R^2\\) y disminuye su \\(\\sigma^2\\). De la √∫ltima columna se observa el mismo comportamiento, \\(R^2\\) aumenta y disminuye su \\(\\sigma^2\\) al sacar todas las observaciones sospechosas. Pero, ¬øcu√°l modelo debo usar como modelo final? ¬øEl modelo 2, el modelo 2 sin la obs 11 o el modelo 2 sin las obs 8, 11, 12 y 13? Lo que se recomienda es que el analista se asesore de un experto en el √°rea de aplicaci√≥n para que juntos estudien esas observaciones sospechosas. Si hay una raz√≥n de peso para considerarlas como observaciones at√≠picas, ellas deben salir del modelo. Si por el contrario, no hay nada raro con las observaciones ellas deben seguir en el modelo. Las observaciones sospechosas NO se deben sacar inmediatamente del modelo. Antes se deben estudiar para ver si hay algo raro con ellas, en caso afirmativo se sacan de la base y se ajusta nuevamente el modelo. Una observaci√≥n influyente NO es una observaci√≥n mala en el modelo. Al contrario, ella es una observaci√≥n clave en el ajuste porque ‚Äúlidera‚Äù la estimaci√≥n. Una observaci√≥n que no es influyente es una observaci√≥n que estando presente o no, el modelo ajustado no se ve afectado. DFFITS Se puede investigar la influencia de eliminar la \\(i\\)-√©sima observaci√≥n sobre el valor predicho o ajustado. \\[ DFFITS_i = \\frac{\\hat{y}_i - \\hat{y}_{i(i)}}{\\sqrt{s_{(i)}^2 h_{ii}}}. \\] Se sugiere que merece investigarse toda observaci√≥n con \\(|DFFITS| &gt; 2 \\sqrt{p/n}\\). La funci√≥n en R para obtener los \\(DFFITS_i\\) es dffits. DFBETAS Indica cu√°nto cambia el coeficiente de regresi√≥n, en unidades de desviaci√≥n est√°ndar, si se omitiera la ùëñ-√©sima observaci√≥n. \\[ DFBETAS_{i,j} = \\frac{\\hat{\\beta}_j - \\hat{\\beta}_{j(i)}}{\\sqrt{s_{(i)}^2 C_{jj}}}, \\] donde \\(C_{jj}\\) es \\(j\\)-√©simo elemento de la diagonal de \\((\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1}\\). Se sugiere que merece investigarse toda observaci√≥n con \\(|DFBETAS| &gt; 2 \\sqrt{n}\\). La funci√≥n en R para obtener los \\(DFBETAS_{i,j}\\) es dfbetas. Ejemplo En R se pueden encontrar las funciones dfbeta y dfbetas, esto puede generar alguna confusi√≥n y por esa raz√≥n vamos a explicar con detalle el asunto. Soluci√≥n Vamos a crear unos datos para el ejemplo. # Creando unos datos de ejemplo datos &lt;- data.frame(x=1:5, y=rnorm(5)) mod &lt;- lm(y ~ x, data=datos) dfbeta(mod) ## (Intercept) x ## 1 -1.3221238 3.305310e-01 ## 2 0.5540403 -1.108081e-01 ## 3 0.1565594 2.748269e-17 ## 4 0.1335995 -1.335995e-01 ## 5 -0.1943646 9.718231e-02 dfbetas(mod) ## (Intercept) x ## 1 -1.5941063 1.321763e+00 ## 2 0.6133199 -4.068304e-01 ## 3 0.1550826 9.029002e-17 ## 4 0.1722504 -5.712900e-01 ## 5 -0.1747695 2.898225e-01 # DFBETAS para la pendiente manual para i=1 mod1 &lt;- lm(y ~ x, data=datos[-1, ]) # Para obtener dfbeta de pendiente para i=1 coef(mod)[2] - coef(mod1)[2] ## x ## 0.330531 # Para obtener dfbetas de pendiente para i=1 numerator &lt;- mod$coef[2] - mod1$coef[2] denominator &lt;- sqrt(summary(mod1)$sigma^2 * diag(summary(mod)$cov.unscaled)[2]) DFBETAS &lt;- numerator/denominator DFBETAS ## x ## 1.321763 En conclusi√≥n, La funci√≥n dfbeta entrega \\(\\hat{\\beta}_j - \\hat{\\beta}_{j(i)}\\). La funci√≥n dfbetas entrega \\(\\frac{\\hat{\\beta}_j - \\hat{\\beta}_{j(i)}}{\\sqrt{s_{(i)}^2 C_{jj}}}\\). ¬øCu√°l de las dos funciones se debe usar? References "]
]
